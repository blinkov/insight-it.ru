<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/munin/feed/index.xml" rel="self"></atom:link><lastBuildDate>Fri, 13 Apr 2012 20:11:00 +0400</lastBuildDate><item><title>Архитектура Instagram</title><link>https://www.insight-it.ru//highload/2012/arkhitektura-instagram/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/a8e562b3/" rel="nofollow" target="_blank" title="https://instagram.com/"&gt;Instagram&lt;/a&gt; - всего лишь &lt;a href="/tag/ios/"&gt;iOS&lt;/a&gt;, а теперь
и &lt;a href="/tag/android/"&gt;Android&lt;/a&gt;, приложение для обмена фотографиями с
друзьями. Последнее время находится на слуху благодаря новости о покупке
проекта &lt;a href="/tag/facebook/"&gt;Facebook&lt;/a&gt;'ом за кругленькую сумму. Недавно один
из основателей проекта, Mike Krieger, выступил на конференции с докладом
о техническом аспекте проекта, который я и хотел бы вкратце пересказать.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2 id="statistika"&gt;Статистика&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Начало:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1 сервер слабее Macbook Pro&lt;/li&gt;
&lt;li&gt;25к регистраций в первый день&lt;/li&gt;
&lt;li&gt;2 разработчика&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Сегодня:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;40+ миллионов пользователей&lt;/li&gt;
&lt;li&gt;100+ виртуальных серверов в EC2, в том числе:&lt;/li&gt;
&lt;li&gt;Проект куплен Facebook за &lt;em&gt;1 млрд. долл&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;1 миллион регистраций за 12 часов после запуска Android-версии&lt;/li&gt;
&lt;li&gt;5 разработчиков&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tekhnologii"&gt;Технологии&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/ubuntu/"&gt;Ubuntu&lt;/a&gt; &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt; 11.04&lt;/strong&gt; - основная
операционная система&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/python/"&gt;Python&lt;/a&gt;&lt;/strong&gt; - основной язык программирования серверной части&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/django/"&gt;Django&lt;/a&gt;&lt;/strong&gt; - фреймворк&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/amazon/"&gt;&lt;strong&gt;Amazon&lt;/strong&gt;&lt;/a&gt;:&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/ec2/"&gt;EC2&lt;/a&gt;&lt;/strong&gt;&amp;nbsp;- хостинг&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/elb/"&gt;ELB&lt;/a&gt;&lt;/strong&gt;&amp;nbsp;- балансировка входящих HTTP-запросов&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/route53/"&gt;Route53&lt;/a&gt;&lt;/strong&gt; - DNS&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/s3/"&gt;S3&lt;/a&gt;&lt;/strong&gt; - хранение фотографий&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/cloudfront/"&gt;CloudFront&lt;/a&gt;&lt;/strong&gt; - &lt;a href="/tag/cdn/"&gt;CDN&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/nginx/"&gt;nginx&lt;/a&gt;&lt;/strong&gt; - второй уровень балансировки входящихHTTP-запросов&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/gunicorn/"&gt;gunicorn&lt;/a&gt;&lt;/strong&gt; - WSGI-сервер&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/haproxy/"&gt;&lt;strong&gt;HAProxy&lt;/strong&gt;&lt;/a&gt;&amp;nbsp;- балансировка нагрузки внутри системы&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/postgresql/"&gt;&lt;strong&gt;PostgreSQL&lt;/strong&gt;&lt;/a&gt; - основное хранилище данных&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/postgis/"&gt;&lt;strong&gt;postgis&lt;/strong&gt;&lt;/a&gt; - поддержка гео-запросов&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/pgfouine/"&gt;&lt;strong&gt;pgfouine&lt;/strong&gt;&lt;/a&gt; - отчеты на основе логов&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/pgbouncer/"&gt;pgbouncer&lt;/a&gt;&lt;/strong&gt; - создание пула соединений&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/redis/"&gt;&lt;strong&gt;Redis&lt;/strong&gt;&lt;/a&gt; - дополнительное хранилище данных&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;&lt;strong&gt;Memcached&lt;/strong&gt;&lt;/a&gt; - кэширование&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/gearman/"&gt;&lt;strong&gt;Gearman&lt;/strong&gt;&lt;/a&gt; - очередь задач&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/solr/"&gt;&lt;strong&gt;Solr&lt;/strong&gt;&lt;/a&gt; - гео-поиск&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="/tag/munin/"&gt;munin&lt;/a&gt;&lt;/strong&gt;, &lt;a href="/tag/statsd/"&gt;&lt;strong&gt;statsd&lt;/strong&gt;&lt;/a&gt;, &lt;a href="/tag/pingdom/"&gt;&lt;strong&gt;pingdom&lt;/strong&gt;&lt;/a&gt; - мониторинг&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/fabric/"&gt;&lt;strong&gt;Fabric&lt;/strong&gt;&lt;/a&gt; - управление кластером&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/xfs/"&gt;&lt;strong&gt;xfs&lt;/strong&gt;&lt;/a&gt; - файловая система&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="filosofiia"&gt;Философия&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Простота&lt;/li&gt;
&lt;li&gt;Минимизация операционных издержек&lt;/li&gt;
&lt;li&gt;Использование подходящих инструментов&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id="istoriia"&gt;История&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Забыли сделать &lt;strong&gt;favicon.ico&lt;/strong&gt; до запуска - в первый же день логи
пестрили ошибками 404&lt;/li&gt;
&lt;li&gt;Для хранения данных использовали просто &lt;strong&gt;Django &lt;a href="/tag/orm/"&gt;ORM&lt;/a&gt;&lt;/strong&gt; и
&lt;strong&gt;PostgreSQL&lt;/strong&gt; (из-за postgis)&lt;/li&gt;
&lt;li&gt;Начали с одного слабого сервера, после успешного запуска решили
переехать на &lt;strong&gt;EC2&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Довольно быстро пришлось вынести &lt;a href="/tag/subd/"&gt;СУБД&lt;/a&gt; на отдельный сервер
(виртуальный, естественно)&lt;/li&gt;
&lt;li&gt;Количество фотографий продолжало расти и расти, даже самый большой
инстанс &lt;strong&gt;EC2&lt;/strong&gt; не справлялся&lt;/li&gt;
&lt;li&gt;Решили вертикально разделить данные на несколько баз, с использованием
механизма &lt;strong&gt;routers&lt;/strong&gt; из ORM, параллельно избавившись от внешних ключей&lt;/li&gt;
&lt;li&gt;Через несколько месяцев суммарный размер базы данных перевалил за 60Гб и
перестало справляться и это решение&lt;/li&gt;
&lt;li&gt;Следующим шагом стало горизонтальное разбиение данных &lt;em&gt;(sharding)&lt;/em&gt;:&lt;/li&gt;
&lt;li&gt;Создали несколько тысяч логических баз данных.&lt;/li&gt;
&lt;li&gt;Распределили их по существенно меньшему количеству физических серверов (читай: виртуальных машин).&lt;/li&gt;
&lt;li&gt;Написали свой механизм определения где искать какую базу данных, с поддержкой миграции (вероятно тоже на основе routers).&lt;/li&gt;
&lt;li&gt;По последним данным под &lt;strong&gt;PostgreSQL&lt;/strong&gt; используется 12+12 виртуальных
машин с максимальной оперативной памятью (68.4Гб), а также сетевые диски
EBS, объединенные в программный RAID посредством mdadm. Это необходимо,
чтобы весь массив данных помещался в памяти, EBS не в состоянии
обеспечить достаточную производительность.&lt;/li&gt;
&lt;li&gt;С некоторыми задачами лучше справляется &lt;strong&gt;Redis&lt;/strong&gt;:&lt;/li&gt;
&lt;li&gt;Для каждого пользователя в Redis есть список идентификаторов новых
фотографий от других пользователей, на которых он подписан.&lt;/li&gt;
&lt;li&gt;При отображении потока новых для пользователя фотографий делается
выборка части такого списка, после чего посредством multiget достается
подробная о них информация из memcached.&lt;/li&gt;
&lt;li&gt;Пробовали возложить на него задачу хранения списков подписчиков, но в
итоге вернулись к решению на &lt;strong&gt;PostgreSQL&lt;/strong&gt; с небольшим кэшированием.&lt;/li&gt;
&lt;li&gt;В Redis также хранится информация о сессиях.&lt;/li&gt;
&lt;li&gt;Несколько фактов о Redis:&lt;ul&gt;
&lt;li&gt;Так как все находится в памяти - очень быстрые операции записи и работы с множествами.&lt;/li&gt;
&lt;li&gt;Является не заменой, а дополнением к основному хранилищу данных.&lt;/li&gt;
&lt;li&gt;Redis хорош для структур данных, которые относительно ограничены.&lt;/li&gt;
&lt;li&gt;Отлично подходит для кэширования комплексных структур данных, где нужно большее, чем просто получить значение по ключу (например - счетчики, подмножества, проверка вхождения в множества).&lt;/li&gt;
&lt;li&gt;Механизм репликации (посредством slaveof) позволяет легко
масштабировать операции чтения.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Пользователи синхронно загружают фотографии на медиа-сервер с
(опциональными) заголовком и месте на карте, все остальное происходит
асинхронно посредством очередей, например:&lt;ul&gt;
&lt;li&gt;Сохраняются гео-метки, обновляется &lt;strong&gt;Solr&lt;/strong&gt; (который впоследствии заменил postgis).&lt;/li&gt;
&lt;li&gt;Идентификатор нового фото добавляется в обсуждавшиеся выше списки для всех подписчиков автора.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Поначалу использовали &lt;a href="/tag/apache/"&gt;Apache&lt;/a&gt; + &lt;code&gt;mod_wsgi&lt;/code&gt; для запуска
&lt;strong&gt;Django&lt;/strong&gt;, впоследствии перешли к gunicorn из-за меньшего потребления
ресурсов и простоты настройки.&lt;/li&gt;
&lt;li&gt;С недавних пор начали использовать&amp;nbsp;&lt;strong&gt;Amazon ELB&lt;/strong&gt;&amp;nbsp;вместо &lt;strong&gt;DNS
round-robin&lt;/strong&gt; для первичной балансировки входяших HTTP-запросов, что
позволило:&lt;/li&gt;
&lt;li&gt;избежать необходимости дешифровки &lt;a href="/tag/ssl/"&gt;&lt;strong&gt;SSL&lt;/strong&gt;&lt;/a&gt; посредством nginx;&lt;/li&gt;
&lt;li&gt;ускорить исключение из балансировки проблемных серверов.&lt;/li&gt;
&lt;li&gt;Благодаря использованию &lt;strong&gt;xfs&lt;/strong&gt; есть возможность "замораживать" и
"размораживать" дисковые массивы при резервном копировании.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="podvodim-itogi"&gt;Подводим итоги&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Многие проблемы с масштабируемостью - результат банальных
    человеческих ошибок.&lt;/li&gt;
&lt;li&gt;Масштабирование = замена всех деталей в машине на скорости 150 км/ч.&lt;/li&gt;
&lt;li&gt;Заранее сложно узнать как в основном будут обращаться к данным, без
    реального использования.&lt;/li&gt;
&lt;li&gt;В первую очередь попытайтесь адаптировать известные Вам технологии и
    инструменты для создания простого и понятного решения, прежде чем
    бросаться на поиски чего-то нетривиального.&lt;/li&gt;
&lt;li&gt;Дополните свое основное хранилище более гибким компонентом, вроде
    Redis.&lt;/li&gt;
&lt;li&gt;Постарайтесь не использовать два инструмента для решения одной и той
    же задачи.&lt;/li&gt;
&lt;li&gt;Оставайтесь гибкими и ловкими = напоминайте себе о том, что на самом
    деле имеет значение.&lt;/li&gt;
&lt;li&gt;Разрабатывайте решения, к которым не придется постоянно возвращаться
    из-за их сбоев.&lt;/li&gt;
&lt;li&gt;Активное юнит- и функциональное тестирование стоят потраченного на
    них времени.&lt;/li&gt;
&lt;li&gt;DRY: не делайте одну и ту же работу несколько раз.&lt;/li&gt;
&lt;li&gt;Слабая связанность посредством уведомлений или сигналов позволяет
    легко менять структуру проекта.&lt;/li&gt;
&lt;li&gt;Дисковый ввод-вывод часто оказывается узким местом, особенно на EC2.&lt;/li&gt;
&lt;li&gt;Спускаться до C нужно только при необходимости, большую часть работы
    лучше делать в Python.&lt;/li&gt;
&lt;li&gt;Короткий цикл разработки - залог быстрого развития.&lt;/li&gt;
&lt;li&gt;Частые совместные рассмотрения кода нужны, чтобы все были в курсе
    происходящего.&lt;/li&gt;
&lt;li&gt;Не изобретайте велосипед.&lt;/li&gt;
&lt;li&gt;Окружите себя с толковыми &lt;a href="https://www.insight-it.ru/consulting/"&gt;консультантами&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Культура открытости вокруг разработки.&lt;/li&gt;
&lt;li&gt;Делитесь с &lt;a href="/tag/opensource/"&gt;opensource&lt;/a&gt; сообществом.&lt;/li&gt;
&lt;li&gt;Фокусируйтесь на том, что вы делаете лучше всего.&lt;/li&gt;
&lt;li&gt;Вашим пользователям абсолютно без разницы, написали ли Вы
    собственную СУБД или нет.&lt;/li&gt;
&lt;li&gt;Не переоптимизируйте и не предполагайте заранее как сайт будет
    расти.&lt;/li&gt;
&lt;li&gt;Не рассчитывайте, что "кто-то еще присоединится к команде и
    разберется с этим".&lt;/li&gt;
&lt;li&gt;Для социальных стартапов очень мало, или даже совсем нет, нерешимых
    вопросов, связанных с масштабируемостью.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="istochnik-informatsii"&gt;Источник информации&lt;/h2&gt;
&lt;p&gt;Упоминавшаяся во вступлении неприлично длинная презентация из 185
слайдов:&lt;/p&gt;
&lt;iframe class="scribd_iframe_embed" data-aspect-ratio="" data-auto-height="true" frameborder="0" height="600" id="doc_73113" scrolling="no" src="http://www.scribd.com/embeds/89025069/content?start_page=1&amp;amp;view_mode=scroll" width="100%"&gt;&lt;/iframe&gt;
&lt;p&gt;На видео, к сожалению, это выступление не записывалось.&lt;/p&gt;
&lt;p&gt;Часть информации взята из &lt;a href="https://www.insight-it.ru/goto/ce2d4e38/" rel="nofollow" target="_blank" title="http://instagram-engineering.tumblr.com/"&gt;технического блога Instagram&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 13 Apr 2012 20:11:00 +0400</pubDate><guid>tag:www.insight-it.ru,2012-04-13:highload/2012/arkhitektura-instagram/</guid><category>Amazon</category><category>Android</category><category>CloudFront</category><category>django</category><category>EC2</category><category>ELB</category><category>Fabric</category><category>Facebook</category><category>gearman</category><category>gunicorn</category><category>HAProxy</category><category>Intagram</category><category>iOS</category><category>Linux</category><category>Memcached</category><category>Munin</category><category>nginx</category><category>ORM</category><category>pgbouncer</category><category>pgFouine</category><category>Pingdom</category><category>postgis</category><category>PostgreSQL</category><category>Python</category><category>Redis</category><category>Route53</category><category>S3</category><category>Solr</category><category>statsd</category><category>Ubuntu</category><category>WSGI</category><category>xfs</category><category>Архитектура Instagram</category></item><item><title>Архитектура Mollom</title><link>https://www.insight-it.ru//highload/2011/arkhitektura-mollom/</link><description>&lt;p&gt;&lt;img alt="Mollom" class="right" src="https://www.insight-it.ru/images/mollom-logo.jpg" title="Mollom"/&gt;
&lt;a href="https://www.insight-it.ru/goto/aa3c2fd2/" rel="nofollow" target="_blank" title="http://mollom.com/"&gt;Mollom&lt;/a&gt; - это прибыльный SaaS сервис по фильтрации различных форм спама из
контента, сгенерированного пользователями: комментариев, постов на
форумах и блогах, опросов, контактных и регистрационных форм.
Определение спама основано не только на контенте, но и репутации и
прошлой активности разместившего его пользователя. Алгоритм машинного
обучения Mollom выполняет роль цифрового модератора 24х7 для более 40
тысяч сайтов, в том числе и очень крупных компаний.&lt;/p&gt;
&lt;p&gt;С того момента, как Mollom запустили систему анализа цифрового контента,
они выявили более 373 миллионов спам сообщений, обнаружив в процессе что
впечатляющие 90% всех прошедших через них сообщений оказались спамом.
Весь этот поток спама в 100 сообщений в секунду обрабатывается всего
двумя географически распределенными серверами. На каждом из них работает
сервер Java-приложений и Cassandra. Так мало ресурсов требуется лишь
из-за того, что они создали очень эффективную систему машинного
обучения. Разве не круто? Так как же они это делают?&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id="statistika"&gt;Статистика&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Обслуживаются 40000 активных веб-сайтов, многие их которых
    принадлежат крупным клиентам, таким как Adobe, Sony BMG, Warner
    Brothers, Fox News и The Economist. Много крупных брендов, с
    крупными сайтами, масса комментариев.&lt;/li&gt;
&lt;li&gt;Обнаруживают пол-миллиона спам-сообщений ежедневно.&lt;/li&gt;
&lt;li&gt;Обрабатывается около 100 запросов к API в секунду.&lt;/li&gt;
&lt;li&gt;Проверка сообщения на спам занимает очень мало времени, обычно около
    30-50 миллисекунд, 95% запросов укладывается в 250 миллисекунд,
    когда самые медленные обрабатываются пол секунды.&lt;/li&gt;
&lt;li&gt;Эффективность определения спама составляет 99.95%. Это означает, что
    из 10000 спам-сообщений Mollom пропустит только 5.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/82e0a09b/" rel="nofollow" target="_blank" title="http://mollom.com/blog/netlog-using-mollom"&gt;Netlog&lt;/a&gt;, европейская
    социальная сеть, имеет отдельный Mollom-сервер в своем датацентре.
    Netlog проверяют на спам около 4 миллионов сообщений каждый день на
    классификаторах, специально натренированных на их данных.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="platforma"&gt;Платформа&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/java/"&gt;Java&lt;/a&gt; - исторически сложилось, что Mollom был с самого
    начала был разработан на Java.&lt;/li&gt;
&lt;li&gt;Два сервера обслуживают основную часть клиентов:&lt;ul&gt;
&lt;li&gt;Один сервер на восточном побережье США, другой - на западном&lt;/li&gt;
&lt;li&gt;В случае сбоя один сервер может полностью подменить другой&lt;/li&gt;
&lt;li&gt;Конфигурация обоих: Intel Xeon Quad core, 2.8GHz, 16GB RAM, 4
    диска по 300 GB, RAID 10.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/ad66f2bf/" rel="nofollow" target="_blank" title="http://www.softlayer.com/"&gt;SoftLayer&lt;/a&gt; - хостинг-провайдер.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/baf11ec8/" rel="nofollow" target="_blank" title="http://cassandra.apache.org/"&gt;Cassandra&lt;/a&gt; - NoSQL база данных,
    выбранная из-за высокой производительности на запись и способности
    работать на серверах, располагающихся в разных датацентрах (была
    разработана в&amp;nbsp;&lt;a href="https://www.insight-it.ru/highload/2010/arkhitektura-facebook/"&gt;Facebook&lt;/a&gt;,
    но там практически не используется).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/dce103e6/" rel="nofollow" target="_blank" title="http://www.mysql.com/"&gt;MySQL&lt;/a&gt; - Java Persistence API используется
    для обычных наборов данных, когда Cassandra используется для больших
    объемов данных.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/2b056aff/" rel="nofollow" target="_blank" title="http://en.wikipedia.org/wiki/GlassFish"&gt;Glassfish&lt;/a&gt; - open source
    сервер приложений для платформы Java EE. Они выбрали именно
    Glassfish за его возможности корпоративного уровня, такие как
    репликация и обработка сбоев.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/cc84f430/" rel="nofollow" target="_blank" title="http://hudson-ci.org/"&gt;Hudson&lt;/a&gt; - предоставляет непрерывное
    тестирование и развертывание кода серверной части на всех
    используемых машинах.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/f94e85c8/" rel="nofollow" target="_blank" title="http://munin-monitoring.org/"&gt;Munin&lt;/a&gt; - измерение и построение
    графиков, касающихся здоровья серверов.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/cfd5a6c7/" rel="nofollow" target="_blank" title="http://www.pingdom.com/"&gt;Pingdom&lt;/a&gt; - внешний мониторинг.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/acf8f59d/" rel="nofollow" target="_blank" title="http://www.zendesk.com/"&gt;Zendesk&lt;/a&gt; - используется для оказания
    поддержки клиентам.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/17f204ac/" rel="nofollow" target="_blank" title="http://drupal.org/"&gt;Drupal&lt;/a&gt; - используется для основного сайта со
    специализированным модулем интернет-магазина.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/a81d9bb9/" rel="nofollow" target="_blank" title="http://unfuddle.com/"&gt;Unfuddle&lt;/a&gt; - хостинг Subversion для
    взаимодействия удаленной команды разработчиков.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="kak-eto-rabotaet"&gt;Как это работает?&lt;/h2&gt;
&lt;p&gt;Процесс выглядит следующим образом:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Когда пользователь отправляет комментарий на сайт, происходит запрос
    к API Mollom.&lt;/li&gt;
&lt;li&gt;Контент анализируется, если он оказывается спамом, то сайту
    сообщается, что необходимо его заблокировать, если же алгоритм не
    уверен на 100% - сайту советуют показать CAPTCHA, которую сервис
    также предоставляет.&lt;/li&gt;
&lt;li&gt;После того, как CAPTCHA будет успешно заполнена, контент
    принимается. В большинстве случаев пользователи не будут ее видеть и
    контент будет приниматься сразу же.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Обнаружение спама является сложным балансом между отказом нормальному
контенту и принятию спама.&lt;/p&gt;
&lt;h2 id="biznes-model"&gt;Бизнес-модель&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Основным залогом популярности Mollom является бесплатная возможность
    попробовать сервис, ограничение составляет 100 нормальных (не спам)
    сообщений в день. Небольшие сайты могут никогда и не достичь этого
    ограничения.&lt;/li&gt;
&lt;li&gt;Далее есть два тарифа: 1 евро в день и 3600 евро с возможностями
    вполне соответствующими этим суммам&lt;/li&gt;
&lt;li&gt;Сайты, использующие бесплатный тариф, вовсе не зря тратят ресурсы
    системы, как кажется на первый взгляд, а являются жизненно-важным
    источником данных для тренировки системы. Без этих данных алгоритмы
    были бы существенно менее точны.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="arkhitektura"&gt;Архитектура&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Разработчики Mollom уделяют максимум внимания времени отклика,
    эффективности кода и использования серверных ресурсов.&lt;/li&gt;
&lt;li&gt;Физически каждый сервер может справиться со всеми запросами, два
    сервера нужны для избежания перерывов в работе системы. Когда оба
    сервера в строю - работа распределяется между ними, когда один
    падает - второй перехватывает его запросы.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Mollom прошел через несколько этапов развития:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Изначально маленькая команда из двух человек работала вечерами
    над основными алгоритмами, классификаторами и реальными
    бизнес-задачами, которые они пытались решить. Для построения
    инфраструктуры серверной части они использовали свои реализации
    базовых механизмов по управлению ресурсами, соединениями и
    потоками. В итоге они обнаружили, что тратят слишком много
    времени на эти вещи. После этого они переключились на Glassfish,
    что позволило им намного меньше беспокоится об управлении
    памятью, REST-запросах, парсинге XML и поддержании пула
    соединений с базой данных.&lt;/li&gt;
&lt;li&gt;В прошлом основной проблемой была пропускная способность
    дисковой подсистемы. Они должны хранить информацию о репутации
    всех IP-адресов и URL по всему Интернету, что привело к
    массивному набору данных с большим количеством случайных
    обращений.&lt;/li&gt;
&lt;li&gt;Поначалу они использовали MySQL на недорогой виртуальной машине,
    что в итоге не смогло масштабироваться.&lt;/li&gt;
&lt;li&gt;Они перенесли данные на твердотельные жесткие диски (SSD) и
    стали все хранить в файлах. Этот шаг решил проблемы с записью,
    но возникли новые проблемы:&lt;ol&gt;
&lt;li&gt;Это правда дорого.&lt;/li&gt;
&lt;li&gt;Очень чувствительно к типу используемой файловой системы&lt;/li&gt;
&lt;li&gt;Запись стала происходить быстрой, но итерация по большим
    наборам данным (что они делали довольно часто для очистки
    данных и обучения классификаторов) по-прежнему была очень
    медленным процессом.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;В итоге они отказались от твердотельных накопителей и стали
    использовать Cassandra.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Cassandra сейчас используется для обработки интенсивного потока
    запросов на запись и в роли кэша:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Работает на RAID10, что хорошо подходит для высоких смешанных
    нагрузок на запись/чтение.&lt;/li&gt;
&lt;li&gt;Cassandra оптимизирована для записи, а в Mollom запись как раз
    происходит намного чаще, чем чтение.&lt;/li&gt;
&lt;li&gt;Разработана для распределенной работы как внутри датацентра, так
    и между датацентрами.&lt;/li&gt;
&lt;li&gt;Обратной стороной медали является отсутствие стандартного NoSQL
    интерфейса, что усложняет реализацию приложений.&lt;/li&gt;
&lt;li&gt;Механизм кэширования строк в Cassandra позволяет им не
    использовать отдельную систему для кэширования, что существенно
    упростило код приложения.&lt;/li&gt;
&lt;li&gt;Cassandra имеет функцию удаления устаревшей информации после
    определенного периода времени. В Европе существуют строгие
    законы о приватности личных данных, согласно которым они должны
    храниться не более определенного срока (штаб-квартира Mollom
    находится в Бельгии). В этом плане эта функция очень удобна.
    Эта функция опять же избавляет от необходимости реализовывать
    данный функционал вручную.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Типичный путь одного комментария внутри системы:&lt;ul&gt;
&lt;li&gt;Балансировка нагрузки между серверами лежит на клиентской
    библиотеке, в роли типичного клиента может выступать сайт на
    Drupal, осуществляющий запрос к API через XML-RPC или REST.&lt;/li&gt;
&lt;li&gt;Запросы обрабатываются сервером приложений Glassfish и проходят
    стандартный процесс обработки с помощью сервлетов и специфичных
    классов.&lt;/li&gt;
&lt;li&gt;Платящие клиенты обслуживаются в первую очередь, что приводит к
    тому, что клиенты на бесплатном тарифе могут ожидать результата
    несколько дольше.&lt;/li&gt;
&lt;li&gt;Запрос анализируется и оценка вероятности спама возвращается
    пользователю. Помимо этого отдельная часть кода Mollom отвечает
    за генерацию, выдачу и проверку CAPTCHA.&lt;/li&gt;
&lt;li&gt;Классификаторы полностью располагаются в оперативной памяти.
    Небольшой кусок контента разбивается на тысячи и тысячи
    крошечных частей, которые могут быть идентифицированы как спам.
    Такие классификаторы хранят в памяти до нескольких миллионов
    признаков, характерных для спама. Анализ должен выполняться
    очень быстро, так что никаких других вариантов кроме
    расположения всех требуемых данных в оперативной памяти просто
    не было.&lt;/li&gt;
&lt;li&gt;В Cassandra хранятся очки репутации, частоты, URL и IP-адреса.&lt;/li&gt;
&lt;li&gt;Струтуры данных в памяти не реплицируются напрямую. Они
    записываются в Cassandra, которая и передает их на второй
    сервер. Промежуток времени, когда данные не консистентны, очень
    невелик, так что это не сказывается негативно на алгоритмах.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Балансировка нагрузки с помощью клиента:&lt;ul&gt;
&lt;li&gt;Mollom использует такой подход к балансировке, так как стартап
    не может себе позволить дорогой железный балансировщик нагрузки.
    Если учесть, что им нужна балансировка между датацентрами,
    решение от любого из вендоров было бы комплексным и дорогим.&lt;/li&gt;
&lt;li&gt;У каждого клиента есть индивидуальный список серверов, которыми
    он может воспользоваться. Этот список изменяется через API.&lt;/li&gt;
&lt;li&gt;Каждый клиент может использовать разный список, платящим
    клиентам могут предоставлять отдельные сервера для уменьшения
    задержек.&lt;/li&gt;
&lt;li&gt;Если сервер упал - клиент пытается подключиться к следующему
    серверу в списке.&lt;/li&gt;
&lt;li&gt;С другой стороны такой подход усложняет разработку неофициальных
    клиентов: авторам проекта приходится тесно работать с
    разработчиками сторонних клиентов для обеспечения правильной
    реализации в них балансировки нагрузки.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Машинное обучение:&lt;ul&gt;
&lt;li&gt;Mollom - это набор самообучающихся систем. Отдельные
    CAPTCHA-решения, не учитывают ни пользовательское поведение, ни
    источник контента, заставляя каждого пользователя вводить
    проверочный код при каждом сообщении. В случае с Mollom это
    происходит только когда система анализа контента не уверена в
    конкретном решении.&lt;/li&gt;
&lt;li&gt;Средняя длина сообщения - 500 символов, обычно оно разбивается
    на 3000 характеристик. Принадлежность контента к спаму
    определяется путем оценки репутации IP адреса или Open ID,
    пользовательского идентификатора, эмоциональной окраски, языка,
    профанации, проверки на наличие специфичных слов и фраз, также
    учитывается качество написания текста и многие другие факторы.
    Все эти данные основываются на классификаторах. Некоторые из них
    статистические по природе, так что обучение происходит
    автоматически. Другие же основываются на правилах для того,
    чтобы быть уверенными, что они никогда не могут быть настроены
    неверно. Комбинация результатов всех тестов после нормализации и
    образует финальный рейтинг принадлежности к спаму каждого
    конкретного сообщения.&lt;/li&gt;
&lt;li&gt;Классификаторы и внутренние метрики обучаются с каждым новым
    сообщением и обновляются в реальном времени.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Glassfish берет на себя планировку нагрузки, учитывая многоядерность
    системы:&lt;ul&gt;
&lt;li&gt;Ключ к дизайну системы в многопроцессорном окружении заключается
    в максимальном параллелизации работы при минимальном простое
    из-за блокировок.&lt;/li&gt;
&lt;li&gt;Они используют 16 thread'ов на сервер.&lt;/li&gt;
&lt;li&gt;Большинство запросов обрабатываются сессионными объектами (Java
    Bean), не имеющими состояний. Они хорошо подходят для управления
    параллельными запросами.&lt;/li&gt;
&lt;li&gt;Они держат пул из нескольких сессионных объектов, но определение
    их количества делегируется Glassfish. В пиковую нагрузку это
    число увеличивается для более эффективной обработки запросов,
    порой оно достигает 32.&lt;/li&gt;
&lt;li&gt;Все классификаторы реализованы как раз как такие объекты,
    повторно использующиеся различными thread'ами.&lt;/li&gt;
&lt;li&gt;У каждого объекта есть свое клиентское соединение с Cassandra,
    чтобы гарантировать отсутствие блокировок.&lt;/li&gt;
&lt;li&gt;Когда пользователь не отвечает на CAPTCHA сессия очищается и
    Mollom узнает что это скорее всего был спам.&lt;/li&gt;
&lt;li&gt;На каждом сервере запущено по одной копии каждого
    классификатора.&lt;/li&gt;
&lt;li&gt;В момент очистки сессии происходит небольшая блокировка, когда
    происходит обновление классификаторов.&lt;/li&gt;
&lt;li&gt;Обновленные классификаторы записываются в Cassandra каждые пол
    часа.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Интеграция приложений:&lt;ul&gt;
&lt;li&gt;Mollom использует открытый API, который может быть интегрирован
    в любую систему.&lt;/li&gt;
&lt;li&gt;Библиотеки: Java, PHP, Ruby и другие.&lt;/li&gt;
&lt;li&gt;Готовые модули: Drupal, Joomla, Wordpress и прочие системы
    управления контентом.&lt;/li&gt;
&lt;li&gt;Решения от сторонних разработчиков, основанные на примерах кода
    от &amp;nbsp;Mollom.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Для мониторинга здоровья серверов они используют Munin:&lt;ul&gt;
&lt;li&gt;Каков размер heap памяти после сбора мусора?&lt;/li&gt;
&lt;li&gt;Каково количество доступных соединений?&lt;/li&gt;
&lt;li&gt;Каково количество thread'ов в пуле?&lt;/li&gt;
&lt;li&gt;Оценка времени блокировок в каждом thread'е.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Если взглянуть в целом на архитектуру Mollom, можно увидеть, что они
    стараются построить систему, способную прозрачно работать в
    нескольких датацентрах, чтобы позволить горизонтально расширить
    систему, когда они перерастут текущую двухсерверную конфигурацию:&lt;ul&gt;
&lt;li&gt;Балансировка нагрузки на клиенте позволяет выбирать оптимальный
    сервер и справляться со сбоями одного из них.&lt;/li&gt;
&lt;li&gt;Кластеризация Glassfish облегчает добавление/удаление новых
    машин и позволяет перехватывать запросы, когда один из серверов
    выходит из строя.&lt;/li&gt;
&lt;li&gt;Cassandra используется для управления данными между серверами в
    нескольких датацентрах.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Инсталляция Mollom в Netlog обладает некоторыми интересными
    характеристиками. Она обрабатывает больше сообщений, чем основные
    сервера Mollom, но распределение спама в ней совершенно другое, так
    как люди в ней общаются в рамках социальной сети. Внутри Netlog лишь
    10% сообщений является спамом, когда в суровом мире информационных
    порталов распределение обратно. Интересным следствием является тот
    факт, что обработка нормальных сообщений требует меньше
    вычислительных ресурсов, так что на аналогичном оборудовании удается
    обрабатывать больший поток сообщений.&lt;/li&gt;
&lt;li&gt;Изначально они думали о виртуализированных серверах, в частности об
    Amazon EC2, но в итоге обнаружилось, что наиболее узким местом
    являются операции ввода-вывода - низкая производительность дисковой
    подсистемы в виртуальных машинах создавали реальные проблемы, так
    что они решили воспользоваться вертикальным масштабированием и
    переехали на более дорогие физические машины с большим объемом
    дискового пространства:&lt;ul&gt;
&lt;li&gt;На удивление они не упираются в вычислительные ресурсы: лишь два
    ядра из 8 занимаются вычислениями, когда остальные же работают
    над операциями ввода-вывода.&lt;/li&gt;
&lt;li&gt;Трафик Mollom практически постоянен, так что физические сервера
    более эффективны с финансовой точки зрения. Они рассматривают
    Amazon лишь как запасной вариант для обработки непредвиденных
    пиков нагрузки.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Процесс разработки:&lt;ul&gt;
&lt;li&gt;Команда распределена: трое в Бельгии, остальные в Техасе,
    Бостоне и Германии.&lt;/li&gt;
&lt;li&gt;Scrum используется в процессе разработки и они довольны этой
    методологией. Scrum-собрание проходит через Skype в два часа дня
    по Бельгии.&lt;/li&gt;
&lt;li&gt;Разработчики работают локально и отправляют код на Unfuddle.&lt;/li&gt;
&lt;li&gt;Hudson используется для непрерывного интеграционного
    тестирования.&amp;nbsp;Hudson позволил облегчить миграцию, так как перед
    развертыванием все тесты должны быть пройдены. Они не теряли
    лишнего времени на проблемах, обнаруженных уже в развернутом
    приложении.&lt;/li&gt;
&lt;li&gt;Они активно используют автоматическое тестирование: юнит-тесты,
    системные тесты, тесты Drupal.&lt;/li&gt;
&lt;li&gt;Развертывание по-прежнему делается вручную для минимизации риска
    простоя (что правда спорный момент).&lt;/li&gt;
&lt;li&gt;Для обнаружения утечек памяти они используют анализ дампов
    оперативной памяти. Анализ дампа сервера с 16Гб памяти - дело
    непростое, практически невозможное на обычном компьютере, так
    что они арендуют большую виртуальную машину на Amazon для
    проведения анализа. Весь процесс занимает всего около 2 часов.
    Они сравнивают два дампа: через 10 и 20 часов после запуска
    сервера. Если обнаруживаются значительные отличия, то скорее
    всего дело в утечке памяти.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="puti-razvitiia"&gt;Пути развития&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Mollom API основано на XML-RPC, REST-интерфейс находится на стадии
    тестирования для облегчения интеграции других сервисов.&lt;/li&gt;
&lt;li&gt;Они мигрировали на Cassandra, чтобы облегчить процесс
    горизонтального масштабирования, когда нагрузка достигнет
    соответствующего уровня.&lt;/li&gt;
&lt;li&gt;Скоро будут выпущены корпоративные возможности, которые позволят
    работать с сотнями сайтов как с единым целым. Появится возможность
    легко модерировать несколько сайтов одновременно по эмоциональной
    окраске сообщений, рейтингу спама или удалить все сообщения с
    определенного IP-адреса.&lt;/li&gt;
&lt;li&gt;Они думали над участием в бизнесе потоковых данных вроде Twitter, но
    они сильно ограничены европейскими более строгими требованиями по
    приватности.&lt;/li&gt;
&lt;li&gt;Планируются эксперименты по использованию Glassfish для балансировки
    нагрузки в рамках каждого датацентра.&lt;/li&gt;
&lt;li&gt;Если нагрузка увеличится десятикратно им придется добавить больше
    серверов в Cassandra. Дисковый ввод-вывод является узким местом.
    Дополнительные сервера приложения понадобятся только если нагрузка
    вырастет более, чем на порядок.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="podvodim-itogi"&gt;Подводим итоги&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mollom очень серьезно относится к
    разработке&amp;nbsp;высокопроизводительной системы.&lt;/strong&gt; Они гордятся тем, что
    Mollom очень эффективно использует вычислительные и финансовые
    ресурсы. Множество запросов может обрабатываться одним сервером с
    низкой задержкой, что очень радует как клиентов, так и владельцев
    проекта, так как издержки очень низки. Этот вопрос был выбран
    приоритетным с самого начала и они выбрали подходящие технологии для
    реализации своих целей. Это позволило им вкладывать средства в
    маркетинг, построить базу клиентов и создавать новые продукты на
    основе Mollom.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Машинное обучение требует много исходных данных&amp;nbsp;для успешного
    обнаружение спама.&lt;/strong&gt; Для сбора этих данных предлагает бесплатные
    услуги. Крупные клиенты обеспечивают доход и получают выгоду от
    данных, полученных от более мелких клиентов. Эта модель очень хорошо
    себя проявила в машинном обучении, за которым как известно будущее.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Старайтесь избавиться от проблем, не связанных напрямую с
    продуктом.&lt;/strong&gt; Большие системы требуют серьезных усилий на разработку
    инфраструктуры. Можно убить все время на построение&amp;nbsp;инфраструктуры,
    вместо создания по-настоящему ценного продукта (классификаторов,
    системы репутации, клиентских библиотек). Mollom постоянно пытались
    максимально избавляться от лишних проблем, именно по-этому они
    выбрали Cassandra и Glassfish.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Будьте осторожны с клиентским кодом.&lt;/strong&gt; Выполнение кода на
    клиентской части привлекательно тем, что он тратит чужие ресурсы, а
    не серверные. Проблемы начинаются когда сторонние библиотеки
    разрабатываются некачественно, что заставляет систему в целом
    работать плохо. Плотно работайте с разработчиками клиентских
    библиотек для повышения качества их продукции.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Отдавайте приоритет платящим клиентам.&lt;/strong&gt; Платящие клиенты получают
    более высокое качество услуг, обрабатываются вне очереди, получают
    меньше задержек и получают доступ к запасному серверу когда основной
    дал сбой. Этого вполне достаточно, чтобы подтолкнуть клиентов
    платить.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Уменьшайте объем кода, позволяя используемым сторонним продуктам
    брать на себя грязную работу&lt;/strong&gt;.&amp;nbsp;Поначалу код Mollom был существенно
    большим по объему, чем сейчас. Использование Cassandra и Glassfish
    позволило убрать массу кода, связанного с кэшированием,
    кластеризацией, репликацией и обработкой сбоев. Упрощайте систему со
    временем.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Минимизируйте блокировки.&lt;/strong&gt; Mollom потратили много времени на
    устранение блокировок внутри Glassfish, так как это начинало
    становиться узким местом. Минимизируйте простой от блокировок для
    достижения полного параллелизма.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="istochniki-informatsii-i-dopolnitelnye-materialy"&gt;Источники информации и дополнительные материалы&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/796d6b53/" rel="nofollow" target="_blank" title="http://highscalability.com/blog/2011/2/8/mollom-architecture-killing-over-373-million-spams-at-100-re.html"&gt;Mollom Architecture - Killing Over 373 Million Spams At 100 Request
    Per
    Second&lt;/a&gt;
    (основной источник информации)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/a695ef0e/" rel="nofollow" target="_blank" title="http://mollom.com/files/mollom-technical-whitepaper.pdf"&gt;Mollom Technical
    Whitepaper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/23d06e29/" rel="nofollow" target="_blank" title="http://blogs.sun.com/glassfishpodcast/entry/episode_072_mollom_com_s"&gt;Episode #072 - Mollom.com's GlassFish backend with Dries and
    Johan&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/c1eeadac/" rel="nofollow" target="_blank" title="http://buytaert.net/mollom-gets-a-new-backend"&gt;Mollom gets a new
    backend&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/fd87538b/" rel="nofollow" target="_blank" title="http://blogs.lodgon.com/johan/"&gt;Fighting spam with Mollom on
    Glassfish&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/9c3dc3c9/" rel="nofollow" target="_blank" title="http://mollom.com/api"&gt;Mollom API&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Если Вам понравилась данная статья, можете ознакомиться с другими
&lt;a href="https://www.insight-it.ru/highload/"&gt;материалами по архитектуре высоконагруженных систем&lt;/a&gt; и &lt;a href="/feed/"&gt;подписаться на RSS&lt;/a&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Tue, 15 Feb 2011 19:19:00 +0300</pubDate><guid>tag:www.insight-it.ru,2011-02-15:highload/2011/arkhitektura-mollom/</guid><category>Cassandra</category><category>Drupal</category><category>Glassfish</category><category>Hudson</category><category>Intel</category><category>Java</category><category>Mollom</category><category>Munin</category><category>MySQL</category><category>Pingdom</category><category>saas</category><category>SoftLayer</category><category>Unfuddle</category><category>Xeon</category><category>Zendesk</category><category>Архитектура Mollom</category></item><item><title>Как проект Ravelry дорос до 10 миллионов запросов с помощью Rails</title><link>https://www.insight-it.ru//highload/2009/kak-proekt-ravelry-doros-do-10-millionov-zaprosov-s-pomoshhyu-rails/</link><description>&lt;p&gt;Данная статься основана на замечательном интервью, взятом Tim Bray у
Casey Forbes, создателя &lt;a href="https://www.insight-it.ru/goto/ce0996b1/" rel="nofollow" target="_blank" title="http://www.ravelry.com/"&gt;Ravelry&lt;/a&gt;, сайта на
Ruby on Rails, поддерживаемое сообществом вязальщиц и специалистов по
вышивке крючком численностью более 400000 человек.&lt;/p&gt;
&lt;p&gt;Casey и его небольшой команде удалось реализовать массу великолепных
идей на Ravelry. Этот сайт очень сфокусирован на своей тематике и
представляет собой большую информационную ценность для заинтересованных
лиц. Все пользователи Ravelry просто обожают этот сайт, этот факт
очевиден по их комментариям полным энтузиазма и невероятно быстрому
освоению Ravelry.&lt;/p&gt;
&lt;p&gt;Десять лет назад сайт масштаба Ravelry потребовал бы далеко не один
миллион долларов для поддержания своего функционирования. Сегодня же
Casey является единственным разработчиком Ravelry, а поддержанием
работоспособности системы занимается всего несколько человек.
Изначальный процесс разработки занял у Casey 4 месяца работы по ночам и
выходным. Если Вы взглянете на список технологий, используемых в
Ravelry, Вам станет видно, что проект построен практически полностью на
свободном и бесплатном программном обеспечении, которые просто было
собрано вместе в единую полноценную систему. В сегодняшней экосистеме
существует множество возможностей для того чтобы делать новые вещи
просто комбинируя существующие качественные приложения, языки
программирования, системы хранения, а также услуги по размещению и
предоставлению доступа к веб-приложениям и данным.&lt;/p&gt;
&lt;p&gt;Сейчас Casey и еще несколько сотрудников живут за счет Ravelry. Не это
ли является мечтой любого предприятия малого бизнеса? Хотите узнать как
и Вы могли бы достичь подобных успехов?
&lt;!--more--&gt;
&lt;em&gt;Данный текст является переводом статьи &lt;a href="https://www.insight-it.ru/goto/24572014/" rel="nofollow" target="_blank" title="http://highscalability.com/how-ravelry-scales-10-million-requests-using-rails"&gt;How Ravelry Scales to 10 Million Requests Using Rails&lt;/a&gt;,
автор оригинала - &lt;a href="https://www.insight-it.ru/goto/f3f1b405/" rel="nofollow" target="_blank" title="http://highscalability.com/user/todd-hoff"&gt;Todd Hoff&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id="statistika"&gt;Статистика&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;10 миллионов запросов ежедневно обрабатывается &lt;a href="/tag/rails/"&gt;Rails&lt;/a&gt; (AJAX + RSS + API)&lt;/li&gt;
&lt;li&gt;3.6 миллиона просмотров страниц ежедневно&lt;/li&gt;
&lt;li&gt;430,000 зарегистрированных пользователей. 70,000 активно пользуются
    сайтом ежедневно. 900 новых пользователей регистрируется ежедневно.&lt;/li&gt;
&lt;li&gt;2.3 миллиона проектов по вязанию, 50000 новых сообщений на форуме
    ежедневно, всего 19 миллионов сообщений на форуме, 13 миллионов
    сообщений, 8 миллионов фотографий (большая часть размещена на
    &lt;a href="/tag/flickr/"&gt;Flickr&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Проект начинался на небольшом VPS, но потребности в ресурсах очень
    быстро вышли за его возможности.&lt;/li&gt;
&lt;li&gt;Монетизация: рекламодатели + магазин соответствующей продукции +
    продажа узоров&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="platform"&gt;Platform&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/ruby-on-rails/"&gt;Ruby on Rails&lt;/a&gt; (1.8.6, Ruby GC патчи)&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/percona/"&gt;Percona&lt;/a&gt; сборка &lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/gentoo/"&gt;Gentoo&lt;/a&gt; &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Servers: Silicon Mechanics (не арендуемые, в их собственности)&lt;/li&gt;
&lt;li&gt;Хостинг: Colocation от Hosted Solutions&lt;/li&gt;
&lt;li&gt;Интернет-канал: Cogent (очень дешево)&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/capistrano/"&gt;Capistrano&lt;/a&gt; для развертывания&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/nginx/"&gt;Nginx&lt;/a&gt; существенно более быстрый и менее требовательный к оперативной памяти по сравнению с Apache&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/xen/"&gt;Xen&lt;/a&gt; для виртуализации&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/haproxy/"&gt;HAproxy&lt;/a&gt; для балансировки нагрузки&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/munin/"&gt;Munin&lt;/a&gt; для мониторинга&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/tokyo-cabinet/"&gt;Tokyo Cabinet&lt;/a&gt; / &lt;a href="/tag/tokyo-tyrant/"&gt;Tokyo Tyrant&lt;/a&gt; для кеширования больших объектов&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/nagios/"&gt;Nagios&lt;/a&gt; для предупреждений&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/hoptoad/"&gt;HopToad&lt;/a&gt; для уведомлений об исключительных ситуациях.&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/newrelic/"&gt;NewRelic&lt;/a&gt; для тонкой настройки&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/syslog-ng/"&gt;Syslog-ng&lt;/a&gt; для агрегации логов&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/s3/"&gt;S3&lt;/a&gt; для хранения данных&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/cloudfront/"&gt;Cloudfront&lt;/a&gt; в роли CDN&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/sphinx/"&gt;Sphinx&lt;/a&gt; для текстового поиска&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;Memcached&lt;/a&gt; для кеширования маленьких объектов&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="arkhitektura"&gt;Архитектура&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;7 серверов (Gentoo Linux). Средствами виртуализации (Xen) создано 13
    виртуальных серверов:&lt;ul&gt;
&lt;li&gt;Для обработки пользовательских запросов используются Nginx и
Haproxy. Запросы проходят следущую цепочку: &lt;code&gt;nginx -&amp;gt; haproxy -&amp;gt; apache + mod_passenger&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Один небольшой сервер для резервного копирования данных.&lt;/li&gt;
&lt;li&gt;Один небольшой вспомогательный сервер для некритичных процессов
и тестирования новых версий.&lt;/li&gt;
&lt;li&gt;2 сервера с 32 GB оперативной памяти для master+slave баз
данных, а также поисковой системы Sphinx.&lt;/li&gt;
&lt;li&gt;3 сервера приложений, состоящих из 6 Apache Passenger и
запущенных экземпляров Ruby, каждый ограничен 20-ю потоками.
Суммарно 6 четырехядерных процессоров и 40 GB оперативной памяти.
Часть оперативной памяти большую часть времени простаивает.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;5 терабайт данных располагается в Amazon S3. Cloudfront используется
    как CDN.&lt;/li&gt;
&lt;li&gt;Tokyo Cabinet/Tyrant используется вместо memcached в некоторых
    местах для кеширования более крупных объектов, в частности уже
    размеченного текста в HTML.&lt;/li&gt;
&lt;li&gt;HAproxy и Capistrano используются для вывода новых версий сайта без
    негативного влияния на производительность и работу пользователей.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="podvodim-itogi"&gt;Подводим итоги&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Позвольте своим пользователям работать над Вашим сайтом за Вас&lt;/strong&gt;.
    Проводите итерации и развивайтесь. Начните с чего-то, что просто
    работает, и позвольте людям начать пользоваться продуктом, развивать
    проект совместно с пользователями намного проще. Не торопясь
    развивайте бета-версию своего проекта. Также медленно приглашайте
    новых людей. Старайтесь ежедневно обсуждать с пользователями что бы
    они хотели увидеть нового в проекте. Разрешите им оказывать помощь в
    развитии проекта и результат станет существенно более
    обнадеживающим, утешительным, интуитивно-понятным и эффективным.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Позвольте пользователям спонсировать Ваш проект&lt;/strong&gt;. Ravelry
    частично был создан за счет его пользователей, которые пожертвовали
    в пользу проекта более 71 тысячи долларов. Эти средства были
    переданы проекту просто как дар, а не в обмен на акции. Не
    недооценивайте значимость капитала компании. Ravelry потребовалось 6
    месяцев непрерывной работы и экономии на издержках, связанных с
    серверным оборудованием и каналами связи, чтобы наконец-то начать
    получать прибыль, и полученные от пользователей средства оказались
    основным фактором, позволившим проекту пережить этот тяжелый период.
    Залогом их успеха является поддержание интереса и искры в глазах
    своих пользователей, подталкивание пользователей к оказанию помощи и
    поддержки проекту. Для этого требуется любовь к своему делу и
    самоотдача.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Станьте центром выбранной ниши&lt;/strong&gt;. Найдите нишу на рынке с
    недостаточным предложением. Не стремитесь к массовым рынкам. Совсем
    не обязательно делать что-то для многих миллионов людей. Миллионы
    скорее всего просто зевнут от скуки и в скором времени о Вас
    забудут. Лучше создайте что-нибудь очень полезное для небольшой
    заинтересованной группы лиц и их страсть к их интересам перейдет и к
    Вам.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Успех не обязательно должен быть связан с масштабностью проекта, намного большее значение имеет стабильная и качественная реализация&lt;/strong&gt; &amp;copy; Jeff Putz.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Основная проблема в базе данных&lt;/strong&gt;. Практически вся работа,
    относящаяся к масштабируемости/настройке/производительности, так или
    иначе связана с базой данных. Например, изменение схемы данных для
    больших таблиц в MySQL всегда связано с рядом проблем, особенно если
    простой сервиса неприемлем. Еще один аргумент в пользу баз данных,
    не имеющих схем данных.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Продолжайте получать удовольствие&lt;/strong&gt;. Casey перешел на Ruby on
    Rails так как ему хотелось снова заняться программированием с
    энтузиазмом. Этот факт стал одним из основных факторов, которые
    помогли сделать проект успешным.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Придумывайте новые вещи, которые будут приводить в восторг Ваших
    пользователей&lt;/strong&gt;. Воспользуйтесь магией, людям это нравится. Это тоже
    один из принципов данного проекта. Например по этой
    &lt;a href="https://www.insight-it.ru/goto/e231d34/" rel="nofollow" target="_blank" title="http://www.tbray.org/ongoing/When/200x/2009/09/02/Ravelry#c1252474782.65559"&gt;ссылке&lt;/a&gt;, можно почитать об использовании очень инновационных подходов к управлению форумами.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ruby &amp;mdash; это круто&lt;/strong&gt;. Он представляет собой интересный язык
    программирования, позволивший Ravelry быстро пройти стадию
    изначальной разработки и выпускать новые версии дважды в день в
    период бета-тестирования.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Получайте большую прибыль за счет минимизации издержек&lt;/strong&gt;. У
    Ravelry есть свой магазин с соответствующей тематике продукцией,
    оптовые счета, принтеры и реализующая компания. Это позволяет им
    поддерживать издержки на низком уровне, таким образом их прибыль не
    уходит сторонним компаниям вроде CafePress.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Наиболее сложный переход заключается в переходе от одного сервера к нескольким&lt;/strong&gt;. В этом процессе все меняется и становится более
    сложным и комплексным. Всегда имейте этот переход ввиду, когда
    планируете архитектуру веб-приложения.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;В сегодняшней экосистеме имеется возможность делать массу различных вещей даже обладая минимумом ресурсов&lt;/strong&gt;. Для создания
    комплексного сайта вроде Ravelry больше не нужно много людей или
    финансов. Взгляните на список различных программ, используемых в
    Ravelry, а также на небольшое количество людей, работающих над
    поддержанием работы проекта.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Некоторые люди могут жаловаться, что здесь нет практически никаких
подробностей о том, как же все таки работает Ravelry. Сайты таких
размеров не должны иметь развернутого описания мистического процесса его
масштабирования, такие проекты могут быть построены просто из составных
частей, с умом собранных вместе. И это очень здорово.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Thu, 24 Sep 2009 11:31:00 +0400</pubDate><guid>tag:www.insight-it.ru,2009-09-24:highload/2009/kak-proekt-ravelry-doros-do-10-millionov-zaprosov-s-pomoshhyu-rails/</guid><category>Ravelry</category><category>Ruby</category><category>Rails</category><category>Ruby on Rails</category><category>Percona</category><category>MySQL</category><category>Gentoo</category><category>Linux</category><category>Capistrano</category><category>nginx</category><category>HAProxy</category><category>Munin</category><category>Tokyo Cabinet</category><category>Tokyo Tyrant</category><category>Xen</category><category>Nagios</category><category>HopToad</category><category>NewRelic</category><category>syslog-ng</category><category>Cloudfront</category><category>S3</category><category>Sphinx</category><category>memcached</category></item><item><title>Архитектура Twitter</title><link>https://www.insight-it.ru//highload/2008/arkhitektura-twitter/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/c2919313/" rel="nofollow" target="_blank" title="https://www.twitter.com"&gt;Twitter&lt;/a&gt; стартовал как побочный подпроект, но
не смотря на это темпы его роста были впечатляющими: путь от 0 до
миллионов просмотров страниц занял всего несколько коротких месяцев.
Ранние решения о проектировании системы неплохо справлялись с небольшими
нагрузками, но они быстро таяли под напором огромного количества
пользователей, желающих разослать весточки всем своим друзьям с ответом
на простой вопрос: а чем ты занимаешься?&lt;/p&gt;
&lt;p&gt;Поначалу все винили &lt;a href="/tag/ror/"&gt;Ruby on Rails&lt;/a&gt; во всех проблемах с
масштабированием, но Blaine Cook, главный архитектор Twitter, встал на
его защиту:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Основной для нас на самом деле является проблема горизонтального
масштабирования, с этой точки зрения &lt;a href="/tag/ror/"&gt;Ruby on Rails&lt;/a&gt; ничем
не хуже других языков программирования или framework'ов: переход на
"более быстрый" язык программирования дал бы нам 10-20% прирост
производительности, в то время архитектурные преобразования, легко
реализованные средствами &lt;a href="/tag/ror/"&gt;Ruby on Rails&lt;/a&gt;, сделали Twitter
быстрее на 10000%.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Даже если &lt;a href="/tag/ror/"&gt;Ruby on Rails&lt;/a&gt; оказался невиновен, как же тогда
Twitter научился с его помощью рости до все больших и больших высот?
&lt;!--more--&gt;&lt;/p&gt;
&lt;h3 id="istochniki-informatsii"&gt;Источники информации&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Этот текст является продолжением &lt;a href="https://www.insight-it.ru/highload/"&gt;серии переводов&lt;/a&gt;, автор
&lt;a href="https://www.insight-it.ru/goto/9736f7f8/" rel="nofollow" target="_blank" title="http://highscalability.com/scaling-twitter-making-twitter-10000-percent-faster"&gt;оригинала&lt;/a&gt; -
Todd Hoff. На этот раз написать что-либо своими силами у меня не
сложилось, все мысли ушли на другой пост, который я скоро опубликую, а
перевод этот получился несколько менее строгим, чем обычно, но я думаю
ничего страшного.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/1a76cc37/" rel="nofollow" target="_blank" title="http://video.google.com/videoplay?docid=-7846959339830379167"&gt;Scaling Twitter Video&lt;/a&gt;
    от Blaine Cook.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/a004222e/" rel="nofollow" target="_blank" title="http://www.slideshare.net/Blaine/scaling-twitter"&gt;Scaling Twitter Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/7541c4c6/" rel="nofollow" target="_blank" title="http://talklikeaduck.denhaven2.com/articles/2007/06/22/good-news"&gt;Good News&lt;/a&gt;
    блог пост от Rick Denatale&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/96735c2c/" rel="nofollow" target="_blank" title="http://pragmati.st/2007/5/20/scaling-twitter"&gt;Scaling Twitter&lt;/a&gt; блог
    пост от Patrick Joyce&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/7267856d/" rel="nofollow" target="_blank" title="http://readwritetalk.com/2007/09/05/biz-stone-co-founder-twitter/"&gt;Twitter API Traffic is 10x Twitter&amp;rsquo;s Site&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/5eb63819/" rel="nofollow" target="_blank" title="http://www.slideshare.net/britt/a-small-talk-on-getting-big-113066"&gt;A Small Talk on Getting Big. Scaling a Rails App &amp;amp; all that Jazz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="platforma"&gt;Платформа&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/ruby-on-rails/"&gt;Ruby on Rails&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/erlang/"&gt;Erlang&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mongrel/"&gt;Mongrel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/munin/"&gt;Munin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/nagios/"&gt;Nagios&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/google-analytics/"&gt;Google Analytics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/awstats/"&gt;AWStats&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;Memcached&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="statistika"&gt;Статистика&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Более 350000 пользователей. Точная цифра, как обычно, держится в
    секрете.&lt;/li&gt;
&lt;li&gt;Около 600 запросов в секунду.&lt;/li&gt;
&lt;li&gt;В среднем система поддерживает 200-300 соединений в секунду.
    Максимум обычно достигается при значении 800.&lt;/li&gt;
&lt;li&gt;MySQL обрабатывает примерно 2400 запросов в секунду.&lt;/li&gt;
&lt;li&gt;180 экземпляров приложений на Rails, использующих Mongrel как
    веб-сервер.&lt;/li&gt;
&lt;li&gt;1 MySQL сервер (одна большая машина с 8 ядрами) и 1 slave,
    используемый лишь для статистики и отчетов.&lt;/li&gt;
&lt;li&gt;30+ процессов для выполнения произвольных работ.&lt;/li&gt;
&lt;li&gt;8 Sun X4100&lt;/li&gt;
&lt;li&gt;Обработка запроса обычно занимает у Rails 200 миллисекунд.&lt;/li&gt;
&lt;li&gt;В среднем ответ на запрос к базе данных занимает 50-100 миллисекунд.&lt;/li&gt;
&lt;li&gt;Более 16 GB выделено под &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="arkhitektura"&gt;Архитектура&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Проект столкнулся с массой проблем, связанных с масштабируемостью.
    Маленькая птичка частенько давала сбои.&lt;/li&gt;
&lt;li&gt;Изначально не было реализовано никаких форм мониторинга, графиков
    или статистики, это очень затрудняло обнаружение м решение
    возникающих проблем. Впоследствии были внедрены &lt;a href="/tag/munin/"&gt;Munin&lt;/a&gt;
    и &lt;a href="/tag/nagios/"&gt;Nagios&lt;/a&gt;. Разработчики столкнулись с некоторыми
    трудностями при использовании этих продуктов в
    &lt;a href="/tag/solaris/"&gt;Solaris&lt;/a&gt;. Помимо этого был использован сервис Google
    Analytics, но от него обычно мало толку, особенно когда страницы
    даже не загружаются.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Активное использование кэширования средствами &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Например, если подсчет количества чего-либо выполняется медленно,
намного эффективнее один раз запомнить результат в
&lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, чем каждый раз считать его заново.&lt;/li&gt;
&lt;li&gt;Получение информации о статусе своих друзей - непростая задача.
Вместо использования запросов информация о статусе друзей
обновляется в кэше. База данных совсем не используется. Такой подход
позволяет получить предсказуемое время отклика (ограниченное сверху примерно 20 миллисекундами).&lt;/li&gt;
&lt;li&gt;Объекты ActiveRecord настолько велики, что кэширование их
нецелесообразно. Критичные атрибуты хранятся в хэше, а остальная их часть подвергается "ленивой загрузке" в момент запроса на доступ.&lt;/li&gt;
&lt;li&gt;90% запросов являются запросами к API. Таким образом кэширование
страниц или их фрагментов становится бессмысленным, зато никто не мешает им кэшировать сами API запросы.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Внутренняя организация работы с сообщениями:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Сообщения очень активно используются: производители генерируют
сообщения, они образуются в очереди, а затем распространяются по
потребителем.&lt;/li&gt;
&lt;li&gt;Основная функция Twitter заключается в реализации
своеобразного моста между различными форматами электронных сообщений
(SMS, электронная почта, сервисы мгновенного обмена сообщениями и так далее).&lt;/li&gt;
&lt;li&gt;Чтобы инвалидировать в кэше информацию можно просто отправить внутреннее сообщение, зачем выполнять все действия синхронно?&lt;/li&gt;
&lt;li&gt;Изначально этот механизм основывался на DRb (distributed Ruby) -
библиотека, позволяющая отправлять и принимать сообщения сообщения
между удаленными Ruby-объектами по TCP/IP. Но она была несколько
странноватой, да и являлось потенциально слабым местом с точки зрения стабильности.&lt;/li&gt;
&lt;li&gt;Со временем сервис перевели на Rinda, представляющую собой набор
общих для всей системы очередей. Но и у нее были недостатки: все очереди были постоянными, а данные терялись при сбоях.&lt;/li&gt;
&lt;li&gt;Следующей попыткой был Erlang. Но однажды возникла проблема: каким
образом сломавшийся сервер может продолжать работать, но при этом в
очереди откуда-то возникли целых 20000 ожидающих пользователей? Разработчики не знали. На лицо явный недостаток документации...&lt;/li&gt;
&lt;li&gt;В конце концов решение было разработано своими силами: Twitter
выпустил &lt;a href="/tag/starling/"&gt;Starling&lt;/a&gt;, распределенный легковесный
сервер очередей, написанный на Ruby и поддерживающий протокол memcache. Сейчас серверная часть Twitter управляется именно им.&lt;/li&gt;
&lt;li&gt;Распределенные очереди позволяют переживать сбои путем записи их
на диск в критических ситуациях. Другие крупные интернет-проекты также часто пользуются таким подходом.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Работа с SMS осуществляется с помощью сторонних сервисов и
    предоставляемых ими шлюзов. Достаточно дорогое удовольствие.&lt;/li&gt;
&lt;li&gt;Развертывание:&lt;ul&gt;
&lt;li&gt;Просто запускаются дополнительные сервера с mongrel, более элегантного решения пока нет.&lt;/li&gt;
&lt;li&gt;Все внутренние ошибки выдаются пользователям, если обслуживающий
их mongrel сервер на данный момент заменяется.&lt;/li&gt;
&lt;li&gt;Все сервера останавливаются одновременно. Отключение их по одному
по определенным причинам не используется.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Неправильное использование сервиса:&lt;ul&gt;
&lt;li&gt;Много времени сервис был не доступен, так как люди проходились
специальными программами по сайту с целью добавить всех кто
попадался под руку в друзья. 9000 друзей за 24 часа. Это
просто-напросто останавливало работу сайта.&lt;/li&gt;
&lt;li&gt;Были разработаны средства для своевременного обнаружения таких
ситуаций.&lt;/li&gt;
&lt;li&gt;Будте беспощадными, таких пользователей нужно просто удалять.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Сегментирование:&lt;ul&gt;
&lt;li&gt;Пока оно только в планах, сейчас оно не используется.&lt;/li&gt;
&lt;li&gt;В будущем оно будет основываться на времени, а не на
пользователях, так как запросы обычно очень локальны по времени.&lt;/li&gt;
&lt;li&gt;Сегментирование будет не так просто реализовать благодаря
автоматическому запоминанию результатов выполнения функций для
последующего повторного их использования. Никто не даст гарантии,
что операции "только для чтения" на самом деле будут таковыми
являться. Запись в slave, работающий в режиме read-only, - не самая
лучшая идея.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API Twitter генерирует в 10 раз больше трафика, чем сам сайт.&lt;ul&gt;
&lt;li&gt;Их API - самая важная вещь из всех, что они разработали.&lt;/li&gt;
&lt;li&gt;Простота сервиса позволила разработчикам строить свои приложения
поверх инфраструктуры Twitter, привнося все новые и новые идеи.
Например, Twitterrific - красивый способ использовать Twitter в
небольшой команде.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Мониторинг используется для остановки слишком больших процессов.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="podvodim-itogi"&gt;Подводим итоги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Общайтесь со своим сообществом. Не прячьтесь и не пытайтесь решить
    абсолютно все проблемы самостоятельно. Много отличных людей будут
    готовы помочь, достаточно лишь попросить.&lt;/li&gt;
&lt;li&gt;Рассматривайте вашу стратегию масштабирования как бизнес-план.
    Соберите советы помощников для того чтобы облегчить для себя
    принятие решений.&lt;/li&gt;
&lt;li&gt;Стройте свой проект сами. Twitter потратил много времени, пытаясь
    приспособить готовые решения других людей, которые казалось бы
    должны работать, но это оказалось не совсем так. Лучше построить
    какие-то вещи самостоятельно, чтобы иметь высокую степень контроля
    над ситуацией и иметь возможность привносить новые возможности как
    только они понадобились.&lt;/li&gt;
&lt;li&gt;Ставьте перед своими пользователями разумные ограничения. На обычных
    пользователей это не повлияет, но когда кому-нибудь взбредет в
    голову попытаться сломать систему (а такой человек рано или поздно
    найдется) - они сыграют свою роль и спасут работоспособность
    системы.&lt;/li&gt;
&lt;li&gt;Не делайте базу данных центральным узким местом системы, врядли Ваше
    приложение на самом деле требует гигантских операций по объединению
    данных из нескольких таблиц. Используйте кэширование, или проявите
    свою смекалку для поиска альтернативных способов достижения того же
    результата.&lt;/li&gt;
&lt;li&gt;Предусмотрите возможность сегментирования с самого начала, тогда
    перед Вами всегда будут открыты пути для дальнейшего
    масштабирования.&lt;/li&gt;
&lt;li&gt;Очень важно вовремя осознать, что сайт начинает работать медленно.
    Сразу стоит задуматься о системе отчетов для отслеживания
    потенциальных проблем.&lt;/li&gt;
&lt;li&gt;Оптимизируйте базу данных:&lt;ul&gt;
&lt;li&gt;Индексируйте все таблицы, Rails не будет делать это за Вас.&lt;/li&gt;
&lt;li&gt;Используйте "explain" для анализа выполнения запросов. Результаты
могут не совпадать с Вашими ожиданиями.&lt;/li&gt;
&lt;li&gt;Денормализуйте данные. Один только этот совет порой может спасти
ситуацию. Для примера, в Twitter хранят все ID друзей каждого
пользователя вместе, это позволило избежать многих ресурсоемких
запросов.&lt;/li&gt;
&lt;li&gt;Избегайте комплексного объединения данных из нескольких таблиц.&lt;/li&gt;
&lt;li&gt;Избегайте сканирования больших наборов данных.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Кэшируйте все, что только можно.&lt;/li&gt;
&lt;li&gt;Тестируйте все максимально тщательно:&lt;ul&gt;
&lt;li&gt;Когда Вы развертываете приложение, Вы должно быть уверены, что оно
будет работать корректно.&lt;/li&gt;
&lt;li&gt;Они используют полный набор средств для тестирования. Таким
образом, когда произошла неполадка в кэшировании, они узнали о ней
еще до того как она на самом деле произошла.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Длительно функционирующие процессы стоит оформить в виде daemon'ов.&lt;/li&gt;
&lt;li&gt;Используйте уведомления об исключительных ситуациях в совокупности с
    ведением логов, это необходимо для своевременного реагирования на
    них.&lt;/li&gt;
&lt;li&gt;Не делайте глупостей!&lt;ul&gt;
&lt;li&gt;Масштаб проект несколько меняет понятие "глупость".&lt;/li&gt;
&lt;li&gt;Пытаться загрузить 3000 друзей в память одновременно может
заставить сервер временно перестать функционировать, хотя когда
друзей было всего 4 - этот механизм прекрасно работал.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Большая часть производительности зависит не от использованного языка
    программирования, а от продуманной структуры приложения.&lt;/li&gt;
&lt;li&gt;Превратите свой сайт в открытый сервис с помощью создания API. Их
    API является ключом к успеху Twitter. Он позволяет пользователям
    создавать постоянно расширяющуюся экосистему вокруг Twitter,
    соревноваться с которой не так-то просто. Вы никогда не сможете
    сделать столько же работы, сколько смогут Ваши пользователи для Вас,
    Вам просто не хватит креативных идей. Так что не стесняйтесь,
    откройте свое приложение и сделайте интеграцию Вашего приложения с
    другими максимально простой и удобной!&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sat, 10 May 2008 12:36:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-05-10:highload/2008/arkhitektura-twitter/</guid><category>AWStats</category><category>Erlang</category><category>Google Analytics</category><category>Memcached</category><category>mongrel</category><category>Munin</category><category>MySQL</category><category>Nagios</category><category>Ruby on Rails</category><category>Solaris</category><category>Starling</category><category>Twitter</category><category>архитектура</category><category>архитектура Twitter</category></item></channel></rss>
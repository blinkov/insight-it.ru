<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/robots-exclusion-protocol/feed/index.xml" rel="self"></atom:link><lastBuildDate>Fri, 18 Jan 2008 01:13:00 +0300</lastBuildDate><item><title>Путеводитель для роботов</title><link>https://www.insight-it.ru//theory/2008/putevoditel-dlya-robotov/</link><description>&lt;p&gt;Ни для кого не секрет, что одним их основных факторов, влияющих на
расположение страниц интернет-ресурса на просторах поисковых систем,
является уникальность контента (или другими словами - содержания).
Конечно же простейшим способом избежать дублирующегося контента является
просто собственноручная его генерация (или в крайнем случае с помощью
наемных работников или посетителей Вашего сайта). Но, к сожалению, это
позволяет избежать лишь повторов между разными сайтами. Помимо этого
свою роль играют и повторы в рамках одного сайта. Наверняка Вы замечали,
что многие CMS размещают один и тот же текст на разных страницах сайта:
например на обычной странице, в RSS-ленте и каком-нибудь архиве.&lt;/p&gt;
&lt;p&gt;Именно для решения этой маленькой проблемы и была создана технология под
названием &lt;strong&gt;Robots Exclusion Protocol&lt;/strong&gt;. С ее помощью можно
минимизировать возможность повторов содержимого, проиндексированного
поисковыми системами в рамках одного сайта, а также исключить из индекса
неинформативные страницы.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Надеюсь, что Вы представляете себе в чем заключается принцип работы
поисковых систем, но в любом случае не вижу причин для того чтобы не
рассказать вкратце об этом. Помимо собственно сайта, где пользователи
вводят ключевую фразу для поиска, любая поисковая система имеет еще две
части: базу данных (другими словами - индекс сайтов) и специальной
программы (которую чаще всего называют &lt;em&gt;пауком&lt;/em&gt; или по-английски -
&lt;em&gt;crawler&lt;/em&gt; или &lt;em&gt;spider&lt;/em&gt;, но иногда используется более общий термин -
&lt;em&gt;робот&lt;/em&gt;). Эта программа запущена на серверах поисковых систем во
множестве экземпляров и основной целью их работы является пополнение и
обновления индекса поисковой системы. Сам же сайт лишь делает выборку из
индекса в соответствии с запросом и сортирует результат.&lt;/p&gt;
&lt;p&gt;Принцип работы такого класса программ я уже упоминал в &lt;a href="https://www.insight-it.ru/security/2008/otkuda-voznikaet-spam-i-kak-s-nim-borotsya/" title="Откуда возникает спам и как с ним бороться"&gt;записи о борьбе со спамом&lt;/a&gt;,
так что повторюсь лишь вкратце в надежде, что Вы ее уже читали: они
перемещаются по просторам Сети следуя по гиперссылкам, и на каждой
странице, куда они попадают, стараются выполнить заранее определенное
действие, в нашем случае - проиндексировать ее.&lt;/p&gt;
&lt;p&gt;Обсуждаемая нами технология дает возможность веб-мастеру предоставить
crawler'ам, образно говоря, &lt;em&gt;путеводитель&lt;/em&gt; по его сайту. Методов для
этого имеется несколько:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Любой crawler прежде чем перейти на новый домен проверяет
    существование файла по адресу &lt;code&gt;http://www.некий-домен.ru/robots.txt&lt;/code&gt;.
    В таком файле веб-мастер может разместить директивы для
    потенциальных компьютеризированных посетителей в соответствии с
    &lt;a href="https://www.insight-it.ru/goto/32ecd79a/" rel="nofollow" target="_blank" title="http://www.robotstxt.org/norobots-rfc.txt"&gt;соответствующим стандартом&lt;/a&gt;. Если поисковый робот обнаруживает этот файл, то прочитав его он
    корректирует свой маршрут обхода всего интернет-ресурса в
    соответствии с указанными директивами.&lt;/li&gt;
&lt;li&gt;Внутри заголовка любой HTML-страницы или любого другого документа,
    передаваемого по http протоколу (с помощью заголовков самого
    протокола), можно разместить специальный meta-tag для роботов,
    который также должен соответствовать &lt;a href="https://www.insight-it.ru/goto/fef0ecbb/" rel="nofollow" target="_blank" title="http://www.robotstxt.org/meta.html"&gt;стандарту, опубликованному в 1996 году&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Основной частью &lt;em&gt;путеводителя&lt;/em&gt; чаще всего является карта &lt;a href="https://www.insight-it.ru/goto/9821991b/" rel="nofollow" target="_blank" title="http://sitemaps.org/"&gt;сайта в формате XML&lt;/a&gt;. С ее помощью программа может
    быстро определить весь ассортимент страниц, которые ей было бы
    неплохо проиндексировать.&lt;/li&gt;
&lt;li&gt;Самым последним был воплощен в жизнь метод, основанный на
    &lt;a href="https://www.insight-it.ru/goto/a9b68873/" rel="nofollow" target="_blank" title="http://microformats.org/wiki/rel-nofollow"&gt;микроформатах&lt;/a&gt;.
    Реализуется он с помощью параметра &lt;code&gt;rel="nofollow"&lt;/code&gt;, указанного
    внутри тэга &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;, который обозначает ссылку, не предназначенную для
    перехода по ней пауком.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Карты сайтов и директивы robots.txt предназначены для определения
маршрута путешествия crawler'а, в то время как микроформаты и
meta-тэги - для влияния на сам процесс индексации.&lt;/p&gt;
&lt;p&gt;У каждого из описанных выше методов есть своя узкая специализация:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;robots.txt предоставляет базовый набор директив для роботов, которым
    они следуют даже в случае конфликтов с другими использованными
    методами.&lt;/li&gt;
&lt;li&gt;Карта сайта влияет на последовательность и набор страниц, посещенных
    пауком, с помощью указания приоритетов страниц или времени последней
    модификации.&lt;/li&gt;
&lt;li&gt;Мета-тэги распространяют свое действие на весь документ и влияет на
    индексирование страниц (если они одновременно присутствуют как в
    заголовке (X)HTML документа, так и в заголовках &lt;code&gt;X-Robots-Tags&lt;/code&gt;
    HTTP-протокола, то приоритет считается выше у заголовков протокола).&lt;/li&gt;
&lt;li&gt;Микроформаты позволяют в случае необходимости переопределять
    параметры любого конкретного тэга документа, не смотря на указания в
    мета-тэгах.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;С синтаксисом robots.txt лучше всего ознакомиться прямо в
соответствующей спецификации, ссылку на которую я уже приводил (хотя
возможно в будущем я всетаки соберусь написать запись и по этому
поводу). Не знаю занимается ли кто-нибудь генерацией карт сайта вручную,
но для общего развития будет полезно изучить и ее формат, неплохим
примером может послужить &lt;a href="/sitemap.xml" title="XML Sitemap"&gt;XML-карта этого блога&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 18 Jan 2008 01:13:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-01-18:theory/2008/putevoditel-dlya-robotov/</guid><category>crawler</category><category>robots exclusion protocol</category><category>robots.txt</category><category>SEO</category><category>spider</category><category>интернет</category><category>информационные технологии</category><category>поисковые системы</category><category>принцип работы поисковых систем</category><category>технология</category></item></channel></rss>
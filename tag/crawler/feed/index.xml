<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/crawler/feed/index.xml" rel="self"></atom:link><lastBuildDate>Sun, 24 Feb 2008 16:51:00 +0300</lastBuildDate><item><title>nofollow: за и против</title><link>https://www.insight-it.ru//theory/2008/nofollow-za-i-protiv/</link><description>&lt;p&gt;Наверняка каждый владелец любого интернет-ресурса хоть раз сталкивался с
этим микроформатом, &lt;a href="https://www.insight-it.ru/goto/a9b68873/" rel="nofollow" target="_blank" title="http://microformats.org/wiki/rel-nofollow"&gt;rel-nofollow&lt;/a&gt;. Изначально он был введен для обозначения ссылок, оставленных кем-либо, кроме создателя самой веб-страницы, и, как следствие. для снятие с него ответственности
за эту ссылку. Активнее всего этот микроформат влияет на работу
большинства поисковых систем, оказывая влияние на учет ссылок в
определении тех или иных параметров, присваиваемых страницам (Google
PageRank, например). В общем случае ссылки, помеченные атрибутом
&lt;code&gt;rel="nofollow"&lt;/code&gt;, из этого процесса исключаются.
&lt;!--more--&gt;
Но не все так однозначно, насчет этого микроформата сложилось масса
мнений, так как несмотря на свое, казалось бы, предназначение бороться
со спамом на форумах / блогах / социальных сетях / новостных порталах
(нужное подчеркнуть), направленным на создание входящих ссылок на тот
или иной ресурс, порой им злоупотребляют и используют там, где это было
бы излишним.&lt;/p&gt;
&lt;h3 id="protiv"&gt;Против&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;nofollow не в состоянии полностью предотвратить спам в ресурсах
    указанных выше типов;&lt;/li&gt;
&lt;li&gt;название "nofollow" лишь сбивает с толку, &lt;a href="/tag/crawler/"&gt;crawler&lt;/a&gt;'ы
    все равно следуют по таким ссылкам;&lt;/li&gt;
&lt;li&gt;nofollow порой вредит &lt;em&gt;естественным&lt;/em&gt; ссылкам на сайты, которые
    вполне заслуженно могли бы и получить свою входящую ссылку при
    расчете того же, например, PageRank;&lt;/li&gt;
&lt;li&gt;для использования простыми пользователями, этот микроформат
    абсолютно бесполезен;&lt;/li&gt;
&lt;li&gt;благодаря nofollow поисковые системы порой не в состоянии отличить
    ссылки на сайты добросовестных читателей ресурса от ссылок
    спаммеров;&lt;/li&gt;
&lt;li&gt;он препятствует возможности людей, оставляющих комментарии, привлечь
    внимание к какой-либо странице;&lt;/li&gt;
&lt;li&gt;если взглянуть со стороны поисковых систем, nofollow препятствует
    Сети выглядеть как сеть, в прямом смысле этого слова;&lt;/li&gt;
&lt;li&gt;единственные кто получают какую-либо пользу от этого микроформата -
    поисковые системы.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="za"&gt;За&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;но тем не менее, если ссылка размещается посетителем только ради
    влияния на позицию своего ресурса в поисковых системах, наличие
    &lt;code&gt;nofollow&lt;/code&gt; заставит его как минимум задуматься: а стоит ли?&lt;/li&gt;
&lt;li&gt;помимо поисковых систем, данный микроформат может служить
    инструментом вебмастера для организации более эффективной
    перелинковки страниц в рамках одного сайта;&lt;/li&gt;
&lt;li&gt;в недалеком будущем, возможно, движки сайтов смогут ставить атрибут
    &lt;code&gt;nofollow&lt;/code&gt; не на всех подряд ссылках, оставленных посетителями, а
    только на подозрительных с их точки зрения (которая могла бы
    определяться, допустим, средствами эвристического анализа);&lt;/li&gt;
&lt;li&gt;так как oформлен он в виде &lt;a href="/tag/mikroformaty/"&gt;микроформата&lt;/a&gt;, он не
    противоречит стандартам &lt;a href="/tag/xhtml/"&gt;XHTML&lt;/a&gt; и &lt;a href="/tag/html/"&gt;HTML&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Не смотря на множество спорных моментов, этот микроформат определенно
имеет свою скромную роль в жизни Сети. Использовать его или нет - дело
каждого, но по-моему если применять его в меру и только по прямому
назначению, то он только несомненно помогает развитию как Сети в целом,
так и конкретного ресурса в отдельности, особенно с точки зрения
эффективности взаимодействия с поисковыми системами.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sun, 24 Feb 2008 16:51:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-02-24:theory/2008/nofollow-za-i-protiv/</guid><category>crawler</category><category>nofollow</category><category>rel-nofollow</category><category>SEO</category><category>spider</category><category>Микроформаты</category><category>поисковые системы</category><category>принцип работы поисковых систем</category></item><item><title>Путеводитель для роботов</title><link>https://www.insight-it.ru//theory/2008/putevoditel-dlya-robotov/</link><description>&lt;p&gt;Ни для кого не секрет, что одним их основных факторов, влияющих на
расположение страниц интернет-ресурса на просторах поисковых систем,
является уникальность контента (или другими словами - содержания).
Конечно же простейшим способом избежать дублирующегося контента является
просто собственноручная его генерация (или в крайнем случае с помощью
наемных работников или посетителей Вашего сайта). Но, к сожалению, это
позволяет избежать лишь повторов между разными сайтами. Помимо этого
свою роль играют и повторы в рамках одного сайта. Наверняка Вы замечали,
что многие CMS размещают один и тот же текст на разных страницах сайта:
например на обычной странице, в RSS-ленте и каком-нибудь архиве.&lt;/p&gt;
&lt;p&gt;Именно для решения этой маленькой проблемы и была создана технология под
названием &lt;strong&gt;Robots Exclusion Protocol&lt;/strong&gt;. С ее помощью можно
минимизировать возможность повторов содержимого, проиндексированного
поисковыми системами в рамках одного сайта, а также исключить из индекса
неинформативные страницы.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Надеюсь, что Вы представляете себе в чем заключается принцип работы
поисковых систем, но в любом случае не вижу причин для того чтобы не
рассказать вкратце об этом. Помимо собственно сайта, где пользователи
вводят ключевую фразу для поиска, любая поисковая система имеет еще две
части: базу данных (другими словами - индекс сайтов) и специальной
программы (которую чаще всего называют &lt;em&gt;пауком&lt;/em&gt; или по-английски -
&lt;em&gt;crawler&lt;/em&gt; или &lt;em&gt;spider&lt;/em&gt;, но иногда используется более общий термин -
&lt;em&gt;робот&lt;/em&gt;). Эта программа запущена на серверах поисковых систем во
множестве экземпляров и основной целью их работы является пополнение и
обновления индекса поисковой системы. Сам же сайт лишь делает выборку из
индекса в соответствии с запросом и сортирует результат.&lt;/p&gt;
&lt;p&gt;Принцип работы такого класса программ я уже упоминал в &lt;a href="https://www.insight-it.ru/security/2008/otkuda-voznikaet-spam-i-kak-s-nim-borotsya/" title="Откуда возникает спам и как с ним бороться"&gt;записи о борьбе со спамом&lt;/a&gt;,
так что повторюсь лишь вкратце в надежде, что Вы ее уже читали: они
перемещаются по просторам Сети следуя по гиперссылкам, и на каждой
странице, куда они попадают, стараются выполнить заранее определенное
действие, в нашем случае - проиндексировать ее.&lt;/p&gt;
&lt;p&gt;Обсуждаемая нами технология дает возможность веб-мастеру предоставить
crawler'ам, образно говоря, &lt;em&gt;путеводитель&lt;/em&gt; по его сайту. Методов для
этого имеется несколько:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Любой crawler прежде чем перейти на новый домен проверяет
    существование файла по адресу &lt;code&gt;http://www.некий-домен.ru/robots.txt&lt;/code&gt;.
    В таком файле веб-мастер может разместить директивы для
    потенциальных компьютеризированных посетителей в соответствии с
    &lt;a href="https://www.insight-it.ru/goto/32ecd79a/" rel="nofollow" target="_blank" title="http://www.robotstxt.org/norobots-rfc.txt"&gt;соответствующим стандартом&lt;/a&gt;. Если поисковый робот обнаруживает этот файл, то прочитав его он
    корректирует свой маршрут обхода всего интернет-ресурса в
    соответствии с указанными директивами.&lt;/li&gt;
&lt;li&gt;Внутри заголовка любой HTML-страницы или любого другого документа,
    передаваемого по http протоколу (с помощью заголовков самого
    протокола), можно разместить специальный meta-tag для роботов,
    который также должен соответствовать &lt;a href="https://www.insight-it.ru/goto/fef0ecbb/" rel="nofollow" target="_blank" title="http://www.robotstxt.org/meta.html"&gt;стандарту, опубликованному в 1996 году&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Основной частью &lt;em&gt;путеводителя&lt;/em&gt; чаще всего является карта &lt;a href="https://www.insight-it.ru/goto/9821991b/" rel="nofollow" target="_blank" title="http://sitemaps.org/"&gt;сайта в формате XML&lt;/a&gt;. С ее помощью программа может
    быстро определить весь ассортимент страниц, которые ей было бы
    неплохо проиндексировать.&lt;/li&gt;
&lt;li&gt;Самым последним был воплощен в жизнь метод, основанный на
    &lt;a href="https://www.insight-it.ru/goto/a9b68873/" rel="nofollow" target="_blank" title="http://microformats.org/wiki/rel-nofollow"&gt;микроформатах&lt;/a&gt;.
    Реализуется он с помощью параметра &lt;code&gt;rel="nofollow"&lt;/code&gt;, указанного
    внутри тэга &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;, который обозначает ссылку, не предназначенную для
    перехода по ней пауком.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Карты сайтов и директивы robots.txt предназначены для определения
маршрута путешествия crawler'а, в то время как микроформаты и
meta-тэги - для влияния на сам процесс индексации.&lt;/p&gt;
&lt;p&gt;У каждого из описанных выше методов есть своя узкая специализация:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;robots.txt предоставляет базовый набор директив для роботов, которым
    они следуют даже в случае конфликтов с другими использованными
    методами.&lt;/li&gt;
&lt;li&gt;Карта сайта влияет на последовательность и набор страниц, посещенных
    пауком, с помощью указания приоритетов страниц или времени последней
    модификации.&lt;/li&gt;
&lt;li&gt;Мета-тэги распространяют свое действие на весь документ и влияет на
    индексирование страниц (если они одновременно присутствуют как в
    заголовке (X)HTML документа, так и в заголовках &lt;code&gt;X-Robots-Tags&lt;/code&gt;
    HTTP-протокола, то приоритет считается выше у заголовков протокола).&lt;/li&gt;
&lt;li&gt;Микроформаты позволяют в случае необходимости переопределять
    параметры любого конкретного тэга документа, не смотря на указания в
    мета-тэгах.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;С синтаксисом robots.txt лучше всего ознакомиться прямо в
соответствующей спецификации, ссылку на которую я уже приводил (хотя
возможно в будущем я всетаки соберусь написать запись и по этому
поводу). Не знаю занимается ли кто-нибудь генерацией карт сайта вручную,
но для общего развития будет полезно изучить и ее формат, неплохим
примером может послужить &lt;a href="/sitemap.xml" title="XML Sitemap"&gt;XML-карта этого блога&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 18 Jan 2008 01:13:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-01-18:theory/2008/putevoditel-dlya-robotov/</guid><category>crawler</category><category>robots exclusion protocol</category><category>robots.txt</category><category>SEO</category><category>spider</category><category>интернет</category><category>информационные технологии</category><category>поисковые системы</category><category>принцип работы поисковых систем</category><category>технология</category></item><item><title>Откуда возникает спам и как с ним бороться</title><link>https://www.insight-it.ru//security/2008/otkuda-voznikaet-spam-i-kak-s-nim-borotsya/</link><description>&lt;p&gt;На сегодняшний день далеко не каждый пользователь &lt;a href="/net"&gt;Сети&lt;/a&gt; является
человеком, возможно это покажется странным для не интересующегося ИТ
читателя, но существует множество программ, способных передвигаться по
сайтам, следуя по гипер-ссылкам, как внутри одного сайта, так и переходя
с одного сайта на другой (в целом такой тип программ называется
&lt;a href="/tag/spider/"&gt;spider&lt;/a&gt; или &lt;a href="/tag/crawler/"&gt;crawler&lt;/a&gt;). Такие программы
могут иметь совершенно разное предназначение, самый распространенный
пример: поисковые системы используют &lt;a href="/tag/crawler/"&gt;crawler&lt;/a&gt;'ов для
пополнения своих индексов, но, к сожалению, далеко не все программы
этого класса написаны для благих целей.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3 id="good-vs-evil"&gt;Good vs Evil&lt;/h3&gt;
&lt;p&gt;Большая часть "хороших" &lt;a href="/tag/spider/"&gt;spider&lt;/a&gt;'ов используется лишь для
сбора информации о сайте и следуют пожеланиям владельцев сайтов,
оставленных ими в специальном файле под названием &lt;code&gt;robots.txt&lt;/code&gt;, либо
внутри &lt;a href="/tag/html/"&gt;HTML&lt;/a&gt;-разметки с помощью специально предназначенных
для этого тэгов (этот механизм выходит за рамки данного повествования,
так что позволю себе его пропустить, оставив как тему для отдельного
разговора).&lt;/p&gt;
&lt;p&gt;Но даже сбор информации во время автоматизированного путешествия
программы по сайтам можно использовать в корыстных целях - на многих
сайтах люди размещают свою контактную информацию для тех или иных целей,
и некоторые сайты эту информацию "публикуют". &lt;a href="/tag/spider/"&gt;Spider&lt;/a&gt;,
настроенный на сбор контактной информации (в основном адресов
электронной почты и номеров ICQ и прочих служб обмена сообщениями) может
в очень сжатые сроки насобирать длинный список адресов, пригодный,
например, для рассылки нежелательной рекламы, в простонародье называемой
&lt;em&gt;&lt;a href="/tag/spam/"&gt;спам&lt;/a&gt;&lt;/em&gt;. Избежать попадания своей контактной информации в
такие списки относительно просто - достаточно лишь следить за тем, чтобы
она либо не публиковалась, либо была защищена любым из простейших
способов защиты от такого рода программ, начиная от банального
требования регистрации для просмотра контактных данных пользователей,
заканчивая выводом адресов через изображения или шифрование посредством
&lt;em&gt;JavaScript&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Среди прочих функций, которые может выполнять такого рода программа,
одной из наиболее часто используемых является возможность заполнения
такой неотъемлемой составляющей практически любого сайта, как &lt;em&gt;формы&lt;/em&gt;.
Имея возможность заполнения существенно б&lt;em&gt;о&lt;/em&gt;льшего количества форм в
единицу времени, чем человек, такие программы служат основным источником
&lt;em&gt;&lt;a href="/tag/spam/"&gt;спама&lt;/a&gt;&lt;/em&gt; в гостевых книгах, форумах и блогах. Еще одним из
возможных применений автоматического заполнения форм является
регистрация на множестве интернет-ресурсов с целью получения какой-либо
выгоды, например регистрация сайтов в каталогах. Помимо этого
&lt;a href="/tag/crawler/"&gt;crawler&lt;/a&gt; перемещается по сайту с относительно высокой
скоростью, что резко увеличивает нагрузку на &lt;a href="/tag/server/"&gt;сервер&lt;/a&gt;,
особенно при недостаточно оптимизированном движке сайта и/или недостатке
ресурсов сервера, выделяемых на выполнение скриптов сайта.&lt;/p&gt;
&lt;h3 id="zashchita-form-ot-avtomaticheskogo-zapolneniia"&gt;Защита форм от автоматического заполнения&lt;/h3&gt;
&lt;p&gt;Наверняка многие из вас раньше слышали термин &lt;a href="/tag/captcha/"&gt;CAPTCHA&lt;/a&gt;,
но боялись спросить: что же он значит? Как не трудно догадаться этот
термин является аббревиатурой :). Расшифровывается она как
"&lt;strong&gt;C&lt;/strong&gt;ompletely &lt;strong&gt;A&lt;/strong&gt;utomated &lt;strong&gt;P&lt;/strong&gt;ublic &lt;strong&gt;T&lt;/strong&gt;uring test to tell
&lt;strong&gt;C&lt;/strong&gt;omputers and &lt;strong&gt;H&lt;/strong&gt;umans &lt;strong&gt;A&lt;/strong&gt;part". Для меня до сих пор остается
загадкой по какому принципу выбирались слова для составления этой
аббревиатуры, наверное тупо случайным образом :). Смысл этой фразы в
переводе на русский можно передать как "полностью автоматический способ
отличить человека от компьютера". Конечно же имеется ввиду не внешние
различия, а особенности их поведения на просторах сети Интернет. В роли
"компьютера" в данном случае как раз выступают программы, о которых шла
речь в самом начале. Эта технология позволяет владельцам сайтов,
желающих исключить (по крайней мере чисто теоретически, на практике же -
минимизировать) посещение своего ресурса "плохими" "компьютерами",
крайне затруднить их использование.&lt;/p&gt;
&lt;p&gt;В основе этой технологии лежит тот факт, что у программ в большинстве
случаев отсутствует даже какое-либо подобие образного мышления - они
следуют заранее четко определенному алгоритму. Существует множество
вариантов реализации защиты сайта с использованием этого недостатка
компьютерных программ, но все они представляют некоторую проверку,
предлагаемую пользователю и стремящуюся к удовлетворению следующего ряда
требований:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Современные компьютеры не должны иметь возможности точно ее пройти.&lt;/li&gt;
&lt;li&gt;Она должна быть "по зубам" большинству людей.&lt;/li&gt;
&lt;li&gt;Не должна полагаться на тот факт, что потенциальный "злоумышленник"
    просто не знаком с принципом работы данной проверки.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Более подробно о возможностях этой &lt;a href="/tag/tekhnologiya/"&gt;технологии&lt;/a&gt; можно
узнать, прочитав &lt;a href="https://www.insight-it.ru/security/2008/7-sposobov-zashhitit-svoj-internet-resurs-ot-nezhelatelnoj-informacii/"&gt;запись о нескольких вариантах ее реализации&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Thu, 03 Jan 2008 20:25:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-01-03:security/2008/otkuda-voznikaet-spam-i-kak-s-nim-borotsya/</guid><category>captcha</category><category>crawler</category><category>online</category><category>PHP</category><category>spider</category><category>защита интернет-ресурсов</category><category>интернет</category><category>проверка</category><category>Сеть</category><category>спам</category><category>электронная почта</category></item></channel></rss>
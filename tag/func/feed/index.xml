<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/func/feed/index.xml" rel="self"></atom:link><lastBuildDate>Tue, 21 Feb 2012 16:29:00 +0400</lastBuildDate><item><title>Архитектура Tumblr</title><link>https://www.insight-it.ru//highload/2012/arkhitektura-tumblr/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/e90ae6ea/" rel="nofollow" target="_blank" title="http://www.tumblr.com"&gt;&lt;strong&gt;Tumblr&lt;/strong&gt;&lt;/a&gt; - одна из самых популярных в мире
платформ для блоггинга, которая делает ставку на привлекательный внешний
вид, юзабилити и дружелюбное сообщество. Хоть проект и не особо на слуху
в России, цифры говорят сами за себя: 24й по посещаемости сайт в США
с&amp;nbsp;15 миллиардами просмотров страниц в месяц. Хотите познакомиться с
историей этого проекта, выросшего из простого стартапа?
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id="vvedenie"&gt;Введение&lt;/h2&gt;
&lt;p&gt;Как и всем успешным стартапам, Tumblr удалось преодолеть опасную пропать
между начинающим проектом и широко известной компанией. Поиск правильных
людей, эволюция инфраструктуры, поддержка старых решений, паника по
поводу значительного роста посещаемости от месяца к месяцу, при этом в
команде только 4 технических специалиста - все это заставляло
руководство Tumblr принимать тяжелые решения о том над чем стоит
работать, а над чем - нет. Сейчас же технический персонал расширился до
20 человек и у них достаточно энергии для преодоления всех текущих
проблем и разработки новых интересных технических решений.&lt;/p&gt;
&lt;p&gt;Поначалу Tumblr был вполне типичным большим &lt;a href="/tag/lamp/"&gt;LAMP&lt;/a&gt;
приложением. Сейчас же они двигаются в направлении модели распределенных
сервисов, построенных вокруг существенно менее распространенных
технологий. Основные усилия сейчас вкладываются в постепенный уход от
&lt;a href="/tag/php/"&gt;PHP&lt;/a&gt; в пользу более "правильных" и "современных" решений,
оформленных в виде сервисов. Параллельно с переходом к новым технологиям
идут изменения и в команде проекта: от небольшой группы энтузиастов к
полноценной команде разработчиков, имеющей четкую структуру и сферы
ответственности, но тем не менее жаждущей реализовывать новый функционал
и обустраивать совершенно новую инфраструктуру проекта.&lt;/p&gt;
&lt;h2 id="platforma"&gt;Платформа&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/centos/"&gt;CentOS&lt;/a&gt; на серверах, &lt;a href="/tag/mac-os-x/"&gt;Mac OS X&lt;/a&gt; для
    разработки&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/apache/"&gt;Apache&lt;/a&gt; - основной веб-сервер&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, &lt;a href="/tag/scala/"&gt;Scala&lt;/a&gt;, &lt;a href="/tag/ruby/"&gt;Ruby&lt;/a&gt; - языки
    программирования&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/finagle/"&gt;Finagle&lt;/a&gt;&amp;nbsp;- асинхронный RPC сервер и клиент&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt;, &lt;a href="/tag/hbase/"&gt;HBase&lt;/a&gt;&amp;nbsp;- СУБД&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;,&amp;nbsp;&lt;a href="/tag/redis/"&gt;Redis&lt;/a&gt;&amp;nbsp;- кэширование&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/varnish/"&gt;Varnish&lt;/a&gt;, &lt;a href="/tag/nginx/"&gt;nginx&lt;/a&gt; - отдача статики&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/haproxy/"&gt;HAProxy&lt;/a&gt; - балансировка нагрузки&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/kestrel/"&gt;kestrel&lt;/a&gt;, &lt;a href="/tag/gearman/"&gt;gearman&lt;/a&gt; - очередь задач&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/thrift/"&gt;Thrift&lt;/a&gt; - сериализация&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/kafka/"&gt;Kafka&lt;/a&gt; - распределенная шина сообщений&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; - обработка статистики&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/zookeeper/"&gt;ZooKeeper&lt;/a&gt; - хранение конфигурации и состояний
    системы&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/git/"&gt;git&lt;/a&gt; - система контроля версий&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/jenkins/"&gt;Jenkins&lt;/a&gt; - непрерывное тестирование&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="statistika"&gt;Статистика&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Около 500 миллионов просмотров страниц в день&lt;/li&gt;
&lt;li&gt;Более 15 миллиардов просмотров страниц в месяц&lt;/li&gt;
&lt;li&gt;Посещаемость растет примерно на 30% в месяц&lt;/li&gt;
&lt;li&gt;Пиковые нагрузки порядка 40 тысяч запросов в секунду&lt;/li&gt;
&lt;li&gt;Около 20 технических специалистов в команде&lt;/li&gt;
&lt;li&gt;Каждый день создается около 50Гб новых постов и 2.7Тб обновлений списков
последователей&lt;/li&gt;
&lt;li&gt;Более 1Тб статистики обрабатывается в &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; ежедневно&lt;/li&gt;
&lt;li&gt;Используется порядка 1000 серверов:&lt;ul&gt;
&lt;li&gt;500 веб-серверов c Apache и PHP-приложением&lt;/li&gt;
&lt;li&gt;200 серверов баз данных (существенная их часть - резервные)&lt;ul&gt;
&lt;li&gt;47 пулов&lt;/li&gt;
&lt;li&gt;30 партиций (шардов)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;30 серверов &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;25 серверов Redis&lt;/li&gt;
&lt;li&gt;15 серверов Varnish&lt;/li&gt;
&lt;li&gt;25 серверов HAProxy&lt;/li&gt;
&lt;li&gt;8 серверов nginx&lt;/li&gt;
&lt;li&gt;14 серверов для очередей задач&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tipichnoe-ispolzovanie"&gt;Типичное использование&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tumblr&lt;/strong&gt; используется несколько по-другому, чем другие социальные
сети:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;При более чем 50 миллионах постов в день, каждый из них попадает в
среднем к нескольким сотням читателей. Это и не несколько
пользователей с миллионами читателей (например, популярные личности
в Twitter) и не миллиарды личных сообщений.&lt;/li&gt;
&lt;li&gt;Ориентированность на длинные публичные сообщения, полные интересной
информацией и картинками/видео, заставляет пользователей проводить
долгие часы каждый день за чтением Tumblr.&lt;/li&gt;
&lt;li&gt;Большинство активных пользователей подписывается на сотни других
блоггеров, что практически гарантирует много страниц нового контента
при каждом заходе на сайт. В других социальных сетях поток новых
сообщений переполнен ненужным контентом и толком не читается.&lt;/li&gt;
&lt;li&gt;Как следствие, при сложившемся количестве пользователей, средней
аудиторией каждого и высокой активностью написания постов, системе
приходится обрабатывать и доставлять огромное количество информации.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Публичные блоги называют Tumblelog'ами, они не так динамичны и легко
кэшируются.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Сложнее всего масштабировать Dashboard, страницу, где пользователи в
реальном времени читают что нового у блоггеров, на которых они
подписаны:&lt;ul&gt;
&lt;li&gt;Кэширование практически бесполезно, так как для активных
пользователей запросы редко повторяются.&lt;/li&gt;
&lt;li&gt;Информация должна отображаться в реальном времени, быть целостной и
не "задерживаться".&lt;/li&gt;
&lt;li&gt;Около 70% просмотров страниц приходится именно на Dashboard, почти
все пользователи им пользуются.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="staraia-arkhitektura"&gt;Старая архитектура&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Когда проект только начинался, Tumblr размещался в Rackspace и последние выдавали каждому блогу с собственным доменом A-запись. Когда они переросли Rackspace, они не смогли полноценно мигрировать в новый
датацентр, в том числе из-за количества пользователей. Это было в 2007
году, но у них по-прежнему часть доменов ведут на Rackspace и
перенаправляются в новый датацентр с помощью HAProxy и Varnish. Подобных
"унаследованных" проблем у проекта очень много.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;С технической точки зрения проект прошел по пути типичной эволюции
&lt;strong&gt;LAMP&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Исторически разработан на &lt;strong&gt;PHP&lt;/strong&gt;, все началось с веб-сервера,
сервера баз данных и начало потихоньку развиваться.&lt;/li&gt;
&lt;li&gt;Чтобы справляться с нагрузкой они начали использовать memcache,
затем добавили кэширование целых страниц и статических файлов, потом
поставили HAProxy перед кэшами, после чего сделали партиционирование
на уровне &lt;strong&gt;MySQL&lt;/strong&gt;, что сильно облегчило им жизнь.&lt;/li&gt;
&lt;li&gt;Они делали все, чтобы выжать максимум из каждого сервера.&lt;/li&gt;
&lt;li&gt;Было разработано два сервиса на C: генератор уникальных
идентификаторов на основе HTTP и libevent, а также
&lt;a href="https://www.insight-it.ru/goto/533d5aae/" rel="nofollow" target="_blank" title="http://engineering.tumblr.com/post/7819252942/staircar-redis-powered-notifications"&gt;Staircar&lt;/a&gt;,
использующий Redis для обеспечения уведомлений в реальном времени на
Dashboard.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dashboard использует подход
&lt;a href="https://www.insight-it.ru/goto/f4d9020c/" rel="nofollow" target="_blank" title="http://www2.parc.com/istl/projects/ia/papers/sg-sigir92/sigir92.html"&gt;"разбрасывать-собирать"&lt;/a&gt;,
так как из-за отсортировонности данных по времени традиционные схемы
партиционирования работали не очень хорошо. По их прогнозам текущая
реализация позволит им рости еще в течении полугода.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="novaia-arkhitektura"&gt;Новая архитектура&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Приоритетным направлением стали технологии, основанные на JVM, по
причине более быстрой разработки и доступности квалифицированных
кадров. Мотивация несколько спорная, особенно если учесть, что речь
идет в первую очередь о &lt;a href="/tag/scala/"&gt;Scala&lt;/a&gt;, а не
о&amp;nbsp;&lt;a href="/tag/scala/"&gt;Java&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Основная цель - вынести все из PHP приложения в отдельные сервисы, что
сделает его лишь тонким клиентом к внутреннему API.&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Почему выбор пал именно на &lt;strong&gt;Scala&lt;/strong&gt; и &lt;strong&gt;Finagle&lt;/strong&gt;?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Многие разработчики имели опыт с Ruby и PHP, так что Scala был
привлекательным (цитата, логики мало)&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/d7e3c54e/" rel="nofollow" target="_blank" title="https://github.com/twitter/finagle"&gt;Finagle&lt;/a&gt; был одним из основных
факторов в пользу JVM: это библиотека, разработанная в Twitter,
которая решает большинство распределенных задач вроде маршрутизации
запросов и обнаружение/регистрацию сервисов - не пришлось
реализовывать это все с нуля.&lt;/li&gt;
&lt;li&gt;В Scala не принято использовать общие состояния, что избавляет
разработчиков от забот с потоками выполнения и блокировками.&lt;/li&gt;
&lt;li&gt;Им очень нравится Thrift в роли программного интерфейса из-за его
высокой производительности (он кроссплатформенный и к JVM никак не
относится)&lt;/li&gt;
&lt;li&gt;Нравится &lt;a href="/tag/netty/"&gt;Netty&lt;/a&gt;, но не хочется связываться с Java, еще
один аргумент в пользу Scala.&lt;/li&gt;
&lt;li&gt;Рассматривали &lt;a href="/tag/node-js/"&gt;Node.js&lt;/a&gt;, но отказались так как под
JVM проще найти разработчиков, а также из-за отсутствия стандартов,
"лучших практик" и большого количества качественно протестированного
кода.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Старые внутренние сервисы также переписываются с C + libevent на Scala + Fingle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Был создан общий каркас для построения внутренних сервисов:&lt;ul&gt;
&lt;li&gt;Много усилий было приложено для автоматизации управления
распределенной системой.&lt;/li&gt;
&lt;li&gt;Создан аналог скаффолдинга - используется некий шаблон для создания
каждого нового сервиса.&lt;/li&gt;
&lt;li&gt;Все сервисы выглядят одинаково с точки зрения системного
администратора: получение статистики, мониторинг, запуск и остановка
реализованы одинаково для всех сервисов.&lt;/li&gt;
&lt;li&gt;Созданы простые инструменты для сборки сервисов без вникания в
детали используемых стандартных решений.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Используется 6 внутренних сервисов, над которыми работает отдельная
команд. На запуск сервиса с нуля уходит около 2-3 недель.&lt;/li&gt;
&lt;li&gt;Новые, нереляционные СУБД, такие как HBase и Redis, вводятся в
эксплуатацию, но основным хранилищем по-прежнему остается сильно
партиционированный MySQL.&lt;/li&gt;
&lt;li&gt;HBase используется для сервиса сокращенных ссылок для постов, а также
всех исторических данных и аналитики. HBase хорошо справляется с
ситуациями, где необходимы миллионы операций записи в секунду, но он не
достаточно стабилен, чтобы полностью заменить проверенное временем
решение на MySQL в критичных для бизнеса задачах.&lt;/li&gt;
&lt;li&gt;Партиционированный MySQL плохо справляется с отсортированными по времени данными, так как один из серверов всегда оказывается существенно более "горячим", чем остальными. Также сталкивались с значительными задержками в репликации из-за большого количества параллельных операций добавления данных.&lt;/li&gt;
&lt;li&gt;Используется 25 серверов Redis с 8-32 процессами на каждом, что означает
порядка 300-400 экземпляров Redis в сумме.&lt;ul&gt;
&lt;li&gt;Используется для уведомлений в реальном времени на Dashboard (о
событиях вроде "кому-то понравился Ваш пост").&lt;/li&gt;
&lt;li&gt;Высокое соотношений операций записи к операциям чтения сделало MySQL
не очень подходящим кандидатом.&lt;/li&gt;
&lt;li&gt;Уведомления не так критичны, их потеря допустима, что позволило
отключить персистентность Redis.&lt;/li&gt;
&lt;li&gt;Был создан интерфейс между Redis и отложенными задачами в Finagle.&lt;/li&gt;
&lt;li&gt;Сервис коротких ссылок также использует Redis как кэш, а HBase для
постоянного хранения.&lt;/li&gt;
&lt;li&gt;Вторичный индекс Dashboard также построен вокруг Redis.&lt;/li&gt;
&lt;li&gt;Redis также используется для хранения задач Gearman, для чего был
написан memcache proxy на основе Finale.&lt;/li&gt;
&lt;li&gt;Постепенно отказываются от memcached в пользу Redis в роли основного
кэша. Производительность у них сопоставима.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Внутренним сервисам необходим доступ к потоку всех событий в системе
(создание, редактирование и удаление постов, нравится или не нравится и
т.п.), для чего была созданна внутренняя шина сообщений &lt;em&gt;(англ.
firehose, пожарный шланг)&lt;/em&gt;:&lt;ul&gt;
&lt;li&gt;Пробовали использовать в этой роли Scribe, но так как оно по сути
свелось к пропусканию логов через grep в реальном времени - нагрузки
оно не выдержало.&lt;/li&gt;
&lt;li&gt;Текущая реализация основана на Kafka, решению аналогичной задачи от
LinkedIn на Scala.&lt;/li&gt;
&lt;li&gt;MySQL также не рассматривался из-за большой доли операций записи.&lt;/li&gt;
&lt;li&gt;Внутри сервисы используют HTTP потоки для чтения данных, хотя Thrift
интерфейс также используется.&lt;/li&gt;
&lt;li&gt;Поток сообщений хранит события за последнюю неделю с возможностью
указать момент времени с которого считывать данные при открытии
соединения.&lt;/li&gt;
&lt;li&gt;Поддерживается абстракция "группы потребителей", которая позволяет
группе клиентов вместе обрабатывать один поток данных вместе и
независимо, то есть одно и то же сообщение не попадет дважды к
клиентам из одной группы.&lt;/li&gt;
&lt;li&gt;ZooKeeper используется для периодического сохранения текущей позиции
каждого клиента в потоке.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Новая архитектура Dashboard основана на принципе ячеек или ящиков
входящих сообщений:&lt;ul&gt;
&lt;li&gt;Каждая "ячейка" отвечает за группу пользователей и читает новые события
с шины сообщений, если один из её пользователей-подопечных подписан на
автора только что опубликованного поста, то пост добавляется в "почтовый
ящик" подписанного пользователя.&lt;/li&gt;
&lt;li&gt;Когда пользователь заходит в Dashboard его запрос попадает в его ячейку,
которая возвращает ему нужную часть непрочитанных постов.&lt;/li&gt;
&lt;li&gt;Каждая ячейка состоит из трех групп серверов:&lt;ul&gt;
&lt;li&gt;HBase для постоянного хранения копий постов и почтовых ящиков;&lt;/li&gt;
&lt;li&gt;Redis для кэширование свежих данных;&lt;/li&gt;
&lt;li&gt;Сервис, читающий данные из шины и предоставляющий доступ к ящикам
посредством Thrift.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;В HBase используется две таблицы:&lt;ul&gt;
&lt;li&gt;Отсортированный &lt;strong&gt;список идентификаторов постов&lt;/strong&gt; для каждого
пользователя в ячейке, именно в том виде, как они будут отображены в
итоге.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Копии всех постов&lt;/strong&gt; по идентификаторам, что позволяет выдать все
данные для отрисовки Dashboard без обращений к серверам вне одной
ячейки.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Ячейки представляют собой независимые единицы, что позволяет легко
масштабировать систему при росте числа пользователей.&lt;/li&gt;
&lt;li&gt;Платой за относительно безболезненность масштабирования является
чрезвычайная избыточность данных: при том что ежедневно создается лишь
50Гб постов, суммарный объем данных в ячейках растет на 2.7Тб в день.&lt;/li&gt;
&lt;li&gt;Альтернативой было бы использование общего кластера со всеми постами, но
тогда он бы стал единственной точкой отказа и потребовалось бы делать
дополнительные удаленные запросы. Помимо этого выигрыш по объему был бы
не велик - списки идентификаторов занимают значительно больше места, чем
сами посты.&lt;/li&gt;
&lt;li&gt;Пользователи, которые подписаны или на которых подписаны миллионы других
пользователей, обрабатываются отдельно - страницы с их постами
генерируются не заранее (как описывалось выше), а при поступлении
запроса - это позволяет не тратить впустую много ресурсов (этот подход
называется выборочная материализация,
&lt;a href="https://www.insight-it.ru/goto/ab0d48a1/" rel="nofollow" target="_blank" title="http://research.yahoo.com/pub/3203"&gt;подробнее&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Количество пользователей в одной ячейке позволяет управлять балансом
между уровнем надежности и стоимостью содержания этой подсистемы.&lt;/li&gt;
&lt;li&gt;Параллельное чтение их шины сообщений оказывает серьезную нагрузку на
сеть, в дальнейшем из ячеек можно будет составить иерархию: только часть
будет читать напрямую из шины сообщений, а остальным сообщения будут
ретранслироваться.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tumblr географически по-прежнему находится в одном датацентре (если не
считать незначительное присутствие в Rackspace), распределение по
нескольким лишь в планах.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="razvertyvanie"&gt;Развертывание&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Начиналось как несколько rsync-скриптов для распространения
    PHP-приложения. Как только машин стало больше 200 такой подход стал
    занимать слишком много времени.&lt;/li&gt;
&lt;li&gt;Следующий вариант был основан на &lt;a href="/tag/capistrano/"&gt;Capistrano&lt;/a&gt;:
    были созданы три стадии процесса развертывания (разработка,
    тестирование, боевой). Неплохо справлялся с десятками серверов, но
    на сотнях также был слишком медленным, так как основывался на SSH.&lt;/li&gt;
&lt;li&gt;Итоговый вариант основан на &lt;strong&gt;Func&lt;/strong&gt;, решении от
    &lt;a href="/tag/redhat/"&gt;RedHat&lt;/a&gt;, позволившим заменить &lt;a href="/tag/ssh/"&gt;SSH&lt;/a&gt; на
    более легковесный протокол.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="razrabotka"&gt;Разработка&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Поначалу философия была такова, что каждый мог использовать любые
технологии, которые считал уместным. Но довольно скоро пришлось
стандартизировать стек технологий, чтобы было легче нанимать и вводить в
работу новых сотрудников, а также для более оперативного решения
технических проблем.&lt;/li&gt;
&lt;li&gt;Каждый разработчик имеет одинаковую заранее настроенную рабочую станцию,
которая обновляется посредством &lt;a href="/tag/puppet/"&gt;Puppet&lt;/a&gt;:&lt;ul&gt;
&lt;li&gt;Настроена публикация изменений, тестирование и развертывание новых
версий.&lt;/li&gt;
&lt;li&gt;Разработчики используют vim и Textmate.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Новый PHP код систематически инспектируется другими разработчиками.&lt;/li&gt;
&lt;li&gt;Внутренние сервисы подвергаются непрерывному тестированию посредством
Jenkins.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="struktura-komand"&gt;Структура команд&lt;/h2&gt;
&lt;p&gt;Проект разбит на 6 команд:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Инфраструктура:&lt;/strong&gt;&amp;nbsp;все, что ниже 5 уровня по модели OSI -
    маршрутизация, TCP/IP, DNS, оборудование и.т.п.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Платформа:&lt;/strong&gt;&amp;nbsp;разработка основного приложения, партиционирование
    SQL, взаимодействие сервисов.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Надежность (SRE):&lt;/strong&gt;&amp;nbsp;сфокусирована на текущие потребности с точки
    зрения надежности и масштабируемости.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Сервисы:&lt;/strong&gt;&amp;nbsp;занимается более стратегической разработкой того, что
    понадобится через один-два месяца.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Эксплуатация:&lt;/strong&gt;&amp;nbsp;отвечает за обнаружение и реагирование на
    проблемы, плюс тонкая настройка.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="naim"&gt;Найм&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;На интервью они обычно избегают математики и головоломок, основной
    упор идет в основном именно на те вещи, которым придется заниматься
    кандидату.&lt;/li&gt;
&lt;li&gt;Основной вопрос: будет ли он успешно решать поставленные задачи?
    Цель в том, чтобы найти отличных людей, а не в том, чтобы никого не
    брать.&lt;/li&gt;
&lt;li&gt;Разработчиков обязательно просят привести пример своего кода, даже
    во время телефонных интервью.&lt;/li&gt;
&lt;li&gt;Во время интервью кандидатов не ограничивают в наборе инструментов,
    можно даже гуглить.&lt;/li&gt;
&lt;li&gt;Поиск людей с опытом в крупных проектах достаточно сложен, так как
    всего нескольких компаниях по всему миру решают подобные проблемы.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="podvodim-itogi"&gt;Подводим итоги&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Автоматизация - ключ к успеху крупного проекта.&lt;/li&gt;
&lt;li&gt;При партиционировании MySQL может масштабироваться, но лишь при
    преобладании операций чтения.&lt;/li&gt;
&lt;li&gt;Redis с отключенной персистентностью легко может заменить memcached.&lt;/li&gt;
&lt;li&gt;Scala достойно себя проявляет в роли языка программирования для
    внутренних сервисов, во многом благодаря обширной Java-экосистеме.&lt;/li&gt;
&lt;li&gt;Внедряйте новые технологии постепенно, поначалу работать с HBase и
    Redis было очень болезненно, они были включены в основной стек
    технологий только после испытаний в некритичных сервисах и
    подпроектах, где цена ошибки не так велика.&lt;/li&gt;
&lt;li&gt;Проект должен строиться вокруг навыков его команды, а не наоборот.&lt;/li&gt;
&lt;li&gt;Нужно нанимать людей только если они вписываются в команду и в
    состоянии довести работу до результата.&lt;/li&gt;
&lt;li&gt;При выборе технологического стека одну из ключевых ролей играет
    доступность соответствующих специалистов на кадровом рынке.&lt;/li&gt;
&lt;li&gt;Читайте публикации и статьи в блогах. Ключевые аспекты архитектуры,
    включая "ячейки" и частичную материализацию были позаимствованы из
    внешних источников.&lt;/li&gt;
&lt;li&gt;Поспрашивайте своих коллег, кто-то из них мог общаться с
    специалистами из
    &lt;a href="https://www.insight-it.ru/highload/2010/arkhitektura-facebook/"&gt;Facebook&lt;/a&gt;,
    &lt;a href="https://www.insight-it.ru/highload/2011/arkhitektura-twitter-dva-goda-spustya/"&gt;Twitter&lt;/a&gt;,
    &lt;a href="https://www.insight-it.ru/highload/2011/arkhitektura-google-2011/"&gt;Google&lt;/a&gt;
    или
    &lt;a href="https://www.insight-it.ru/highload/2008/arkhitektura-linkedin/"&gt;LinkedIn&lt;/a&gt; -
    если нет прямого доступа, всегда можно получить нужную информацию
    через одно-два "рукопожатия".&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Статья написана на основе &lt;a href="https://www.insight-it.ru/goto/1444dc9b/" rel="nofollow" target="_blank" title="http://highscalability.com/blog/2012/2/13/tumblr-architecture-15-billion-page-views-a-month-and-harder.html"&gt;интервью&lt;/a&gt;&amp;ensp;&lt;a href="https://www.insight-it.ru/goto/511d685/" rel="nofollow" target="_blank" title="http://www.linkedin.com/bmatheny"&gt;Blake Matheny&lt;/a&gt;, директора по разработке платформы Tumblr.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Tue, 21 Feb 2012 16:29:00 +0400</pubDate><guid>tag:www.insight-it.ru,2012-02-21:highload/2012/arkhitektura-tumblr/</guid><category>Apache</category><category>Capistrano</category><category>CentOS</category><category>Finagle</category><category>Func</category><category>gearman</category><category>Git</category><category>Hadoop</category><category>HAProxy</category><category>HBase</category><category>jenkins</category><category>kafka</category><category>Kestrel</category><category>LAMP</category><category>Mac OS X</category><category>Memcached</category><category>MySQL</category><category>nginx</category><category>PHP</category><category>puppet</category><category>Redis</category><category>Ruby</category><category>Scala</category><category>Thrift</category><category>Tumblr</category><category>Varnish</category><category>ZooKeeper</category></item></channel></rss>
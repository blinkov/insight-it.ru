<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/gpl/feed/index.xml" rel="self"></atom:link><lastBuildDate>Sun, 18 May 2008 21:16:00 +0400</lastBuildDate><item><title>GlusterFS</title><link>https://www.insight-it.ru//storage/2008/glusterfs/</link><description>&lt;p&gt;&lt;img alt="GlusterFS Logo" class="right" src="https://www.insight-it.ru/images/glusterfs-logo.png" title="GlusterFS"/&gt;
&lt;a href="https://www.insight-it.ru/goto/12ccc1c7/" rel="nofollow" target="_blank" title="http://www.gluster.org/glusterfs.php"&gt;GlusterFS&lt;/a&gt; представляет собой
кластерную файловую систему, способную масштабироваться для хранения
далеко не одного петабайта данных. Как и многие другие кластерные
файловые системы, GlusterFS агрегирует дисковое пространство большого
количества машин в одну общую параллельную сетевую файловую систему
через Infiniband RDMA или TCP/IP соединение. Обычно в качестве
аппаратной основы для этой файловой системы используется ничем не
выдающееся недорогое серверное оборудование, в полной мере реализуя
принцип программного построения стабильности при использовании на
ненадежном оборудовании.
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;Кластерные файловые системы еще не достаточно приспособлены для
использования на крупных предприятиях: обычно процесс их развертывания и
поддержания в работающем состоянии не так уж прост. Но зато они отлично
масштабируются и достаточно дешевы, ведь для них достаточно самого
простого серверного оборудования и opensource операционных систем и
програмного обеспечения. Основной целью разработчиков
&lt;a href="/tag/glusterfs/"&gt;GlusterFS&lt;/a&gt; как раз и является построение кластерной
файловой системы, адаптированной для использования в рамках серьезных
компаний.&lt;/p&gt;
&lt;p&gt;Список основных ее особенностей по большей части мало чем отличается от
других кластерных файловых систем:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Состоит из клиентской и серверной частей. Клиентская часть позволяет
    монтировать файловую систему, а серверная - &lt;strong&gt;glusterfsd&lt;/strong&gt; -
    экспортировать в нее локальное дисковое пространство.&lt;/li&gt;
&lt;li&gt;Масштабируемость близка к &lt;em&gt;O(1)&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Широкий спектр возможностей за счет использования модульной
    архитектуры.&lt;/li&gt;
&lt;li&gt;Имеется возможность восстановления файлов и директорий из файловой
    системы даже без ее инициализации.&lt;/li&gt;
&lt;li&gt;Отсутствие централизованного сервера метаданных, что делает ее более
    устойчивой к потенциальным сбоям.&lt;/li&gt;
&lt;li&gt;Расширяемый интерфейс выполнения задач, с поддержкой загрузки
    модулей в зависимости от особенностей выполнения пользователями
    операций по работе с данными.&lt;/li&gt;
&lt;li&gt;Расширяющий функциональность механизм трансляторов.&lt;/li&gt;
&lt;li&gt;Поддержка &lt;em&gt;Infiniband RDMA&lt;/em&gt; и &lt;em&gt;TCP/IP&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Возможность автоматического восстановления в случае сбоев.&lt;/li&gt;
&lt;li&gt;Полностью реализована на уровне приложений, что упрощает ее
    поддержание в рабочем состоянии, портирование и дальнейшую
    разработку.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Но некоторые моменты все же заслуживают отдельного внимания:&lt;/p&gt;
&lt;h4&gt;Совместимость&lt;/h4&gt;
&lt;p&gt;Как уже упоминалось, файловая система реализована полностью на
уровне пользовательских приложений, что делает возможным ее
монтирование без каких-либо дополнительных патчей в ядре
операционной системы, единственное требование к нему: поддержка
FUSE. Серверная часть &lt;a href="/tag/glusterfs/"&gt;GlusterFS&lt;/a&gt; может
функционировать на любой POSIX-совместимой операционной системе и
протестирована на &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;, &lt;a href="/tag/freebsd/"&gt;FreeBSD&lt;/a&gt;,
&lt;a href="/tag/solaris/"&gt;OpenSolaris&lt;/a&gt;, в отличии от клиентской части, которая
может работать только в &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Модули&lt;/h4&gt;
&lt;p&gt;В виде модулей реализованы различные варианты выполнения
основополагающих операций: передачи данных и балансировки нагрузки в
рамках кластера. Транспортные модули обеспечивают передачу данных по
различным типам соединений:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;TCP/IP&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Infiniband-verbs&lt;/strong&gt;;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Infiniband-&lt;abbr title="Socket Direct Protocol"&gt;SDP&lt;/abbr&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Балансировка нагрузки может выполняться по следующим алгоритмам:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;abbr title="Adaptive Least Usage"&gt;ALU&lt;/abbr&gt;&lt;/strong&gt; - использует
    целый ряд факторов, включающий объем свободного локального
    дискового пространства, активность операций чтения и записи,
    количество одновременно открытых файлов, скорость физического
    вращения дисков. Значимость, придаваемая каждому из показателей,
    может достаточно гибко настраиваться.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;abbr title="Round Robin"&gt;RR&lt;/abbr&gt;&lt;/strong&gt; - по очереди размещает
    файлы последовательно на каждом узле, после чего начинает
    процесс заново, образуя своеобразный цикл. Этот метод эффективен
    если файлы имеют примерно одинаковый размер, а узлы кластера -
    одинаковый размер экспортированного локального дискового
    пространства.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random&lt;/strong&gt; - распределяют файлы случайным образом.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;abbr title="Non-Uniform File Access"&gt;NUFA&lt;/abbr&gt;&lt;/strong&gt; -
    приоритет отдается созданию файлов локально, а не на других
    узлах кластера.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Switch&lt;/strong&gt; - располагает файлы по определенным указанным
    особенностям имен файлов, по аналогии со &lt;strong&gt;switch(filename)&lt;/strong&gt; в
    программировании, обычно в качестве критерия распределения
    файлов имеет смысл использовать их расширение.&lt;/li&gt;
&lt;/ul&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Трансляторы&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Они представляют собой очень мощный механизм для расширения
возможностей GlusterFS, сама идея трансляторов бала позаимствована у
&lt;a href="https://www.insight-it.ru/goto/a8e9005c/" rel="nofollow" target="_blank" title="http://hurd.gnu.org"&gt;GNU/Hurd&lt;/a&gt; и заключается она в загрузке
бинарных библиотек (.so) в процессе работы системы в зависимости от
использованных настроек и использовании их в виде своеобразной
цепочки обработчиков при работе с файлами как на серверной, так и на
клиентской стороне. В &lt;a href="/tag/glusterfs/"&gt;GlusterFS&lt;/a&gt; практически все
дополнительные возможности реализованы именно виде трансляторов,
начиная от дополнений, увеличивающих производительность, заканчивая
средствами отладки. Вкратце перечислю основные из них:
+   &lt;strong&gt;&lt;abbr title="Automatic File Replication"&gt;AFR&lt;/abbr&gt;&lt;/strong&gt; - автоматическая репликация файлов.
+   &lt;strong&gt;Stripe&lt;/strong&gt; - разбивает файлы на блоки фиксированного размера.
+   &lt;strong&gt;Unify&lt;/strong&gt; - объединяет несколько узлов кластера в один большой
    виртуальный узел, один узел выделяется для обеспечения
    внутреннего namespace. Директории создаются на всех узлах,
    составляющих unify, а каждый файл - лишь на одном (если не
    используется &lt;abbr title="Automatic File Replication"&gt;AFR&lt;/abbr&gt;).
+   &lt;strong&gt;Trace&lt;/strong&gt; - предоставляют информацию для отладки в виде
    дополнительных записей в лог.
+   &lt;strong&gt;Filter&lt;/strong&gt; - фильтрация файлов на основании их имен и/или
    атрибутов.
+   &lt;strong&gt;Posix-locks&lt;/strong&gt; - обеспечивает POSIX блокировку записей
    независимую от используемой системы хранения.
+   &lt;strong&gt;Trash&lt;/strong&gt; - предоставляет функциональность сопоставимую с
    libtrash (или "корзиной" - если так понятнее).
+   &lt;strong&gt;Fixed-id&lt;/strong&gt; - обеспечивает доступ только для пользователей с
    определенными UID и GUID.
+   &lt;strong&gt;Posix&lt;/strong&gt; - соединяет GlusterFS с низлежащей локальной файловой
    системой.
+   &lt;strong&gt;rot-13&lt;/strong&gt; - транслятор обеспечивает возможность шифрования и
    дешифрования данных по примитивному одноименному алгоритму.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Список возможностей, обеспечиваемых широким набором модулей и
транслятором, впечатляет, большинство других opensource кластерных
файловых систем не могут похвастаться подобной функциональностью
(&lt;a href="/tag/glusterfs/"&gt;GlusterFS&lt;/a&gt; выпускается под GPL). Благодаря возможности
работы через Infiniband производительность передачи данных также
достаточно высока - она может достигать десятков гигабит в секунду.
Обработка сбоев в отдельных узлах также осуществляется достаточно
эффективно, так как может быть автоматизирована. Из потенциальных
недостатков можно назвать некоторое количество редко проявляющих себя
багов в коде, а также достаточно большой размер заголовков в
используемом протоколе (несколько сотен байт). В целом эта система
вполне работоспособна и полноценно выдерживает конкуренцию со стороны
своих opensource "коллег".&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sun, 18 May 2008 21:16:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-05-18:storage/2008/glusterfs/</guid><category>GlusterFS</category><category>GPL</category><category>Infiniband</category><category>кластер</category><category>Масштабируемость</category><category>файловая система</category></item><item><title>Hypertable</title><link>https://www.insight-it.ru//storage/2008/hypertable/</link><description>&lt;p&gt;&lt;img alt="Hypertable" class="right" src="https://www.insight-it.ru/images/hypertable-logo.gif" title="Hypertable"/&gt;
&lt;a href="https://www.insight-it.ru/goto/63463036/" rel="nofollow" target="_blank" title="http://www.hypertable.org"&gt;Hypertable&lt;/a&gt; является еще одним opensource
проектом, направленным на воспроизведение функционала
&lt;a href="/tag/bigtable/"&gt;BigTable&lt;/a&gt; от &lt;a href="/tag/google/"&gt;Google&lt;/a&gt;. Поставленная перед
проектом цель заключается в реализации системы хранения данных на базе
распределенной файловой системы, позволяющей перейти на новый уровень
производительности при работе с гигантскими объемами данных.
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;Принцип работы &lt;a href="/tag/hypertable/"&gt;Hypertable&lt;/a&gt; прост до безобразия:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hypertable хранит данные в табличном формате, сортируя записи по
    основному ключу;&lt;/li&gt;
&lt;li&gt;для хранимых данных не используются какие-либо типы данных, любая
    ячейка интерпретируется как байтовая строка;&lt;/li&gt;
&lt;li&gt;масштабируемость достигается путем разбиения таблиц на смежные
    интервалы строк и хранения их на разных физических машинах;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;в системе используется два типа серверов:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Master Server&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&amp;ndash; как и во многих других подобных системах мастер-сервер
выполняет обязанности скорее административного характера: он
управляет работой Range серверов, работает с метаданными
(которые хранятся просто в отдельной таблице, наравне с
остальными).&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Range Server&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&amp;ndash; их задача стоит в собственно в хранении диапазонов строк из
различных таблиц. Каждый сервер может хранить несколько
несмежных диапазонов строк, если диапазон превышает по объему
определенный лимит (по-умолчанию - 200 MB), то он разбивается на
пополам и одна половина обычно перемещяется на другой сервер.
Если же на одном из серверов подходит к концу дисковое
пространство, то под руководством мастер-сервера часть
диапазонов с него перераспределяется на менее загруженные Range
серверы.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Еще одним компонентом системы является Hyperspace, этот сервер
    предоставляет указатель на основную таблицу с метаданными, а также
    пространство имен. Помимо этого этот сервис выступает в роли
    lock-механизма для клиентов системы.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;В качестве основы для этой системы может использоваться как входящая в
состав &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; файловая система &lt;a href="/tag/hdfs/"&gt;HDFS&lt;/a&gt;, так и
&lt;a href="/tag/kfs/"&gt;KosmosFS&lt;/a&gt;, о которой я недавно
&lt;a href="https://www.insight-it.ru/storage/2008/fajjly-v-kosmose/"&gt;рассказывал&lt;/a&gt;. Это позволяет
Hypertable выступать в роли конкурента для &lt;a href="/tag/hbase/"&gt;HBase&lt;/a&gt; в рамках
проекта &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;HBase и Hypertable выполняют достаточно похожие функции и преследуют
практически одни и те же цели, но есть некоторые ньюансы. Одним из
глобальных различий в этих системах является языки программирования, с
использованием которого они реализованы. HBase написана на
&lt;a href="/tag/java/"&gt;Java&lt;/a&gt;, в то время как разработчики Hypertable предпочли
&lt;a href="/tag/c/"&gt;C++&lt;/a&gt;. Это повлекло за собой массу различий в инкапсулированной
реализации различных операций.&lt;/p&gt;
&lt;p&gt;Для доступа к данным каждая из систем использует язык HQL, только в
одном случае аббревиатура расшифровывается как HBase Query Language, а в
другом - Hypertable Query Language (как эгоистично :) ). По сути и то и
другое является сильно упрощенным диалектом &lt;a href="/tag/sql/"&gt;SQL&lt;/a&gt;, что
позволяет сократить знакомство с синтаксисом HQL до пары минут при
достаточном знании классического SQL. Хотелось бы отметить, что вся
простота в сравнении с классическим SQL и реляционными СУБД вполне
обоснована: обе системы хранения данных предназначены для использования
в совокупности с &lt;a href="/tag/mapreduce/"&gt;MapReduce&lt;/a&gt; программами, что делает их
просто хранилищем данных, а не средством их обработки.&lt;/p&gt;
&lt;p&gt;После небольшого лирического отступления в виде сравнения с HBase
хотелось бы все же вернуться к теме нашего разговора, а именно к
организации хранения данных в Hypertable. Данные хранятся в виде пар
ключ:значение, причем храняться все версии строк с указанием времени,
когда они были созданы. Таким образом легко проследить за процессом
изменения данных во времени, а также узнать какие именно операции
проводились над ними в прошлом. Стандартный механизм работы с версиями
данных может быть переопределен на хранения лишь фиксированного
количества версий строки, позволяя использовать удаление устаревших
записей для освобождения дополнительного дискового пространства.&lt;/p&gt;
&lt;p&gt;Для более эффективной работы с обновлением случайных ячеек таблиц
используется кэширование. Поступающие данные собираются в оперативной
памяти и при достижении определенного лимита сжимаются и записываются на
диск.&lt;/p&gt;
&lt;p&gt;Для более эффективной работы с распределенной файловой системой
используется механизм под названием &lt;em&gt;Access Groups&lt;/em&gt;. Суть заключается в
объединении колонок таблиц в группы, в которых они чаще всего
используется вместе. Такие группы данных по возможности храняться вместе
на физических носителях. Если запрос включает в себя только данные из
колонок одной группы доступа, то с дисков считывается только эти
колонки, в противном случае приходиться работать со всей строкой
целиком. Такой подход позволяет существенно оптимизировать работу
операций ввода/вывода.&lt;/p&gt;
&lt;p&gt;Проект еще находится в стадии разработки и до стабильного релиза ему еще
далеко, но тем не менее он уже вполне может себя показать в качестве
конкурента как для других систем подобного класса, так и для более
стандартных реляционных баз данных. Основными недостающими моментами в
этой системе в данной системе является отсутствие некоторого порой
необходимого функционала в HQL, а такжы некоторые проблемы с
отказоустойчивостью, вызванные единственностью в рамках системы Master и
Hyperspace серверов.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sat, 05 Apr 2008 20:27:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-04-05:storage/2008/hypertable/</guid><category>C++</category><category>GPL</category><category>Hadoop</category><category>HDFS</category><category>HQL</category><category>Hypertable</category><category>KFS</category><category>opensource</category></item></channel></rss>
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/lvs/feed/index.xml" rel="self"></atom:link><lastBuildDate>Tue, 22 Mar 2011 00:17:00 +0300</lastBuildDate><item><title>Архитектура Одноклассников</title><link>https://www.insight-it.ru//highload/2011/arkhitektura-odnoklassnikov/</link><description>&lt;p&gt;Сегодня представители &lt;a href="https://www.insight-it.ru/goto/2c99aef2/" rel="nofollow" target="_blank" title="http://www.odnoklassniki.ru"&gt;Одноклассников&lt;/a&gt;
рассказали о накопленном за 5 лет опыте по поддержанию высоконагруженного
проекта. Была опубликована довольно детальная информация о том, как
устроена эта социальная сеть для аудитории "постарше". Далее можно
прочитать мою версию материала, либо перейти на оригинал &lt;a href="https://www.insight-it.ru/goto/b762a864/" rel="nofollow" target="_blank" title="http://habrahabr.ru/company/odnoklassniki/blog/115881/"&gt;по сссылке&lt;/a&gt;.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2 id="platforma"&gt;Платформа&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/windows/"&gt;Windows&lt;/a&gt; и &lt;a href="/tag/opensuse/"&gt;openSUSE&lt;/a&gt; - основные
    операционные системы&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/java/"&gt;Java&lt;/a&gt; - основной язык программирования&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/c/"&gt;С/С++&lt;/a&gt; - для некоторых модулей&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/gwt/"&gt;GWT&lt;/a&gt; - реализация динамического веб-интерфейса&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/tomcat/"&gt;Apache Tomcat&lt;/a&gt; - сервера приложений&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/jboss/"&gt;JBoss 4&lt;/a&gt; - сервера бизнес-логики&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/lvs/"&gt;LVS&lt;/a&gt; и &lt;a href="/tag/ipvs/"&gt;IPVS&lt;/a&gt; - балансировка нагрузки&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mssql/"&gt;MS SQL 2005 и 2008&lt;/a&gt; - основная СУБД&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/berkleydb/"&gt;BerkleyDB&lt;/a&gt; - дополнительная СУБД&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/lucene/"&gt;Apache Lucene&lt;/a&gt; - индексация и поиск текстовой
    информации&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="statistika"&gt;Статистика&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;До 2.8 млн. пользователей онлайн в часы пик&lt;/li&gt;
&lt;li&gt;7,5 миллиардов запросов в день (150 000 запросов в секунду в часы
    пик)&lt;/li&gt;
&lt;li&gt;2 400 серверов и систем хранения данных, из которых 150 являются
    веб-серверами&lt;/li&gt;
&lt;li&gt;Сетевой трафик в час пик: 32 Gb/s&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="oborudovanie"&gt;Оборудование&lt;/h2&gt;
&lt;p&gt;Сервера используются двухпроцессорные с 4 ядрами, объемом памяти от 4 до
48 Гб. В зависимости от роли сервера данные хранятся либо в памяти, либо
на дисках, либо на внешних системах хранения данных.&lt;/p&gt;
&lt;p&gt;Все оборудование размещено в 3 датацентрах, объединенных в оптическое
кольцо. На данный момент на каждом из маршрутов пропускная способность
составляет 30Гбит/с. Каждый из маршрутов состоит из физически
независимых друг от друга оптоволоконных пар, которые агрегируются в
общую &amp;ldquo;трубу&amp;rdquo; на корневых маршрутизаторах.&lt;/p&gt;
&lt;p&gt;Сеть физически разделена на внутреннюю и внешнюю, разные интерфейсы
серверов подключены в разные коммутаторы и работают в разных сетях. По
внешней сети HTTP сервера, общаются с Интернетом, по внутренней сети все
сервера общаются между собой.&amp;nbsp;Топология внутренней сети &amp;ndash; звезда.
Сервера подключены в L2 коммутаторы (access switches), которые, в свою
очередь, подключены как минимум двумя гигабитными линками к aggregation
стеку маршрутизаторов. Каждый линк идет к отдельному коммутатору в
стеке. Для того, чтобы эта схема работала, используется
протокол&amp;nbsp;&lt;a href="https://www.insight-it.ru/goto/a03e0548/" rel="nofollow" target="_blank" title="http://ru.wikipedia.org/wiki/RSTP"&gt;RSTP&lt;/a&gt;. При необходимости,
подключения access коммутаторов к agregation стеку осуществляются более
чем двумя линками с использованием link aggregation портов.&amp;nbsp;Aggregation
коммутаторы подключены 10Гб линками в корневые маршрутизаторы, которые
обеспечивают как связь между датацентрами, так и связь с внешним
миром.&amp;nbsp;Используются коммутаторы и маршрутизаторы от компании Cisco.&lt;/p&gt;
&lt;p&gt;Для связи с внешним миром используются прямые подключения с несколькими
крупнейшими операторами связи, общий сетевой&amp;nbsp;трафик в часы пик доходит
до 32Гбит/с.&lt;/p&gt;
&lt;h2 id="arkhitektura"&gt;Архитектура&lt;/h2&gt;
&lt;p&gt;Архитектура проекта имеет традиционную многоуровневую структуру:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;презентационный уровень;&lt;/li&gt;
&lt;li&gt;уровень бизнес-логики;&lt;/li&gt;
&lt;li&gt;уровень кэширования;&lt;/li&gt;
&lt;li&gt;уровень баз данных;&lt;/li&gt;
&lt;li&gt;уровень инфраструктуры (логирование, конфигурация и мониторинг).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Код проекта в целом написан на Java, но есть исключения в виде модулей
для кэширования на C и C++.
Java был выбран так как он является удобным языком для разработки,
доступно множество наработок в различных сферах, библиотек и opensource
проектов.&lt;/p&gt;
&lt;h3 id="prezentatsionnyi-uroven"&gt;Презентационный уровень&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Используем собственный фреймворк, позволяющий строить композицию
    страниц на языке Jаvа, с использованием собственные GUI фабрик (для
    оформления текста, списков, таблиц и портлетов).&lt;/li&gt;
&lt;li&gt;Страницы состоят из независимых блоков (обычно портлетов), что
    позволяет обновлять информацию на них частями с помощью AJAX
    запросов.&lt;/li&gt;
&lt;li&gt;При данном подходе одновременно обеспечивается минимум перезагрузок
    страниц для пользователей с включенным JavaScript, так и полная
    работоспособность сайта для пользователей, у которых он отключен.&lt;/li&gt;
&lt;li&gt;Google Web Toolkit используется для реализации функциональные
    компонент, таких как Сообщения, Обсуждения и Оповещения, а также все
    динамических элементов (меню шорткатов, метки на фотографиях,
    сортировка фотографий,&amp;nbsp;ротация подарков и.т.д.).&amp;nbsp;В GWT используются
    UIBinder и HTMLPanel для создания интерфейсов.&lt;/li&gt;
&lt;li&gt;Кешируются все внешние ресурсы (Expires и Cache-Control заголовки).
    CSS и JavaScript файлы минимизируются и сжимаются (gzip).&lt;/li&gt;
&lt;li&gt;Для уменьшения количества HTTP запросов с браузера, все JavaScript и
    CSS файлы объединяются в один. Маленькие графические изображения
    объединяются в спрайты.&lt;/li&gt;
&lt;li&gt;При загрузке страницы скачиваются только те ресурсы, которые на
    самом деле необходимы для начала работы.&lt;/li&gt;
&lt;li&gt;Никаких универсальных CSS селекторов. Стараются не использовать
    типовые селекторы (по имени тэга), что повышает скорость отрисовки
    страниц внутри браузера.&lt;/li&gt;
&lt;li&gt;Если необходимы CSS expressions, то пишутся &amp;laquo;одноразовые&amp;raquo;. По
    возможности избегаются фильтры.&lt;/li&gt;
&lt;li&gt;Кешируется обращения к DOM дереву, а так же свойства элементов,
    приводящие к reflow. Обновляется DOM дерево в &amp;laquo;оффлайне&amp;raquo;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="uroven-biznes-logiki_1"&gt;Уровень бизнес-логики&lt;/h2&gt;
&lt;p&gt;На уровне бизнес логики располагаются около 25 типов серверов и
компонентов, общающихся между собой через удаленные интерфейсы. Каждую
секунду происходит около 3 миллионов удаленных запросов между этими
модулями.
Сервера на уровне бизнес логики разбиты на группы. Каждая группа
обрабатывает различные события. Есть механизм маршрутизации событий, то
есть любое событие или группу событий можно выделить и направить на
обработку на определенную группу серверов.&amp;nbsp;При общении серверов между
собой используется свое решение, основанное на&amp;nbsp;&lt;a href="https://www.insight-it.ru/goto/5e85a755/" rel="nofollow" target="_blank" title="http://www.jboss.org/jbossremoting"&gt;JBoss
Remoting&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="uroven-keshirovaniia"&gt;Уровень кэширования&lt;/h2&gt;
&lt;p&gt;Для кэширования данных используется самописный модуль
odnoklassniki-cache. Он предоставляет возможность хранения данных в
памяти средствами Java Unsafe. Кэшируются все данные, к которым
происходит частое обращение, например: профили пользователей, списки
участников сообществ, информация о самих сообществах, граф связей
пользователей и групп, праздники, мета информация о фотографиях и многое
другое.Для хранения больших объемов данных в памяти используется память
Java off heap memory для снятия ненужной нагрузки с сборщика
мусора.&amp;nbsp;Кеши могут использовать локальный диск для хранения данных, что
превращает их в высокопроизводительный сервер БД.&amp;nbsp;Кеш сервера, кроме
обычных операций ключ-значение, могут выполнять запросы по данным,
хранящимся в памяти, минимизируют таким образом передачу данных по сети.
Используется map-reduce для выполнения запросов и операций на кластере.
В особо сложных случаях, например для реализации запросов по социальному
графу, используется язык C. Это помогает повысить производительность.&lt;/p&gt;
&lt;p&gt;Данные распределяются между кластерами кеш серверов, а также
используется репликация партиций для обеспечения надежности.&amp;nbsp;Иногда
требования к быстродействию настолько велики, что используются локальные
короткоживущие кеши данных полученных с кеш серверов, расположенные
непосредственно в памяти серверов бизнес логики.&lt;/p&gt;
&lt;p&gt;Для примера, один сервер, кэширующий граф связей пользователей, в час
пик может обработать около 16 600 запросов в секунду. Процессоры при
этом заняты до 7%, максимальный load average за 5 минут &amp;mdash; 1.2.
Количество вершин графа - более 85 миллионов, связей 2.5 миллиарда. В
памяти граф занимает 30 GB.&lt;/p&gt;
&lt;h2 id="uroven-baz-dannykh"&gt;Уровень баз данных&lt;/h2&gt;
&lt;p&gt;Суммарный объем данных без резервирования составляет 160Тб. Используются
два решения для хранения данных: MS SQL и BerkeleyDB. Данные хранятся в
нескольких копиях, в зависимости от их типа от двух до четырех. Полное
резервное копирование всех данных осуществляется раз в сутки, плюс
каждые 15 минут делаются резервные копии новых данных. В результате
максимально возможная потеря данных составляет 15 минут.&lt;/p&gt;
&lt;p&gt;Сервера с MS SQL объединены в failover кластера, при выходе из строя
одного из серверов, находящийся в режиме ожидания сервер берет на себя
его функции. Общение с MS SQL происходит посредством JDBC драйверов.&lt;/p&gt;
&lt;p&gt;Используются как вертикальное, так и горизонтальное разбиение данных,
т.е. разные группы таблиц располагаются на разных серверах (вертикальное
партиционирование), а данные больших таблицы дополнительно
распределяются между серверами (горизонтальное партиционирование).
Встроенный в СУБД аппарат партиционирования не используется &amp;mdash; весь
процесс реализован на уровне бизнес-логики.&amp;nbsp;Распределенные транзакции не
используются &amp;mdash; всё только в пределах одного сервера. Для обеспечения
целостности, связанные данные помещаются на один сервер или, если это
невозможно, дополнительно разрабатывается логика обеспечения целостности
данных.&amp;nbsp;В запросах к БД не используются JOIN даже среди локальных таблиц
для минимизации нагрузки на CPU. Вместо этого используется
денормализация данных или JOIN происходят на уровне бизнес сервисов, что
позволяет осуществлять JOIN как с данными из баз данных, так и с данными
из кэша.&amp;nbsp;При проектировании структуры данных не используются внешние
ключи, хранимые процедуры и триггеры. Опять же для снижения потребления
вычислительных ресурсов на серверах баз данных.
SQL операторы DELETE также используются с осторожностью &amp;mdash; это самая
тяжелая операция. Данные удаляются чаще всего через маркер: запись
сначала отмечается как удаленная, а потом удаляется окончательно с
помощью фонового процесса.&amp;nbsp;Широко используются индексы, как обычные, так
и кластерные. Последние для оптимизации наиболее высокочастотных
запросов в таблицу.&lt;/p&gt;
&lt;p&gt;Используется C реализация BerkleyDB версии 4.5. Для работы с BerkleydDB
используется своя библиотека, позволяющая организовывать двухнодовые
master-slave кластера с использованием родной BDB репликация. Запись
происходит только в master, чтение происходит с обеих нод. Данные
хранятся в tmpfs, transaction логи сохраняются на дисках. Резервная
копия логов делается каждые 15 минут. Сервера одного кластера размещены
на разных лучах питания дабы не потерять обе копии одновременно. Помимо
прочего, BerkleyDB используется и в роли очереди заданий.&lt;/p&gt;
&lt;p&gt;Внутри системы используется взвешенный round robin, а также вертикальное
и горизонтальное разбиение данных как на уровне СУБД, так и на уровне
кэширования.&lt;/p&gt;
&lt;p&gt;В разработке новое решение для хранения данных, так как необходим еще
более быстрый и надежный доступ к данным.&lt;/p&gt;
&lt;h2 id="uroven-infrastruktury"&gt;Уровень инфраструктуры&lt;/h2&gt;
&lt;p&gt;Для агрегации статистики используется собственная библиотека, основанная
на log4j. Сохраняется такая информация, как количество вызовов, среднее,
максимальное и минимальное время выполнения, количество ошибок. Данные
сохраняются во временные базы, но раз в минуту данные переносятся из них
в общий склад данных (data warehouse), а временные базы очищаются. Сам
склад реализован на базе решений от Microsoft: MS SQL 2008 и сиситема
генерации отчетов Reporting Services. Он расположен на 13 серверах,
находящихся в отдельной от production среде. Некоторые из них отвечают
за статистику в реальном времени, а некоторые за ведение и
предоставление доступа к архиву. Общий объем статистических данных
составляет 13Тб.&amp;nbsp;Планируется внедрение многомерного анализа статистики
на основе OLAP.&lt;/p&gt;
&lt;p&gt;Управление сервисами происходит через самописную централизованную
систему конфигурации. Через веб-интерфейс доступно изменение
расположения портлетов, конфигурации кластеров, изменение логики
сервисов и прочее. Вся конфигурация сохраняется в базе данных. Каждый из
серверов периодически проверяет, есть ли обновления для приложений,
которые на нем запущены, и, если есть, применяет их.&lt;/p&gt;
&lt;p&gt;Мониторинг логически разделен на две части:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Мониторинг сервисов и компонентов&lt;/li&gt;
&lt;li&gt;Мониторинг ресурсов, оборудования и сети&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Система мониторинга сервисов также самописная и основывается на
оперативных данных с упомянутого выше склада. Мониторинг ресурсов и
здоровья оборудования же онован на Zabbix, а статистика по
использованию ресурсов серверов и сети накапливаетя в Cacti.&amp;nbsp;Для
предпринятия мер по устранению чрезвычайных ситуаций работают дежурные,
которые следят за всеми основными параметрами.&amp;nbsp;Оповещения о наиболее
критичных аномалиях приходят по смс, остальные оповещения отсылаются по
емейлу.&lt;/p&gt;
&lt;h2 id="komanda"&gt;Команда&lt;/h2&gt;
&lt;p&gt;Над проектом работают около 70 технических специалистов:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;40 разработчиков;&lt;/li&gt;
&lt;li&gt;20 системных администраторов и инженеров;&lt;/li&gt;
&lt;li&gt;8 тестеров.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Все разработчики разделены на небольшие команды до 3х человек. Каждая из
команд работает автономно и разрабатывает либо какой-то новый сервис,
либо работает над улучшением существующих. В каждой команде есть
технический лидер или архитектор, который ответственен за архитектуру
сервиса, выбор технологий и подходов. На разных этапах к команде могут
примыкать дизайнеры, тестеры и системные администраторы.&lt;/p&gt;
&lt;p&gt;Разработка ведется итерациями в несколько недель. Как пример жизненного
цикла разработки можно привести 3х недельный цикл:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;определение архитектуры;&lt;/li&gt;
&lt;li&gt;разработка, тестирование на компьютерах разработчиков;&lt;/li&gt;
&lt;li&gt;тестирование на pre-production среде, релиз на production среду.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Практически весь новый функционал делается &amp;laquo;отключаемым&amp;raquo;, типичный
процесс запуска новой функциональной возможности:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Функционал разрабатывается и попадает в production релиз;&lt;/li&gt;
&lt;li&gt;Через централизованную систему конфигурации функционал включается
    для небольшой части пользователей;&lt;/li&gt;
&lt;li&gt;Анализируется статистика активности пользователей, нагрузка на
    инфраструктуру;&lt;/li&gt;
&lt;li&gt;Если предыдущий этап прошел успешно, функционал включается
    постепенно для все большей аудитории;&lt;/li&gt;
&lt;li&gt;Если в процессе запуска собранная статистика выглядет
    неудовлетворительно, либо непозволительно вырастает нагрузка на
    инфраструктуру, то функционал отключается, анализируются причины,
    исправляются ошибки, происходит оптимизация и все повторяется с
    начала.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="podvodim-itogi"&gt;Подводим итоги&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;В отличии от остальных популярных социальных сетей в Одноклассниках
    используются технологии, рассчитанные в первую очередь на
    корпоративный рынок, начиная от обоих СУБД и заканчивая
    операционными системами.&lt;/li&gt;
&lt;li&gt;Во многом этот факт обуславливает комплексный подход к генерации
    пользовательского интерфейса, не слишком высокую производительность
    и многие другие особенности этой социальной сети.&lt;/li&gt;
&lt;li&gt;Использование "тяжелых" технологий с самого начала оставило
    Одноклассники с большим количеством доставшегося по наследству от
    ранних версий устаревшего кода и купленных давно лицензий на
    проприетарный софт, которые выступают в роли оков, от которых
    довольно сложно избавиться.&lt;/li&gt;
&lt;li&gt;Возможно эти факторы и являются одними из основных препятствий на
    пути к завоеванию большей доли рынка и быстрому развитию платформы
    как в функциональном, так и техническом плане.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Tue, 22 Mar 2011 00:17:00 +0300</pubDate><guid>tag:www.insight-it.ru,2011-03-22:highload/2011/arkhitektura-odnoklassnikov/</guid><category>BerkleyDB</category><category>C. GWT</category><category>IPVS</category><category>Java</category><category>Jboss</category><category>Lucene</category><category>LVS</category><category>MSSQL</category><category>openSUSE</category><category>Tomcat</category><category>Windows</category><category>Архитектура Одноклассников</category><category>Масштабируемость</category><category>Одноклассники</category></item><item><title>Архитектура Wikimedia</title><link>https://www.insight-it.ru//highload/2008/arkhitektura-wikimedia/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/687b5b81/" rel="nofollow" target="_blank" title="http://wikimedia.org"&gt;Wikimedia&lt;/a&gt; является платформой для
&lt;a href="https://www.insight-it.ru/goto/35f4fea7/" rel="nofollow" target="_blank" title="http://wikipedia.org"&gt;Wikipedia&lt;/a&gt;, &lt;a href="https://www.insight-it.ru/goto/389e980c/" rel="nofollow" target="_blank" title="http://wiktionary.org"&gt;Wiktionary&lt;/a&gt; и
еще семи менее крупных wiki-проектов. Этот документ очень пригодится
новичкам, пытающимся довести свои проекты до масштабов гигантских
вебсайтов. Здесь можно найти множество интересных деталей и
инновационных идей, которые уже успели доказать свою работоспособность
на самых посещаемых сайтах всего Интернета.
&lt;!--more--&gt;&lt;/p&gt;
&lt;h3 id="istochniki-informatsii"&gt;Источники информации&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Перевод &lt;a href="https://www.insight-it.ru/goto/cd47c021/" rel="nofollow" target="_blank" title="http://highscalability.com/wikimedia-architecture"&gt;статьи&lt;/a&gt;.
Автор - &lt;a href="https://www.insight-it.ru/goto/f3f1b405/" rel="nofollow" target="_blank" title="http://highscalability.com/user/todd-hoff"&gt;Todd Hoff&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/c8e5f8d0/" rel="nofollow" target="_blank" title="http://www.nedworks.org/~mark/presentations/san/Wikimedia%20architecture.pdf"&gt;Архитектура Wikimedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/62eceab/" rel="nofollow" target="_blank" title="http://meta.wikimedia.org/wiki/Wikimedia_servers"&gt;Серверы Wikimedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/c56ad62f/" rel="nofollow" target="_blank" title="http://oracle2mysql.wordpress.com/2007/08/22/12/"&gt;scale-out vs scale-up&lt;/a&gt; из блога "Oracle to MySQL"&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="platforma"&gt;Платформа&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/apache/"&gt;Apache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/squid/"&gt;Squid&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/lvs/"&gt;LVS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/lucene/"&gt;Lucene&lt;/a&gt; для поиска&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;Memcached&lt;/a&gt; для распределенного кэширования объектов&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/lighttpd/"&gt;lighttpd&lt;/a&gt; для работы с изображениями&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="statitstika"&gt;Статитстика&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;8 миллионов статей распределены по сотням языковых подпроектов
    (английские, голландские, ...)&lt;/li&gt;
&lt;li&gt;В десятке самых высоконагруженных проектов по данным
    &lt;a href="https://www.insight-it.ru/goto/3b390e59/" rel="nofollow" target="_blank" title="http://alexa.com"&gt;Alexa&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Экспоненциальный рост: в терминах посетителей, трафика и серверов
    удвоение происходит каждые 4-6 месяцев&lt;/li&gt;
&lt;li&gt;30000 HTTP запросов в секунду в периоды пиковой нагрузки&lt;/li&gt;
&lt;li&gt;3 GBps трафик данных&lt;/li&gt;
&lt;li&gt;3 датацентра: Тампа, Амстердам, Сеул&lt;/li&gt;
&lt;li&gt;350 серверов, конфигурации варьируются от однопроцессорных Pentium 4
    с 512 MB оперативной памяти до двухпроцессорных Xeon Quad-Core с 16
    GB RAM.&lt;/li&gt;
&lt;li&gt;Управляется ~6 людьми&lt;/li&gt;
&lt;li&gt;Три кластера на трех разных континентах&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="arkhitektura"&gt;Архитектура&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Географическая балансировка нагрузки, основываясь на IP клиента,
    перенаправляет их на ближайший кластер. Происходит статическое
    отображение множества IP адресов на множество стран, а затем и на
    множество кластеров.&lt;/li&gt;
&lt;li&gt;Кэширование с помощью &lt;a href="/tag/squid/"&gt;Squid&lt;/a&gt; группируется по типу
    контента: текст для wiki отдельно от изображений и больших
    статических файлов.&lt;/li&gt;
&lt;li&gt;На данный момент функционирует 55 &lt;a href="/tag/squid/"&gt;Squid&lt;/a&gt; серверов, плюс
    еще 20 подготавливается к запуску.&lt;/li&gt;
&lt;li&gt;1000 HTTP запросов в секунду на каждый сервер, в периоды повышенной
    нагрузки эта цифра может достигать 2500.&lt;/li&gt;
&lt;li&gt;~ 100-250 MBps на сервер.&lt;/li&gt;
&lt;li&gt;~ 14000-32000 открытых соединений на каждом сервере.&lt;/li&gt;
&lt;li&gt;До 40 GB дискового кэша на каждом Squid сервере.&lt;/li&gt;
&lt;li&gt;До 4 дисков в каждом сервере (1U серверы).&lt;/li&gt;
&lt;li&gt;8 GB оперативной памяти, половину использует &lt;a href="/tag/squid/"&gt;Squid&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/e669c01a/" rel="nofollow" target="_blank" title="http://www.powerdns.com"&gt;PowerDNS&lt;/a&gt; предоставляет геораспределение.&lt;/li&gt;
&lt;li&gt;В основном и региональных датацентрах текстовые и медиа кластеры
    построены на &lt;a href="/tag/lvs/"&gt;LVS&lt;/a&gt;,
    &lt;abbr title="Common Address Redundancy Protocol"&gt;CARP&lt;/abbr&gt;
&lt;a href="/tag/squid/"&gt;Squid&lt;/a&gt;, кэш &lt;a href="/tag/squid/"&gt;Squid&lt;/a&gt;. В основном датацентре
    также находится хранилище медиа-данных.&lt;/li&gt;
&lt;li&gt;Для того, чтобы обеспечить предоставление только последних версий
    страниц, всем Squid-серверам отправляются инвалидационные запросы.&lt;/li&gt;
&lt;li&gt;Централизованно управляемая и синхронизированная установка
    программного обеспечения для сотен серверов.&lt;/li&gt;
&lt;li&gt;MediaWiki отлично масштабируется с несколькими процессорами, так что
    закупаются двухпроцессорный четырех ядерные серверы (8 ядер на
    сервер).&lt;/li&gt;
&lt;li&gt;Одно и то же оборудование выполняет как задачи внешнего хранения
    данных, так и кэширования &lt;a href="/tag/memcached/"&gt;Memcached&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;Memcached&lt;/a&gt; используется для кэширования метаданных
    изображений, данных парсера, различий между ревизиями,
    пользователей, сессий. Метаданные, такие как история ревизий,
    отношений статей (ссылки, категории и так далее), учетные записи
    пользователей хранятся в основных базах данных&lt;/li&gt;
&lt;li&gt;Сам текст находится во внешних хранилищах данных.&lt;/li&gt;
&lt;li&gt;Статические (загруженные пользователями) файлы, например
    изображения, хранятся отдельно на сервере изображений, а метаданные
    (размер, тип и так далее) кэшируются в основной базе данных и
    объектном кэше.&lt;/li&gt;
&lt;li&gt;Отдельная база данных для каждой вики (не отдельный сервер!).&lt;/li&gt;
&lt;li&gt;Один master и много реплицированных slave серверов.&lt;/li&gt;
&lt;li&gt;Операции чтения равномерно распределяются по slave серверам,
    операции записи направляются на master.&lt;/li&gt;
&lt;li&gt;Иногда master используется и для операция чтения, когда репликация
    на slave еще не завершена.&lt;/li&gt;
&lt;li&gt;Внешнее хранение данных:&lt;ul&gt;
&lt;li&gt;Текст статей хранится на отдельных кластерах, которые представляют
собой простой средство хранения данных с возможностью только
дописывания новых данных. Такой подход позволяет сохранить
дорогостоящее место в высоконагруженных основных базах данных от
редко используемой информации.&lt;/li&gt;
&lt;li&gt;Благодаря этому появляются дополнительные неиспользованные ресурсы
на серверах приложений (порой 250-500 GB на сервер).&lt;/li&gt;
&lt;li&gt;На данной момент используются реплицируемые кластеры из 3
&lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt; серверов, но в будущем это может измениться, так
как требуется более удобное управление ими.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="podvodim-itogi"&gt;Подводим итоги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Сфокусируйтесь на архитектуре, а не на операциях или чем-то другом.&lt;/li&gt;
&lt;li&gt;Иногда кэширование обходится дороже, чем повторные вычисление или
    поиск данных в исходном источнике.&lt;/li&gt;
&lt;li&gt;Старайтесь избегать сложных алгоритмов, запросов к базе данных и
    тому подобного.&lt;/li&gt;
&lt;li&gt;Кэшируйте каждый результат, который дорого вам обошелся и является
    относительно локальным.&lt;/li&gt;
&lt;li&gt;Сфокусируйтесь на "горячих точках" в коде.&lt;/li&gt;
&lt;li&gt;Масштабируйтесь разделением:&lt;ul&gt;
&lt;li&gt;операций чтения и записи (master/slave);&lt;/li&gt;
&lt;li&gt;сложных операций и более частых и простых (группы запросов);&lt;/li&gt;
&lt;li&gt;больших, популярных вики и более мелких.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Улучшайте кэширование: временная и пространственная локализация
    данных, а также уменьшение набора данных на каждом сервере.&lt;/li&gt;
&lt;li&gt;Выполняйте компрессию текстовых данных, храните только изменения в
    статьях.&lt;/li&gt;
&lt;li&gt;Казалось бы простые вызовы библиотечных функций порой на практике
    могут занимать слишком много времени.&lt;/li&gt;
&lt;li&gt;Скорость поиска данных на диске ограничена, так что чем больше
    дисков - тем лучше!&lt;/li&gt;
&lt;li&gt;Масштабирование с использованием обычного оборудование не означает
    использование самых дешевых вещей, которые удастся найти. Серверы
    баз данных Wikipedia сегодня представляют собой 16GB RAM, двух- или
    четырех-ядерные серверы с 6 15000 rpm SCSI дисками, организованными
    в RAID 0. Возможно они бы и использовали более дешевые системы, но
    16 GB как раз хватает для размещения основного объема данных, а
    остальное берут на себя жесткие диски, это вполне соответствует
    потребностям системы, которую они построили. Примерно по таким же
    причинам их веб-сервера имеют 8 ядер, так как это позволяет достичь
    неплохой производительности &lt;a href="/tag/php/"&gt;PHP&lt;/a&gt; при достаточно простой
    организации балансировки нагрузки.&lt;/li&gt;
&lt;li&gt;Для масштабирования требуется выполнение массы работы, но если
    заранее этого не предусмотреть - понадобится сделать еще больше.
    MediaWiki изначально была написана для одного master сервера баз
    данных. Затем добавилась поддержка slave. Затем добавилось
    распределение по языкам и проектам. Дизайн системы с тех пор
    прекрасно выдерживает все нагрузки, но без очистки от новых узких
    мест системы не обошлось.&lt;/li&gt;
&lt;li&gt;Каждый, кто хочет разработать свою базу данных таким образом, чтобы
    она позволила недорого масштабироваться с уровня одного сервера до
    уровня десятки лучших сайтов Интернета, должен начать с обработки
    слегка устаревших данных на реплицированных slave серверах, при этом
    не забывать балансировать нагрузку операций чтения между slave
    серверами. Если это возможно - блоки данных (группы пользователей,
    учетных записей, или чего угодно) должны размещаться каждый на
    разных серверах. Можно делать это с самого начала используя
    виртуализацию, чтобы удостовериться в работоспособности архитектуры,
    когда вы еще "маленькие". Это &lt;strong&gt;намного&lt;/strong&gt; проще, чем когда вы
    делаете то же самое, но под ежемесячно удваивающейся нагрузкой.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 28 Mar 2008 15:32:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-03-28:highload/2008/arkhitektura-wikimedia/</guid><category>Apache</category><category>lighttpd</category><category>Linux</category><category>Lucene</category><category>LVS</category><category>Memcached</category><category>MySQL</category><category>PHP</category><category>Squid</category><category>архитектура</category><category>архитектура Wikimedia</category><category>геораспределение</category><category>Масштабируемость</category></item></channel></rss>
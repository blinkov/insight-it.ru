<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/keshirovanie/feed/index.xml" rel="self"></atom:link><lastBuildDate>Sat, 20 Oct 2012 12:32:00 +0400</lastBuildDate><item><title>Оптимизация интерактивных сайтов</title><link>https://www.insight-it.ru//interactive/2012/optimizaciya-interaktivnykh-sajjtov/</link><description>&lt;p&gt;Возвращаясь к теме&amp;nbsp;&lt;a href="https://www.insight-it.ru/interactive/"&gt;"Интерактивных сайтов"&lt;/a&gt;,&amp;nbsp;сегодня я хотел бы обсудить заключительную часть повествования, их
&lt;strong&gt;оптимизацию&lt;/strong&gt;. Возможно вы уже успели реализовать все или часть
обсуждавшихся в предыдущих статьях приемов, в этой статье я "подкину"
Вам еще несколько.&amp;nbsp;Настоятельно рекомендую прежде чем читать дальше
ознакомиться хотя бы с первой статьей про общую архитектуру, а лучше,
конечно, со всеми предыдущими статьями серии. В этот раз мы пройдемся по
всем обсуждавшимся в отдельных статьях компонентам, правда в другом
порядке, и будем обсуждать возможные пути их улучшения.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2 id="oglavlenie-serii-interaktivnye-saity"&gt;Оглавление серии "Интерактивные сайты"&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://www.insight-it.ru/interactive/2012/arkhitektura-interaktivnykh-sajjtov/"&gt;Общая архитектура&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.insight-it.ru/interactive/2012/klientskaya-chast-interaktivnogo-sajjta/"&gt;Организация клиентской части&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.insight-it.ru/interactive/2012/postoyannoe-soedinenie-mezhdu-brauzerom-i-serverom/"&gt;Постоянное соединение между браузером и сервером&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.insight-it.ru/interactive/2012/povtornoe-ispolzovanie-shablonov/"&gt;Повторное использование шаблонов&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.insight-it.ru/interactive/2012/servernaya-chast-interaktivnogo-sajjta-i-potoki-soobshhenijj/"&gt;Серверная часть интерактивного сайта и потоки сообщений&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://www.insight-it.ru/interactive/2012/optimizaciya-interaktivnykh-sajjtov/"&gt;Оптимизация&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="servernaia-chast"&gt;Серверная часть&lt;/h2&gt;
&lt;p&gt;На серверной стороне есть масса простора для оптимизации, но, чтобы не
распыляться, постараюсь сосредоточиться лишь на том, что напрямую
связано с темой &lt;em&gt;интерактивных сайтов&lt;/em&gt;. В частности на процессе
маршрутизации сообщений и уведомлений между пользователями.&lt;/p&gt;
&lt;p&gt;Когда разрабатывается первая версия сайта, то многие части функционала
проще всего реализовать в виде массовых рассылок, как-то так: произошло
какое-то публично-доступное событие, допустим кто-то куда-то поставил
"мне нравится", отправляем его в брокер сообщений с пометкой "доставить
всем" &lt;em&gt;(fanout)&lt;/em&gt;. В итоге все подключенные на данный момент клиенты
получают это уведомление и каждый сам решает что с ним делать - что-то
менять на текущей странице или просто проигнорировать.&lt;/p&gt;
&lt;p&gt;Но при большом количестве соединений и потоке событий такой подход
становится роскошью. Большинство подобных ситуаций можно реализовать
подпиской на тематические &lt;em&gt;(topic)&lt;/em&gt; рассылки для каждого пользователя
индивидуально, то есть когда пользователь открывает ту или иную
страницу - серверная сторона должна подписать его на уведомления,
связанные именно с тем контентом, который находится у него на экране.
Это позволит свести к минимуму количество&amp;nbsp;доставленных&amp;nbsp;зря сообщений.&lt;/p&gt;
&lt;p&gt;Ситуации, когда правда нужны массовые рассылки по всем пользователям,
хоть и редки, но все же бывают. Если есть возможность их избежать, то
лучшей ей воспользоваться.&lt;/p&gt;
&lt;p&gt;Чтобы реализовать индивидуальные подписки как изложено выше, вероятно
понадобится еще и изменить принцип установления соединений между
брокером сообщений и сервером, поддерживающим постоянное соединение. Для
схемы массовых рассылок достаточно одного такого соединения на сервер.
Каждый сервер хранит список активных соединений с браузерами и, получив
новое сообщение от брокера, просто итеративно проходится по нему,
ретранслируя сообщение в каждое соединение. В таком случае для
последнего соединения в списке задержка может достигать нескольких
секунд, что не всегда приемлемо. Для схемы индивидуальных подписок есть
два основных варианта:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Реализовать мини-брокер внутри каждого такого сервера, т.е. сам
    сервер по-прежнему держит лишь одно соединение с настоящим брокером
    и получает все подряд сообщения, но прежде чем ретранслировать
    анализирует его и отправляет лишь части соединений.&lt;/li&gt;
&lt;li&gt;Либо держать создавать много примитивных процессов, которые с одной
    стороны держат соединение с браузером, с другой - с брокером. Каждый
    из них подписан именно на те сообщения, которые нужны данному
    пользователю, и ретранслируют их все без анализа.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="card blue lighten-4"&gt;
&lt;p&gt;&lt;div class="card-content"&gt;
Оба варианта имеют право на существование, какой окажется лучше -
зависит от многих факторов, нужно тестировать. Лично мне больше по душе
второй, но далеко не на каждой платформе его удастся эффективно
реализовать - настоящих системных процессов для такого использования
не&amp;nbsp;напасешься.
&lt;/div&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;h2 id="postoiannoe-soedinenie-mezhdu-brauzerom-i-serverom"&gt;Постоянное соединение между браузером и сервером&lt;/h2&gt;
&lt;p&gt;Помимо выбора удачной библиотеки абстракции протоколов для различных
браузеров, о чем я уже довольно подробно писал в соответствующей статье
серии, здесь я могу предложить еще два момента для значительного
улучшения производительности.&lt;/p&gt;
&lt;h3 id="mezhvkladochnoe-vzaimodeistvie-cross-tab-communication"&gt;Межвкладочное взаимодействие &lt;em&gt;(cross-tab communication)&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;На эту тему в Интернете ходит масса слухов и разговоров, но адекватной
инструкции о том как это можно кроссбраузерно организовать в разумные
сроки я не встречал, если кто знает - дайте в ссылку в комментариях,
пожалуйста. А я пока попробую поделиться своим опытом.&lt;/p&gt;
&lt;p&gt;Вкратце для тех, кто не в курсе: в самой простой реализации постоянное
соединение между браузером и сервером устанавливается для каждой вновь
открытой вкладки заново. Так как каждое такое соединение ресурсоемко, то
этого хотелось бы избежать. Помочь в этом может организация
&lt;strong&gt;межвкладочного взаимодействия&lt;/strong&gt; или, другими словами, общения между
вкладками/окнами браузера: одна вкладка избирается &lt;em&gt;главной&lt;/em&gt; и
устанавливает соединение с сервером, когда она получает новое
сообщение - она переправляет его конкретной открытой вкладке или же всем
сразу; те же, в свою очередь, когда хотят отправить сообщение на сервер,
отправляют его сначала &lt;em&gt;главной&lt;/em&gt; вкладке, а та уже пересылает на сервер.
В итоге все работает как и раньше, но соединений не больше одного на
браузер.&lt;/p&gt;
&lt;p&gt;Вообще в явном виде общение между вкладками браузера, как Вы, вероятно,
знаете, не предусмотрено. Именно из-за этого реализовать это все
кроссбраузерно не просто. Для начала приведу список технологий, которые
так или иначе можно для этого приспособить, большинство из них принято
относить к нынче модному &lt;a href="/tag/html5/"&gt;HTML5&lt;/a&gt;, в порядке возрастания
моих симпатий:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/704e1f8a/" rel="nofollow" target="_blank" title="http://en.wikipedia.org/wiki/Local_shared_object"&gt;Flash Local Shared Cookies&lt;/a&gt; - даже не рассматривал как вариант, так как требуется Adobe Flash, плюс, кажется, постоянно всплывает окно вроде
    &lt;a href="https://www.insight-it.ru/goto/e9a669cc/" rel="nofollow" target="_blank" title="http://www.macromedia.com/support/documentation/en/flashplayer/help/help06.html"&gt;этого&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/732af670/" rel="nofollow" target="_blank" title="http://caniuse.com/#feat=x-doc-messaging"&gt;postMessage&lt;/a&gt;&amp;nbsp;-&amp;nbsp;отправка
    сообщения указанному окну по его идентификатору. Поддержка
    браузерами хорошая, но большинство примеров показывают общение с
    iframe, а сопутствующего API для получения списка всех открытых
    окон/вкладок я не нашел, может быть плохо искал.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/86256a54/" rel="nofollow" target="_blank" title="http://caniuse.com/#feat=webworkers"&gt;Web Workers&lt;/a&gt; - в браузере
    создается не зависящий от вкладок поток, с которым можно общаться из
    вкладок. Поддержка браузерами хромает, а там где её нет -
    polyfill'ов пока не придумали.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/fc6c98e9/" rel="nofollow" target="_blank" title="http://caniuse.com/#feat=namevalue-storage"&gt;Web Storage&lt;/a&gt; -
    локальное хранилище пар ключ-значение с ограничением в 5-10Мб на
    домен. Хорошая поддержка браузерами, а там где её нет - есть
    polyfill'ы. Еще бывает &lt;a href="https://www.insight-it.ru/goto/71a12fd0/" rel="nofollow" target="_blank" title="http://caniuse.com/#feat=sql-storage"&gt;Web SQL&lt;/a&gt;, но для данной задачи это уже перебор.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;В общем рекомендую последний вариант, из дополнительных плюсов хранилище
можно использовать и для других целей, но об этом в следующих разделах.&lt;/p&gt;
&lt;p&gt;Если есть желание и время можно работать напрямую с API хранилища, но
все же самостоятельно разбираться с особенностями браузеров - занятие не
благодарное, так что могу посоветовать взглянуть на имеющиеся opensource
библиотеки-обертки. Из тех, что я пробовал, мне больше всего нравится
&lt;strong&gt;&lt;a href="https://www.insight-it.ru/goto/288f4119/" rel="nofollow" target="_blank" title="http://www.jstorage.info/"&gt;jStorage&lt;/a&gt;&lt;/strong&gt;&amp;nbsp;из-за своей "зеленой" таблицы
поддержки браузерами и готовому publish/subscribe API.&lt;/p&gt;
&lt;p&gt;Итак, вкратце пройдемся по ориентировочному алгоритму реализации
межвкладочного взаимодействия:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Каждая вкладка при своем открытии придумывает себе уникальный
    идентификатор (проще всего на основе &lt;em&gt;Math.random&lt;/em&gt;), будем называть
    его &lt;strong&gt;tab_id&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;В хранилище будут храниться список всех активных tab_id, допустим,
    &lt;strong&gt;tabs&lt;/strong&gt; и tab_id &lt;em&gt;главной&lt;/em&gt; &lt;em&gt;вкладки&lt;/em&gt;, допустим,&amp;nbsp;&lt;strong&gt;master&lt;/strong&gt;. Каждая
    новая вкладка смотрит есть ли другие открытые вкладки. Если есть -
    просто дописывает себя в tabs, если нет - то еще и объявляет себя
    главной и открывает соединение с браузером.&lt;/li&gt;
&lt;li&gt;Далее она подписывается на сообщения отправленные лично ей (по её
    tab_id) и на различные типы сообщений, которые могут быть интересны
    всем вкладкам.&lt;/li&gt;
&lt;li&gt;В обработчике события &lt;em&gt;window.onbeforeunload&lt;/em&gt;&amp;nbsp;(происходит сразу же
    перед закрытием вкладки) каждая вкладка убирает себя из &lt;strong&gt;tabs&lt;/strong&gt;&amp;nbsp;и
    если она была главной, то и из &lt;strong&gt;master&lt;/strong&gt; тоже. Альтернативный
    вариант: &lt;strong&gt;master&lt;/strong&gt; сразу может выбирать себе "преемника". Так как
    это событие срабатывает не всегда (когда компьютер жестко вырубился
    питанием, фатальный сбой в браузере, плюс оно не поддерживается
    неоправданно популярной в рунете Оперой и мобильным Safari), то
    придется создать альтернативный механизм проверки активности
    &lt;strong&gt;master&lt;/strong&gt; и очистки &lt;strong&gt;tabs&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Так как какого-либо API для проверки открыта ли вкладка по её
    &lt;strong&gt;tab_id&amp;nbsp;&lt;/strong&gt;по очевидным причинам нет, нужно придумать свою схему.
    Самый простой рабочий вариант, пришедший мне в голову:&lt;ul&gt;
&lt;li&gt;Главная вкладка пишет каждые несколько сотен&amp;nbsp;миллисекунд&amp;nbsp;в
    хранилище текущую дату/время, теоретически так как все
    происходит на одном компьютере, то текущее время во всех
    вкладках должно быть одно и то же;&lt;/li&gt;
&lt;li&gt;Не-главные вкладки каждые 1-3 секунд читают значение из того же
    места в хранилище и если оно отстает от текущего на, допустим,
    больше чем секунду, то главную вкладку, вероятно, закрыли и надо
    её "свергнуть" - удалить из &lt;strong&gt;tabs&lt;/strong&gt; и &lt;strong&gt;master&lt;/strong&gt;&amp;nbsp;и назначить,
    например, первую или последнюю запись из списка&amp;nbsp;&lt;strong&gt;tabs&lt;/strong&gt; новой
    главной вкладкой;&lt;/li&gt;
&lt;li&gt;Если выбранная новая вкладка тоже оказалась уже закрыта, не
    беда - во всех случаях, кроме совсем неадекватных, этот не
    хитрый механизм переберет все&amp;nbsp;&lt;strong&gt;tabs&lt;/strong&gt; и найдет-таки нормальную
    открытую;&lt;/li&gt;
&lt;li&gt;Каждая вкладка подписывается на изменения значения &lt;strong&gt;master&lt;/strong&gt;,
    чтобы если новое значение совпадет с её tab_id открыть
    соединение с сервером.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Отправка сообщений происходит по простому publish/subscribe, где
    master подписывается и ретранслирует в соединение с сервером, а
    отправляют все остальные вкладки. Если вкладка отправляет запрос,
    ответ на который хочет получить только она сама (чаще всего переход
    на другую страницу сайта или отправка формы), то она указывает в
    отправляемом запросе свой "обратный адрес" в виде tab_id. Master,
    получив ответ на такое сообщение с указанным обратным адресом,
    перенаправляет его отправителю.&lt;/li&gt;
&lt;li&gt;Также в хранилище полезно иметь переменную-флаг (также с подпиской
    на изменения), обозначающую открыто ли сейчас где-то постоянное
    соединение, чтобы вместо того, чтобы отправлять сообщения&amp;nbsp;в
    никуда&amp;nbsp;вкладки использовали какой-то альтернативный способ (AJAX или
    переход по ссылке / отправка формы средствами браузера). В качестве
    альтернативы можно реализовать очередь неотправленных сообщений, но
    по факту когда с соединением проблемы, то неизвестно когда они
    устранятся и устранятся ли вообще, так что смысла в ней чаще всего
    мало.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Надеюсь вышеизложенное окажется кому-то полезным, если нужны какие-то
уточнения - не стесняйтесь спрашивать в комментариях.&lt;/p&gt;
&lt;h3 id="minimizatsiia-razmera-soobshchenii"&gt;Минимизация размера сообщений&lt;/h3&gt;
&lt;p&gt;&lt;a href="/tag/json/"&gt;JSON&lt;/a&gt; хоть и сильно выигрывает у &lt;a href="/tag/xml/"&gt;XML&lt;/a&gt;&amp;nbsp;по объему
сериализованных сообщений, но все же является текстовым форматом с
указанием схемы (название для каждого значения) внутри самого сообщения.
Почему минимизация объема передаваемых по постоянному соединению
данных - дело полезное, объяснять, думаю, не стоит.&lt;/p&gt;
&lt;p&gt;Первое, что приходит в голову, чтобы уменьшить объем сообщений -
избавиться от включенной в них схемы, оставив только чистые данные.
Изобретать свой формат ни к чему, есть неплохой&amp;nbsp;широко
распространенный&amp;nbsp;кандидат в виде &lt;a href="/tag/google/"&gt;Google&lt;/a&gt;&amp;nbsp;&lt;a href="/tag/protocol-buffers/"&gt;Protocol
Buffers&lt;/a&gt;. Кстати, недавно нашел библиотеку с
&lt;a href="/tag/javascript/"&gt;JavaScript&lt;/a&gt; реализацией Protocol Buffers с хорошими
отзывами, в ближайшее время думаю сам опробую:
&lt;a href="https://www.insight-it.ru/goto/a420ea/" rel="nofollow" target="_blank" title="https://github.com/sirikata/protojs"&gt;protojs&lt;/a&gt;. Если кто уже работал с
ней - буду рад, если поделитесь впечатлениями.&lt;/p&gt;
&lt;p&gt;Но на практике оказалось, что эта самая схема обычно занимает максимум
10-20% от сообщения, так как большинство данных все же текстовые.
Использование Protocol Buffers было бы намного более выгодным, если бы
было необходимо "упаковать" много чисел или флагов, для текстовых данных
выигрыш намного меньше.&lt;/p&gt;
&lt;p&gt;Экономии в разы можно добиться используя обычные алгоритмы компрессии
(или, если так привычнее, архивации) данных.
&lt;a href="/tag/javascript/"&gt;JavaScrtipt&lt;/a&gt; "из коробки" этого делать не умеет, но
есть полно библиотек на любой вкус и цвет, правда все хромают и чаще
всего не кроссбраузерные. Приведу несколько, которые запомнились после
вечера, проведенного за изучением данного вопроса:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/be52f434/" rel="nofollow" target="_blank" title="http://rosettacode.org/wiki/LZW_compression"&gt;LZW&lt;/a&gt; - есть реализации
    на большинстве языков программирования, но компрессия не очень
    сильная (раза в полтора-два в лучшем случае), плюс реализация под
    интересующий меня &lt;a href="/tag/erlang/"&gt;Erlang&lt;/a&gt; оказалась дико неэффективна
    по памяти, а на бинарных строках сходу не нашлась.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/49c64f8e/" rel="nofollow" target="_blank" title="https://github.com/imaya/zlib.js"&gt;zlib.js&lt;/a&gt; - умеет &lt;em&gt;zlib (deflate)&lt;/em&gt;
    и &lt;em&gt;gzip&lt;/em&gt;, но, к сожалению, в моем браузере не могла разжать обратно
    то, что сжала, плюс объем кода библиотеки очень большой.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/730dabaf/" rel="nofollow" target="_blank" title="https://github.com/dankogai/js-deflate"&gt;js-deflate&lt;/a&gt; - не
    обновлялась уже 4 года, отсутствует документация, но зато в целом
    работает. Подбирать метод компрессии для серверной стороны пришлось
    почти экспериментально, оказался &lt;em&gt;zlib (deflate)&lt;/em&gt; без заголовков и
    контрольной суммы (в &lt;a href="/tag/erlang/"&gt;Erlang&lt;/a&gt; встроенная функция zlib:zip). Компрессия примерно в 3-4 раза.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Если все же решите использовать компрессию, то рекомендую реализовать
флаг для ситуаций когда в клиенте все же декомпрессия по каким-то
причинам сломана. Достаточно просто сжать-разжать короткую строку и
сравнить с оригиналом, если не совпало или выскочило исключение -
просить сервер отвечать без компрессии.&lt;/p&gt;
&lt;p&gt;По поводу дополнительных вычислительных ресурсов, которые будут
потребляться на компрессию/декомпрессию, вопрос, конечно, спорный, в
целом надо все мерять и делать выводы. Но если учесть, что почти во всех
современных устройствах, даже телефонах, как минимум 1Ггц процессор, а
на сервере можно кэшировать уже сжатые данные, то это не особо большая
проблема. К слову объем сообщений уменьшается тоже не гарантированно,
бывает что "сжатая" версия оказывается такой же или даже чуть больше,
чем оригинал. В общем, использовать компрессию нужно осторожно :)&lt;/p&gt;
&lt;h2 id="povtornoe-ispolzovanie-shablonov_1"&gt;Повторное использование шаблонов&lt;/h2&gt;
&lt;p&gt;Сообщение со списком шаблонов для использование на клиентской части,
вероятно, будет самым большим по объему и больше других выиграет от
компрессии. Но есть возможность легко минимизировать и количество таких
сообщений. Помните, я писал, что локальное хранилище в браузере можно и
для других целей использовать?&lt;/p&gt;
&lt;p&gt;Кэширование шаблонов - идеальный пример. Получив от сервера шаблоны он
кладет их не только в объект-обертку, но и в локальное хранилище. На
сервере помимо самого JSON'а с шаблонами генерируем хэш (md5, sha или
crc - не важно) текущей версии. Клиент, когда открывает соединение,
сообщает серверу есть ли у него какая-то версия и если есть, то какая,
сервер отправляет новую версию в ответ только если хэши не совпали.&lt;/p&gt;
&lt;p&gt;Аналогичным образом можно кэшировать и другую редко меняющуюся объемную
информацию, например данные для автодополнения в текстовых полях
&lt;em&gt;(autocomplete)&lt;/em&gt;.&lt;/p&gt;
&lt;h2 id="zakliuchenie"&gt;Заключение&lt;/h2&gt;
&lt;p&gt;Надеюсь предложенные в этой статье приемы окажутся Вам полезны. Буду
рад, если Вы поделитесь своим опытом и приемами по данной теме в
комментариях, а также с удовольствием обсужу подробности.&lt;/p&gt;
&lt;div class="card green"&gt;
&lt;p&gt;&lt;div class="card-content white-text"&gt;
Эта статья - шестая и заключительная в &lt;a class="green-text text-lighten-4" href="https://www.insight-it.ru/interactive/"&gt;серии про Интерактивные сайты&lt;/a&gt;, автор - &lt;a class="green-text text-lighten-4" href="https://www.insight-it.ru/goto/b03d9116/" rel="nofollow" target="_blank" title="http://blinkov.ru"&gt;Иван&amp;nbsp;Блинков&lt;/a&gt;, основано на личном опыте.
До встречи &lt;a class="green-text text-lighten-4" href="/feed/"&gt;на страницах Insight IT&lt;/a&gt;!
&lt;/div&gt;&lt;/p&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sat, 20 Oct 2012 12:32:00 +0400</pubDate><guid>tag:www.insight-it.ru,2012-10-20:interactive/2012/optimizaciya-interaktivnykh-sajjtov/</guid><category>deflate</category><category>html5</category><category>JavaScript</category><category>JSON</category><category>jStorage</category><category>Protocol Buffers</category><category>Web Storage</category><category>zlib</category><category>клиентская оптимизация</category><category>компрессия</category><category>кэширование</category><category>оптимизация</category></item><item><title>Масштабируемые веб-архитектуры</title><link>https://www.insight-it.ru//theory/2008/masshtabiruemye-veb-arkhitektury/</link><description>&lt;p&gt;&lt;img alt="Масштабируемость" class="right" src="https://www.insight-it.ru/images/display.png"/&gt;
Уже немало слов было сказано по этой теме как в моем блоге, так и за
его пределами. Мне кажется настал подходящий момент для того, чтобы
перейти от частного к общему и попытаться взглянуть на данную тему
отдельно от какой-либо успешной ее реализации.&lt;/p&gt;
&lt;p&gt;Приступим?
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;Для начала имеет смысл определиться с тем, о чем мы вообще будем
говорить. В данном контексте перед веб-приложением ставятся три основные
цели:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;масштабируемость&lt;/strong&gt; - способность своевременно реагировать на
    непрерывный рост нагрузки и непредвиденные наплывы пользователей;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;доступность&lt;/strong&gt; - предоставление доступа к приложению даже в случае
    чрезвычайных обстоятельств;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;производительность&lt;/strong&gt; - даже малейшая задержка в загрузке страницы
    может оставить негативное впечатление у пользователя.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Основной темой разговора будет, как не трудно догадаться,
масштабируемость, но и остальные цели не думаю, что останутся в стороне.
Сразу хочется сказать пару слов про доступность, чтобы не возвращаться к
этому позднее, подразумевая как "само собой разумеется": любой сайт так
или иначе стремится к тому, чтобы функционировать максимально стабильно,
то есть быть доступным абсолютно всем своим потенциальным посетителям в
абсолютно каждый момент времени, но порой случаются всякие
непредвиденные ситуации, которые могут стать причиной временной
недоступности. Для минимизации потенциального ущерба доступности
приложения необходимо избегать наличия компонентов в системе,
потенциальный сбой в которых привел бы к недоступности какой-либо
функциональности или данных (или хотябы сайта в целом). Таким образом
каждый сервер или любой другой компонент системы должен иметь хотябы
одного дублера (не важно в каком режиме они будут работать: параллельно
или один "подстраховывает" другой, находясь при этом в пассивном
режиме), а данные должны быть реплицированы как минимум в двух
экземплярах (причем желательно не на уровне RAID, а на разных физических
машинах). Хранение нескольких резервных копий данных где-то отдельно от
основной системы (например на специальных сервисах или на отдельном
кластере) также поможет избежать многих проблем, если что-то пойдет не
так. Не стоит забывать и о финансовой стороне вопроса: подстраховка на
случай сбоев требует дополнительных существенных вложений в
оборудование, которые имеет смысл стараться минимизировать.&lt;/p&gt;
&lt;p&gt;Масштабируемость принято разделять на два направления:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Вертикальная масштабируемость&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Увеличение производительности каждого компонента системы c целью
повышения общей производительности.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Горизонтальная масштабируемость&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Разбиение системы на более мелкие структурные компоненты и
разнесение их по отдельным физическим машинам (или их группам) и/или
увеличение количества серверов параллельно выполняющих одну и ту же
функцию.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Так или иначе, при разработке стратегии роста системы приходится искать
компромис между ценой, временем разработки, итоговой производительность,
стабильностью и еще массой других критериев. С финансовой точки зрения
вертикальная масштабируемость является далеко не самым привлекательным
решением, ведь цены на сервера с большим количеством процессоров всегда
растут практически экспоненциально относительно количества процессоров.
Именно по-этому наиболее интересен горизонтальный подход, так как именно
он используется в большинстве случаев. Но и вертикальная
масштабируемость порой имеет право на существование, особенно в
ситуациях, когда основную роль играет время и скорость решения задачи, а
не финансовый вопрос: ведь купить БОЛЬШОЙ сервер существенно быстрее,
чем практически заново разрабатывать приложения, адаптируя его к работе
на большом количестве параллельно работающих серверов.&lt;/p&gt;
&lt;p&gt;Закончив с общими словами давайте перейдем к обзору потенциальных
проблем и вариантов их решений при горизонтальном масштабировании.
Просьба особо не критиковать - на абсолютную правильность и
достоверность не претендую, просто "мысли вслух", да и даже упомянуть
все моменты данной темы у меня определенно не получится.&lt;/p&gt;
&lt;h3 id="servery-prilozhenii"&gt;Серверы приложений&lt;/h3&gt;
&lt;p&gt;В процессе масштабирования самих приложений редко возникают проблемы,
если при разработке всегда иметь ввиду, что каждый экземпляр приложения
должен быть непосредственно никак не связан со своими "коллегами" и
должен иметь возможность обработать абсолютно любой запрос пользователя
вне зависимости от того где обрабатывались предыдущие запросы данного
пользователя и что конкретно он хочет от приложения в целом в текущий
момень.&lt;/p&gt;
&lt;p&gt;Далее, обеспечив независимость каждого отдельного запущенного
приложения, можно обрабатывать все большее и большее количество запросов
в единицу времени просто увеличивая количество параллельно
функционирующих серверов приложений, участвующих в системе. Все
достаточно просто (относительно).&lt;/p&gt;
&lt;h3 id="balansirovka-nagruzki"&gt;Балансировка нагрузки&lt;/h3&gt;
&lt;p&gt;Следущая задача - равномерно распределить запросы между доступными
серверами приложений. Существует масса подходов к решению этой задачи и
еще больше продуктов, предлагающих их конкретную реализацию.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Оборудование&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Сетевое оборудование, позволяющее распределять нагрузку между
несколькими серверами, обычно стоит достаточно внушительные суммы,
но среди прочих вариантов обычно именно этот подход предлагает
наивысшую производительность и стабильность (в основном благодаря
качеству, плюс такое оборудование иногда поставляется парами,
работающими по принципу
&lt;a href="https://www.insight-it.ru/goto/a40f2b94/" rel="nofollow" target="_blank" title="http://en.wikipedia.org/wiki/Heartbeat_%28program%29"&gt;HeartBeat&lt;/a&gt;).
В этой индустрии достаточно много серьезных брендов, предлагающих
свои решения - есть из чего выбрать: &lt;em&gt;Cisco&lt;/em&gt;, &lt;em&gt;Foundry&lt;/em&gt;, &lt;em&gt;NetScalar&lt;/em&gt;
и многие другие.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Программное обеспечение&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;В этой области еще большее разнообразие возможных вариантов.
Получить программно производительность сопоставимую с аппаратными
решениями не так-то просто, да и HeartBeat придется обеспечивать
программно, но зато оборудование для функционирования такого решения
представляет собой обычный сервер (возможно не один). Таких
программных продуктов достаточно много, обычно они представляют
собой просто HTTP-серверы, перенаправляющие запросы своим коллегам
на других серверах вместо отправки напрямую на обработку
интерпретатору языка программирования. Для примера можно упомянуть,
скажем, &lt;a href="/tag/nginx/"&gt;nginx&lt;/a&gt; с &lt;code&gt;mod_proxy&lt;/code&gt;. Помимо этого имеют
место более экзотические варианты, основанные на DNS, то есть в
процессе определения клиентом IP-адреса сервера с необходимым ему
интернет-ресурсов адрес выдается с учетом нагрузки на доступные
сервера, а также некоторых географических соображений.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Каждый вариант имеет свой ассортимент положительных и отрицательных
сторон, именно по-этому однозначного решения этой задачи не существует -
каждый вариант хорош в своей конкретной ситуации. Не стоит забывать, что
никто не ограничивает Вас в использовании лишь одного из них, при
необходимости может запросто быть реализована и практически произвольная
комбинация из них.&lt;/p&gt;
&lt;h3 id="resursoemkie-vychisleniia"&gt;Ресурсоемкие вычисления&lt;/h3&gt;
&lt;p&gt;Во многих приложениях используются какие-либо сложные механизмы, это
может быть конвертирование видео, изображений, звука, или просто
выполнение каких-либо ресурсоемких вычислений. Такие задачи требует
отдельного внимания если мы говорим о Сети, так как пользователь
интернет-ресурса врядли будет счастлив наблюдать за загружающейся
несколько минут страницей в ожидании лишь для того, чтобы увидеть
сообщение вроде: "Операция завершена успешно!".&lt;/p&gt;
&lt;p&gt;Для избежания подобных ситуаций стоит постараться минимизировать
выполнение ресурсоемких операций синхронно с генерацией интернет
страниц. Если какая-то конкретная операция не влияет на новую страницу,
отправляемую пользователю, то можно просто организовать &lt;em&gt;очередь&lt;/em&gt;
заданий, которые необходимо выполнить. В таком случае в момент когда
пользователь совершил все действия, необходимые для начала операции,
сервер приложений просто добавляет новое задание в очередь и сразу
начинает генерировать следущую страницу, не дожидаясь результатов. Если
задача на самом деле очень трудоемкая, то такая очередь и обработчики
заданий могут располагаться на отдельном сервере или кластере.&lt;/p&gt;
&lt;p&gt;Если результат выполнения операции задействован в следующей странице,
отправляемой пользователю, то при асинхронном ее выполнении придется
несколько схитрить и как-либо отвлечь пользователя на время ее
выполнения. Например, если речь идет о конвертировании видео в &lt;strong&gt;flv&lt;/strong&gt;,
то например можно быстро сгенерировать скриншот с первым кадром в
процессе составления страницы и подставить его на место видео, а
возможность просмотра динамически добавить на страницу уже после, когда
конвертирование будет завершено.&lt;/p&gt;
&lt;p&gt;Еще один неплохой метод обработки таких ситуаций заключается просто в
том, чтобы попросить пользователя "зайти попозже". Например, если сервис
генерирует скриншоты веб-сайтов из различных браузеров с целью
продемонстрировать правильность их отображения владельцам или просто
интересующимся, то генерация страницы с ними может занимать даже не
секунды, а минуты. Наиболее удобным для пользователя в такой ситуации
будет предложение посетить страницу по указанному адресу через
столько-то минут, а не ждать у моря погоды неопределенный срок.&lt;/p&gt;
&lt;h3 id="sessii"&gt;Сессии&lt;/h3&gt;
&lt;p&gt;Практически все веб-приложения каким-либо образом взаимодействуют со
своими посетителями и в подавляющем большинстве случаев в них
присутствует необходимость отслеживать перемещения пользователей по
страницам сайта. Для решения этой задачи обычно используется механизм
&lt;em&gt;сессий&lt;/em&gt;, который заключается в присвоении каждому посетителю
уникального идентификационного номера, который ему передается для
хранения в cookies или, в случае их отсутствия, для постоянного
"таскания" за собой через GET. Получив от пользователя некий ID вместе с
очередным HTTP-запросом сервер может посмотреть в список уже выданных
номеров и однозначно определить кто его отправил. С каждым ID может
ассоциироваться некий набор данных, который веб-приложение может
использовать по своему усмотрению, эти данные обычно по-умолчанию
хранятся в файле во временной директории на сервере.&lt;/p&gt;
&lt;p&gt;Казалось бы все просто, но... но запросы посетителей одного и того же
сайта могут обрабатывать сразу несколько серверов, как же тогда
определить не был ли выдан полученный ID на другом сервере и где вообще
хранятся его данные?&lt;/p&gt;
&lt;p&gt;Наиболее распространенными решениями является централизация или
децентрализация сессионных данных. Несколько абсурдная фраза, но,
надеюсь, пара примеров сможет прояснить ситуацию:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Централизованное хранение сессий&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Идея проста: создать для всех серверов общую "копилку", куда они
смогут складывать выданные ими сессии и узнавать о сессиях
посетителей других серверов. В роли такой "копилки" теоретически
может выступать и просто примонтированная по сети файловая система,
но по некоторым причинам более перспективным выглядит использование
какой-либо СУБД, так как это избавляет от массы проблем, связанных с
хранением сессионных данных в файлах. Но в варианте с общей базой
данных не стоит забывать, что нагрузка на него будет неуклонно расти
с ростом количества посетителей, а также стоит заранее предусмотреть
варианты выхода из проблематичных ситуаций, связанных с
потенциальными сбоями в работе сервера с этой СУБД.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Децентрализованное хранение сессий&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Наглядный пример - хранение сессий в &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;,
изначально расчитанная на распределенное хранение данных в
оперативной памяти система позволит получать всем серверам быстрый
доступ к любым сессионным данным, но при этом (в отличии от
предыдущего способа) какой-либо единый центр их хранения будет
отсутствовать. Это позволит избежать узких мест с точек зрения
производительности и стабильности в периоды повышенных нагрузок.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;В качестве альтернативы сессиям иногда используют похожие по
предназначению механизмы, построенные на cookies, то есть все
необходимые приложению данные о пользователе хранятся на клиентской
стороне (вероятно в зашифрованном виде) и запрашиваются по мере
необходимости. Но помимо очевидных преимуществ, связанных с отсутствием
необходимости хранить лишние данные на сервере, возникает ряд проблем с
безопасностью. Данные, хранимые на стороне клиента даже в зашифрованном
виде, представляют собой потенциальную угрозу для функционирования
многих приложений, так как любой желающий может попытаться
модифицировать их в своих интересах или с целью навредить приложению.
Такой подход хорош только если есть уверенность, что абсолютно любые
манипуляции с хранимые у пользователей данными безопасны. Но можно ли
быть уверенными на 100%?&lt;/p&gt;
&lt;h3 id="staticheskii-kontent"&gt;Статический контент&lt;/h3&gt;
&lt;p&gt;Пока объемы статических данных невелики - никто не мешает хранить их в
локальной файловой системе и предоставлять доступ к ним просто через
отдельный легковесный веб-сервер вроде &lt;a href="/tag/lighttpd/"&gt;lighttpd&lt;/a&gt; (я
подразумеваю в основном разные формы медиа-данных), но рано или поздно
лимит сервера по дисковому пространству или файловой системы по
количеству файлов в одной директории будет достигнут, и придется думать
о перераспределении контента. Временным решением может стать
распределение данных по их типу на разные сервера, или, возможно,
использование иерархической структуры каталогов.&lt;/p&gt;
&lt;p&gt;Если статический контент играет одну из основных ролей в работе
приложения, то стоит задуматься о применении распределенной файловой
системы для его хранения. Это, пожалуй, один из немногих способов
горизонтально масштабировать объем дискового пространства путем
добавления дополнительных серверов без каких-либо кардинальных изменений
в работе самого приложения. На какой именно кластерной файловой системе
остановить свой выбор ничего сейчас советовать не хочу, я уже
опубликовал далеко не один обзор конкретных реализаций - попробуйте
прочитать их все и сравнить, если этого мало - вся остальная Сеть в
Вашем распоряжении.&lt;/p&gt;
&lt;p&gt;Возможно такой вариант по каким-либо причинам будет нереализуем, тогда
придется "изобретать велосипед" для реализации на уровне приложения
принципов схожих с сегментированием данных в отношении СУБД, о которых я
еще упомяну далее. Этот вариант также вполне эффективен, но требует
модификации логики приложения, а значит и выполнение дополнительной
работы разработчиками.&lt;/p&gt;
&lt;p&gt;Альтернативой этим подходам выступает использование так называемых
&lt;strong&gt;Content Delievery Network&lt;/strong&gt; - внешних сервисов, обеспечивающих
доступность Вашего контента пользователям за определенное материальное
вознаграждение сервису. Преимущество очевидно - нет необходимости
организовывать собственную инфраструктуру для решения этой задачи, но
зато появляется другая дополнительная статья расходов. Список таких
сервисов приводить не буду, если кому-нибудь понадобится - найти будет
не трудно.&lt;/p&gt;
&lt;h3 id="keshirovanie"&gt;Кэширование&lt;/h3&gt;
&lt;p&gt;Кэширование имеет смысл проводить на всех этапах обработки данных, но в
разных типах приложений наиболее эффективными являются лишь некоторые
методы кэширования.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;СУБД&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Практически все современные СУБД предоставляют встроенные механизмы
для кэширования результатов определенных запросов. Этот метод
достаточно эффективен, если Ваша система регулярно делает одни и те
же выборки данных, но также имеет ряд недостатков, основными из
которых является инвалидация кэша всей таблицы при малейшем ее
изменении, а также локальное расположение кэша, что неэффективно при
наличии нескольких серверов в системе хранения данных.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Приложение&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;На уровне приложений обычно производится кэширование объектов любого
языка программирования. Этот метод позволяет вовсе избежать
существенной части запросов к СУБД, сильно снижая нагрузку на нее.
Как и сами приложения такой кэш должен быть независим от конкретного
запроса и сервера, на котором он выполняется, то есть быть доступным
всем серверам приложений одновременно, а еще лучше - быть
распределенным по нескольким машинам для более эффективной
утилизации оперативной памяти. Лидером в этом аспекте кэширования по
праву можно назвать &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, о котором я в свое
время уже успел &lt;a href="https://www.insight-it.ru/storage/2008/obzor-memcached/"&gt;подробно рассказать&lt;/a&gt;.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;HTTP-сервер&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Многие веб-серверы имеют модули для кэширования как статического
контента, так и результатов работы скриптов. Если страница редко
обновляется, то использование этого метода позволяет без каких-либо
видимых для пользователя изменений избегать генерации страницы в
ответ на достаточно большую часть запросов.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Reverse proxy&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Поставив между пользователем и веб-сервером прозрачный
прокси-сервер, можно выдавать пользователю данные из кэша прокси
(который может быть как в оперативной памяти, так и дисковым), не
доводя запросы даже до HTTP-серверов. В большинстве случаев этот
подход актуален только для статического контента, в основном разных
форм медиа-данных: изображений, видео и тому подобного. Это
позволяет веб-серверам сосредоточиться только на работе с самими
страницами.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Кэширование по своей сути практически не требует дополнительных затрат
на оборудование, особенно если внимательно наблюдать за использованием
оперативной памяти остальными компонентами серверами и утилизировать все
доступные "излишки" под наиболее подходящие конкретному приложению формы
кэша.&lt;/p&gt;
&lt;p&gt;Инвалидация кэша в некоторых случаях может стать нетривиальной задачей,
но так или иначе универсального решения всех возможных проблем с ней
связанных написать не представляется возможным (по крайней мере лично
мне), так что оставим этот вопрос до лучших времен. В общем случае
решение этой задачи ложится на само веб-приложение, которое обычно
реализует некий механизм инвалидации средствами удаления объекта кэша
через определенный &lt;em&gt;период времени&lt;/em&gt; после его создания или последнего
использования, либо "вручную" при возникновении определенных &lt;em&gt;событий&lt;/em&gt;
со стороны пользователя или других компонентов системы.&lt;/p&gt;
&lt;h3 id="bazy-dannykh"&gt;Базы данных&lt;/h3&gt;
&lt;p&gt;На закуску я оставил самое интересное, ведь этот неотъемлемый компонент
любого веб-приложения вызывает больше проблем при росте нагрузок, чем
все остальные вместе взятые. Порой даже может показаться, что стоит
вообще отказаться от горизонтального масштабирования системы хранения
данных в пользу вертикального - просто купить тот самый БОЛЬШОЙ сервер
за шести- или семизначную сумму не-рублей и не забивать себе голову
лишними проблемами.&lt;/p&gt;
&lt;p&gt;Но для многих проектов такое кардинальное решение (и то, по большому
счету, временное) не подходит, а значит перед ними осталась лишь одна
дорога - горизонтальное масштабирование. О ней и поговорим.&lt;/p&gt;
&lt;p&gt;Путь практически любого веб проекта с точки зрения баз данных начинался
с одного простого сервера, на котором работал весь проект целиком. Затем
в один прекрасный момент наступает необходимость вынести СУБД на
отдельный сервер, но и он со временем начинает не справляться с
нагрузкой. Подробно останавливаться на этих двух этапах смысла особого
нет - все относительно тривиально.&lt;/p&gt;
&lt;p&gt;Следующим шагом обычно бывает &lt;strong&gt;master-slave&lt;/strong&gt; с асинхронной репликацией
данных, как работает эта схема уже неоднократно упоминалось в блоге, но,
пожалуй, повторюсь: при таком подходе все операции записи выполняются
лишь на одном сервере (master), а остальные сервера (slave) получают
данные напрямую от "мастера", обрабатывая при этом лишь запросы на
чтение данных. Как известно, операции чтения и записи любого веб-проекта
всегда растут пропорционально росту нагрузки, при этом сохраняется почти
фиксированным соотношение между обоими типами запросов: на каждый запрос
на обновление данных обычно приходится в среднем около десятка запросов
на чтение. Со временем нагрузка растет, а значит растет и количество
операций записи в единицу времени, а сервер-то обрабатывает их всего
один, а затем он же еще и обеспечивает создание некоторого количества
копий на других серверах. Рано или поздно издержки операций репликации
данных станут быть настолько высоки, что этот процесс станет занимать
очень большую часть процессорного времени каждого сервера, а каждый
slave сможет обрабатывать лишь сравнительно небольшое количество
операций чтения, и, как следствие, каждый дополнительный slave-сервер
начнет увеличивать суммарную производительность лишь незначительно, тоже
занимаясь по большей части лишь поддержанием своих данных в соответствии
с "мастером".&lt;/p&gt;
&lt;p&gt;Временным решением этой проблемы, возможно, может стать замена
master-сервера на более производительный, но так или иначе не выйдет
бесконечно откладывать переход на следующий "уровень" развития системы
хранения данных: &lt;strong&gt;"sharding"&lt;/strong&gt;, которому я совсем недавно посвятил
&lt;a href="https://www.insight-it.ru/theory/2008/segmentirovanie-bazy-dannykh/"&gt;отдельный пост "Сегментирование баз данных"&lt;/a&gt;.
Так что позволю себе остановиться на нем лишь вкратце: идея заключается
в том, чтобы разделить все данные на части по какому-либо признаку и
хранить каждую часть на отдельном сервере или кластере, такую часть
данных в совокупности с системой хранения данных, в которой она
находится, и называют сегментом или &lt;em&gt;shard&lt;/em&gt;&amp;rsquo;ом. Такой подход позволяет
избежать издержек, связанных с реплицированием данных (или сократить их
во много раз), а значит и &lt;em&gt;существенно&lt;/em&gt; увеличить общую
производительность системы хранения данных. Но, к сожалению, переход к
этой схеме организации данных требует массу издержек другого рода. Так
как готового решения для ее реализации не существует, приходится
модифицировать логику приложения или добавлять дополнительную
"прослойку" между приложением и СУБД, причем все это чаще всего
реализуется силами разработчиков проекта. Готовые продукты способны лишь
облегчить их работу, предоставив некий каркас для построения основной
архитектуры системы хранения данных и ее взаимодействия с остальными
компонентами приложения.&lt;/p&gt;
&lt;p&gt;На этом этапе цепочка обычно заканчивается, так как сегментированные
базы данных могут горизонтально масштабироваться для того, чтобы в
полной мере удовлетворить потребности даже самых высоконагруженных
интернет-ресурсов. К месту было бы сказать пару слов и о собственно
самой структуре данных в рамках баз данных и организации доступа к ним,
но какие-либо решения сильно зависят от конкретного приложения и
реализации, так что позволю себе лишь дать пару общих рекомендаций:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Денормализация&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Запросы, комбинирующие данные из нескольких таблиц, обычно при
прочих равных требуют большего процессорного времени для выполнения,
чем запрос, затрагивающий лишь одну таблицу. А производительность,
как уже упоминалось в начале повествования, чрезвычайно важна на
просторах Сети.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Логическое разбиение данных&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Если какая-то часть данных всегда используется отдельно от основной
массы, то иногда имеет смысл выделить ее в отдельную независимую
систему хранения данных.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Низкоуровневая оптимизация запросов&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Ведя и анализируя логи запросов, можно определить наиболее медленные
из них. Замена найденных запросов на более эффективные с той же
функциональностью может помочь более рационально использовать
вычислительные мощности.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;В этом разделе стоит упомянуть еще один, более специфический, тип
интернет-проектов. Такие проекты оперируют данными, не имеющими четко
формализованную структуру, в таких ситуациях использование реляционных
СУБД в качестве хранилища данных, мягко говоря, нецелесообразно. В этих
случаях обычно используют менее строгие базы данных, с более примитивной
функциональностью в плане обработки данных, но зато они способны
обрабатывать огромные объемы информации не придираясь к его качеству и
соответствию формату. В качестве основы для такого хранилища данных
может служить кластерная файловая система, а для анализа же данных в
таком случае используется механизм под названием
&lt;a href="/tag/mapreduce/"&gt;MapReduce&lt;/a&gt;, принцип его работы я расскажу лишь вкратце,
так как в полном своем масштабе он несколько выходит за рамки данного
повествования.&lt;/p&gt;
&lt;p&gt;Итак, мы имеем на входе некие произвольные данные в не факт что
правильно соблюденном формате. В результате нужно получить некое
итоговое значение или информацию. Согласно данному механизму практически
любой анализ данных можно провести в следующие два этапа:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Основной целью данного этапа является представление произвольных
входных данных в виде промежуточных пар ключ-значение, имеющих
определенный смысл и формально оформленных. Результаты подвергаются
сортировке и группированию по ключу, а после чего передаются на
следующий этап.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Reduce&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Полученные после &lt;strong&gt;map&lt;/strong&gt; значения используются для финального
вычисления требуемых итоговых данных.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Каждый этап каждого конкретного вычисления реализуется в виде
независимого мини-приложения. Такой подход позволяет практически
неограниченно распараллеливать вычисления на огромном количестве машин,
что позволяет в мгновения обрабатывать объемы практически произвольных
данных. Для этого достаточно лишь запустить эти приложения на каждом
доступном сервере одновременно, а затем собрать воедино все результаты.&lt;/p&gt;
&lt;p&gt;Примером готового каркаса для реализации работы с данными по такому
принципу служит opensource проект Apache Foundation под названием
&lt;a href="https://www.insight-it.ru/storage/2008/hadoop/"&gt;&lt;em&gt;Hadoop&lt;/em&gt;&lt;/a&gt;, о котором я уже неоднократно
рассказывал ранее, да и &lt;a href="https://www.insight-it.ru/goto/1a5b89d0/" rel="nofollow" target="_blank" title="http://ru.wikipedia.org/wiki/Hadoop"&gt;статейку в Википедию&lt;/a&gt; написал в свое время.&lt;/p&gt;
&lt;h3 id="vmesto-zakliucheniia"&gt;Вместо заключения&lt;/h3&gt;
&lt;p&gt;Если честно, мне с трудом верится, что я смог написать настолько
всеобъемлющий пост и сил на подведение итогов уже практически не
осталось. Хочется лишь сказать, что в разработке крупных проектов важна
каждая деталь, а неучтенная мелочь может стать причиной провала. Именно
по-этому в этом деле учиться стоит не на своих ошибках, а на чужих.&lt;/p&gt;
&lt;p&gt;Хоть может быть этот текст и выглядит как некое обобщение всех постов из
серии &lt;a href="https://www.insight-it.ru/highload/"&gt;"Архитектуры высоконагруженных систем"&lt;/a&gt;, но врядли он
станет финальной точкой, надеюсь мне &lt;a href="/feed/"&gt;найдется что сказать&lt;/a&gt; по
этой теме и в будущем, может быть однажды это будет основано и на личном
опыте, а не просто будет результатом переработки массы полученной мной
информации. Кто знает?...&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Mon, 12 May 2008 09:00:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-05-12:theory/2008/masshtabiruemye-veb-arkhitektury/</guid><category>online</category><category>архитектура</category><category>веб-приложение</category><category>веб-проект</category><category>веб-сервер</category><category>геораспределение</category><category>информационные технологии</category><category>кэширование</category><category>Масштабируемость</category><category>распределенные вычисления</category><category>сегментирование баз данных</category></item><item><title>Обзор memcached</title><link>https://www.insight-it.ru//storage/2008/obzor-memcached/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/62123c99/" rel="nofollow" target="_blank" title="http://www.danga.com/memcached/"&gt;&lt;strong&gt;memcached&lt;/strong&gt;&lt;/a&gt; представляет собой
высокопроизводительную распределенную систему кэширования объектов в
оперативной памяти.&lt;/p&gt;
&lt;p&gt;Оформлена она в виде классического &lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'а, слушающего
подключения на одном из TCP-портов (по-умолчанию: 11211). Работа же с
ним осуществляется с помощью клиентских библиотек, доступных практически
для всех популярных языков программирования.
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; не использует конфигурационные файлы, но
все же может быть в какой-то степени настроен под свои нужды с помощью
параметров, указываемых при запуске &lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'а, и
переменных окружения. Например, часто используется параметр &lt;strong&gt;-m&lt;/strong&gt;,
позволяющий указать объем используемой для хранения объектов оперативной
памяти.
По сути кэширование с помощью &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; представляет
собой некое подобие глобального ассоциативного массива, то есть набора
соответствий &lt;em&gt;ключ &amp;rarr; объект&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="kak-zhe-ono-rabotaet"&gt;Как же оно работает?&lt;/h3&gt;
&lt;p&gt;Принцип очень прост: после установления соединения между клиентом
(произвольное приложение, воспользовавшееся услугами одной из клиентских
библиотек) и сервером (распределенной системой, состоящей из
&lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'ов), клиенту предоставляется возможность выполнять
четыре примитивных действия для организации кэширования:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;set&lt;/strong&gt; - установить соответствие между ключом и указанным объектом;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;add&lt;/strong&gt; - аналогично &lt;em&gt;set&lt;/em&gt;, но только при условии, что объекта с
    таким ключом в кэше нет;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;replace&lt;/strong&gt; - абсолютная противоположность &lt;em&gt;add&lt;/em&gt;, выполняется только
    если такой объект в кэше есть;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;get&lt;/strong&gt; - получить объект из кэша по указанному ключу.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Вывод напрашивается лишь один: проще не придумаешь.&lt;/p&gt;
&lt;h3 id="v-sravnenii"&gt;В сравнении&lt;/h3&gt;
&lt;p&gt;Многие &lt;a href="/tag/subd/"&gt;СУБД&lt;/a&gt; предоставляют встроенные средства кэширования,
но на практике они умеют кэшировать только результаты запросов, что не
всегда является именно тем, что необходимо веб-приложению. СУБД обычно
полностью очищают кэш таблицы при каждом изменении данных, что приводит
к полной его бесполезности при активном обновлении таблиц.&lt;/p&gt;
&lt;p&gt;Еще один альтернативный вариант кэширования может предоставить
http-сервер, в большинстве случаев кэш дублируется несколько раз для
каждого процесса &lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, &lt;a href="/tag/perl/"&gt;Perl&lt;/a&gt; или любого другого
используемого языка программирования. Помимо излишних затрат оперативной
памяти, такой вариант развития событий еще и снижает эффективность
самого кэша.&lt;/p&gt;
&lt;h3 id="na-praktike"&gt;На практике&lt;/h3&gt;
&lt;p&gt;Использование &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; на практике в написании
приложений ничуть не сложнее, чем в теории. Например, если говорить о
&lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, то для доступа к &lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'y достаточно
установить соответствующий &lt;a href="https://www.insight-it.ru/goto/a0e58a5c/" rel="nofollow" target="_blank" title="http://pecl.php.net/package/memcache"&gt;PECL extension&lt;/a&gt;, который предоставит класс &lt;strong&gt;Memcached&lt;/strong&gt;. С помощью его методов осуществляется доступ ко всем возможностям &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, о которых я уже упоминал: &lt;strong&gt;connect&lt;/strong&gt;, &lt;strong&gt;set&lt;/strong&gt;, &lt;strong&gt;add&lt;/strong&gt;, &lt;strong&gt;get&lt;/strong&gt; и так далее.&lt;/p&gt;
&lt;p&gt;Для многих других языков программирования также существуют API, список
которых можно &lt;a href="https://www.insight-it.ru/goto/94c7c37e/" rel="nofollow" target="_blank" title="http://www.danga.com/memcached/apis.bml"&gt;найти на официальном сайте&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="o-chem-ne-stoit-zabyvat"&gt;О чем не стоит забывать&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Кэш не является базой данных!&lt;/em&gt; Не стоит забывать, что кэш является
&lt;em&gt;очень&lt;/em&gt; ненадежным местом хранения данных, не предоставляет избыточности
и каких-либо гарантий, что сохраненная в нем информация будет доступна
через какое-то время. За производительность приходится платить.&lt;/p&gt;
&lt;h3 id="v-zakliuchenii"&gt;В заключении&lt;/h3&gt;
&lt;p&gt;...хотелось бы сказать, что эта &lt;a href="/tag/tekhnologiya/"&gt;технология&lt;/a&gt; является
очень производительным и эффективным решением вопроса кэширования для
масштабных интернет-проектов. Возможности по ее применению не
ограничиваются Сетью, ведь она реализована в виде обычного daemon'а, что
открывает ее для всего спектра программного обеспечения, так или иначе
следующего &lt;a href="/tag/unix-way/"&gt;"Unix&amp;nbsp;way"&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Thu, 21 Feb 2008 18:08:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-02-21:storage/2008/obzor-memcached/</guid><category>cash</category><category>cashing</category><category>daemon</category><category>Memcached</category><category>информационные технологии</category><category>кэш</category><category>кэширование</category><category>производительность</category><category>реализация</category><category>технология</category><category>unix way</category></item></channel></rss>
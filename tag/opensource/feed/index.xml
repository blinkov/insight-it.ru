<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/opensource/feed/index.xml" rel="self"></atom:link><lastBuildDate>Sat, 31 Mar 2012 00:08:00 +0400</lastBuildDate><item><title>Twitter Storm</title><link>https://www.insight-it.ru//highload/2012/twitter-storm/</link><description>&lt;p&gt;&lt;em&gt;&lt;a href="https://www.insight-it.ru/goto/964382fd/" rel="nofollow" target="_blank" title="https://github.com/nathanmarz/storm/"&gt;Storm&lt;/a&gt; является распределенной
системой для выполнения вычислений в реальном времени.&lt;/em&gt; Она родилась в
рамках проекта Backtype, который специализировался на аналитике твитов и
который в июле 2011 был приобретен &lt;a href="/tag/twitter/"&gt;Twitter&lt;/a&gt;. Так же как
&lt;a href="/tag/apache/"&gt;Apache&lt;/a&gt; &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; предоставляет набор
базовых абстракций, инструментов и механизмов для пакетной обработки
данных, &lt;strong&gt;Twitter Storm&lt;/strong&gt; делает это для задачи обработки данных &lt;em&gt;в
режиме реального времени&lt;/em&gt;. Хотите узнать в чем их отличие?&lt;/p&gt;
&lt;!--more--&gt;
&lt;h2 id="otlichie"&gt;Отличие&lt;/h2&gt;
&lt;p&gt;Не смотря на то, что &lt;em&gt;Storm&lt;/em&gt; изначально появился на свет в процессе
неудачных попыток приспособить &lt;em&gt;Hadoop&lt;/em&gt; к задаче обработки данных в
реальном времени, сравнивать их некорректно. Никакой хак или патч не
сможет заставить Hadoop работать по-настоящему в режиме реального
времени, так как в его основе лежит фундаментально другая концепция и
набор принципов, которые актуальны лишь в контексте задачи пакетной
обработки данных. &lt;strong&gt;Storm&lt;/strong&gt; можно представить как &lt;strong&gt;"Hadoop для
вычислений в реальном времени"&lt;/strong&gt;, но по факту между ними нет практически
ничего общего, кроме изначально-распределенной природы, слегка похожей
архитектуры, работы внутри JVM и публичной доступности. Для понимания
задачи, которая стоит перед Storm, лучше взглянуть на то, как она обычно
решается.&lt;/p&gt;
&lt;p&gt;Традиционно, если перед проектом или бизнесом вставала задача обработки
какой-то информации в реальном времени, то она в итоге сводилась к
цепочке преобразований данных и распределялась по серверам, которые их
выполняют и передают результаты друг другу посредством сообщений и
очередей-посредников. При таком подходе &lt;em&gt;существенная&lt;/em&gt; часть времени
уходила на маршрутизацию сообщений, настройку и развертывание новых
промежуточных очередей и обработчиков, обеспечение отказоустойчивости и
надежности. По сути &lt;strong&gt;Storm&lt;/strong&gt; берет все вышеперечисленное на себя,
позволяя разработчикам сосредоточиться на реализации логики обработки
сообщений.&lt;/p&gt;
&lt;h2 id="osobennosti"&gt;Особенности&lt;/h2&gt;
&lt;p&gt;Итак, основные особенности Storm, вытекающие из требований к подобным
системам:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Три основных варианта использования, но ими он не ограничивается:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Обработка потоков сообщений&lt;/strong&gt; &lt;em&gt;(stream processing)&lt;/em&gt; в реальном
времени, с возможностью внесения изменений во внешние базы данных;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Постоянные вычисления&lt;/strong&gt;&amp;nbsp;&lt;em&gt;(continuous computation)&lt;/em&gt; на основе
источников данных с публикацией результатов произвольным клиентам в
реальном времени;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Распределенные удаленные вызовы&lt;/strong&gt; &lt;em&gt;(distributed RPC)&lt;/em&gt; с
выполнением комплексных вычислений параллельно во время запроса.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Масштабируемость:&lt;/strong&gt; Storm может обрабатывать огромное количество
сообщений в секунду. Для масштабирование необходимо лишь добавить
сервера в кластер и увеличить параллельность в настройках топологии. В
одном из первых приложений для Storm обрабатывался 1 миллион сообщений в
секунду на кластере из 10 серверов, при этом выполнялось несколько сотен
запросов в секунду к внешней базе данных.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Гарантия отсутствия потерь данных:&lt;/strong&gt;&amp;nbsp;в отличии от других систем
обработки сообщений в реальном времени (например
&lt;a href="https://www.insight-it.ru/goto/9cb3bfa0/" rel="nofollow" target="_blank" title="http://incubator.apache.org/s4"&gt;S4&lt;/a&gt; от Yahoo!) это свойство изначально
является частью архитектуры Storm.&amp;nbsp;Для этого используется механизм
подтверждения&amp;nbsp;&lt;em&gt;(acknowledgement)&lt;/em&gt;&amp;nbsp;успешной обработки каждого конкретного
сообщения.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Стабильность:&lt;/strong&gt;&amp;nbsp;в то время как &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; позволительны
простои по несколько часов, так как он априори не является системой
реального времени, одной из основных целей Storm является стабильная
бесперебойная работа кластера, с максимально безболезненным его
управлением.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Защита от сбоев:&lt;/strong&gt;&amp;nbsp;если что-то пошло не так во время выполнения
вычисления, Storm переназначит задачи и попробует снова. В его задачи
входит обеспечение бесконечной работы вычислений (или до момента
запланированной или ручной остановки).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Независимость от языка программирования:&lt;/strong&gt; в то время как большая
часть системы написана на &lt;a href="/tag/clojure/"&gt;Clojure&lt;/a&gt; и работает в
&lt;a href="/tag/jvm/"&gt;JVM&lt;/a&gt;, сами компоненты системы могут быть реализованы на
любом языке, что удобно для проектов, использующих в основном другие
технологии.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;У Вас уже могло сложиться общее представление, о том что собой
представляет &lt;strong&gt;Twitter Storm&lt;/strong&gt; и насколько он актуален лично для Вас или
Вашего проекта. Если интерес все еще не погас, предлагаю перейти к
концепции, предлагаемой Storm для разработки приложений под эту
платформу.&lt;/p&gt;
&lt;h2 id="kontseptsiia"&gt;Концепция&lt;/h2&gt;
&lt;p&gt;Для начала пройдемся по основным абстракциям, которые используются в
Storm:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Поток&lt;/strong&gt; &lt;em&gt;(Stream)&lt;/em&gt;: неограниченный поток сообщений, представленных в
виде кортежей (произвольных именованный список значений). При этом все
кортежи в одном потоке должны иметь одинаковую схему: элемент на каждой
позиции должен иметь один и тот же тип данных и значение.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Струя воды из крана&lt;/strong&gt;&amp;nbsp;&lt;em&gt;(Spout)&lt;/em&gt;: источник потоков, который берет их из какой-то внешней системы.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cтруя состояния&lt;/strong&gt;&amp;nbsp;&lt;em&gt;(state spout)&lt;/em&gt;: предоставляет распределенный доступ к некому общему состоянию, которое кэшируется в памяти на исполнителях и синхронно обновляется при внешних изменениях. Таким образом возможно избежать обращений к внешней базе данных при обработке каждого сообщения. В случае с Twitter этим общим состоянием является сам
социальный граф.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Молния&lt;/strong&gt; &lt;em&gt;(Bolt)&lt;/em&gt;: обрабатывает входящие потоки и создает исходящие
потоки, производя какую-либо обработку данных (по сути здесь реализуется
основная бизнес-логика). Помимо этого никто не запрещает использовать
при обработке какие угодно внешние сервисы вроде &lt;a href="/tag/subd/"&gt;СУБД&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Топология&lt;/strong&gt; &lt;em&gt;(Topology)&lt;/em&gt;: произвольная связанная сеть из "молний" и
"струй". При создании топологии можно указать:&lt;ul&gt;
&lt;li&gt;&lt;em&gt;уровень параллелизма&lt;/em&gt; для каждого компонента, что создаст
необходимое количество его потоков исполнения в кластере.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;группировку потоков&lt;/em&gt;, то есть как именно сообщения будут
распределяться между созданными потоками исполнения каждого
компонента, есть четыре основных варианта - случайно &lt;em&gt;(shuffle)&lt;/em&gt;,
каждый получит по копии &lt;em&gt;(all)&lt;/em&gt;, хэш по определенным полям сообщения
&lt;em&gt;(fields)&lt;/em&gt;, один поток получает все сообщения &amp;nbsp;&lt;em&gt;(global)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Таким образом, для создания приложения для обработки данных в реальном
времени с использованием &lt;strong&gt;Storm&lt;/strong&gt;, необходимо:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Определить схему(ы) потока(ов) сообщений.&lt;/li&gt;
&lt;li&gt;Реализовать источник(и) сообщений, основанные на парсинге каких-то
    внешних данных (для Backtype это был Twitter firehose, поток всех
    твитов) или реакции на события (допустим действия пользователей в
    виде HTTP-запросов).&lt;/li&gt;
&lt;li&gt;Реализовать обработчик(и) сообщений, которые преобразуют входящие
    сообщения и либо создают новые потоки сообщений, либо как-то влияют
    на внешний мир, например изменяя что-то в базе данных (они
    используют &lt;a href="/tag/cassandra/"&gt;Cassandra&lt;/a&gt; для этого).&lt;/li&gt;
&lt;li&gt;Объединить реализованные компоненты в топологию и запустить её на
    кластере.&lt;/li&gt;
&lt;li&gt;При необходимости оптимизировать систему, включив общее состояние в
    топологию.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;С точки зрения разработчика приложения большего знать и не нужно, но
самое интересное происходит как раз дальше. Что собой представляет
Storm-кластер и как с его помощью исполняется реализованное описанным
выше способом приложение?&lt;/p&gt;
&lt;h2 id="arkhitektura"&gt;Архитектура&lt;/h2&gt;
&lt;p&gt;Проект очень сильно завязан на &lt;a href="/tag/zookeeper/"&gt;Zookeeper&lt;/a&gt; для
координации работы кластера, с чем он очень неплохо справляется. Все
остальные компоненты системы системы не содержат в себе состояния, что
обеспечивает их быстрый запуск, даже после &lt;code&gt;kill -9&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Storm Cluster" class="responsive-img" src="https://www.insight-it.ru/images/storm-cluster.png" title="Storm Cluster"/&gt;&lt;/p&gt;
&lt;p&gt;В остальном все достаточно просто:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Мастер-сервер &lt;em&gt;(Nimbus)&lt;/em&gt; отвечает за распространение кода,
    распределение задач и мониторинг сбоев.&lt;/li&gt;
&lt;li&gt;На каждом сервере в кластере запускается процесс-надсмотрщик
    &lt;em&gt;(Supervisor)&lt;/em&gt;, который запускает локально потоки исполнения,
    отвечающие за выполнение назначенных ему компонентов топологий.&lt;/li&gt;
&lt;li&gt;Передача сообщений между компонентами топологий осуществляется
    напрямую, посредством &lt;a href="/tag/zeromq/"&gt;ZeroMQ&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Топологии являются &lt;a href="/tag/thrift/"&gt;Thrift&lt;/a&gt;-структурами, а
    мастер-сервер - &lt;a href="/tag/thrift/"&gt;Thrift&lt;/a&gt;-сервисом, что позволяет
    осуществлять регистрацию топологий и другие операции программно из
    любого языка программирования.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Присутствующий в единственном экземпляре мастер-сервер является
единственной точкой отказа лишь на первый взгляд. По факту он
используется лишь для внесение изменений в кластер и топологии, так что
его непродолжительное отсутствие не повлияет на функционирование
запущенных вычислений. А так как состояние кластера хранится в
&lt;em&gt;Zookeeper&lt;/em&gt;, то запуск мастера на другой машине в случае аппаратного
сбоя - вопрос лишь грамотно настроенного мониторинга и максимум одной
минуты.&lt;/p&gt;
&lt;p&gt;Используемый механизм подтверждений успешной обработки сообщения
&lt;em&gt;(acknowledgement)&lt;/em&gt; гарантирует, что все сообщения, попавшие в систему,
рано или поздно будут обработаны, даже при локальных сбоях оборудования.
Хотя более глобальные катаклизмы вроде "потери" стойки все же могут
нарушить функционирование системы, про работу в нескольких датацентрах
речь также не идет.&lt;/p&gt;
&lt;h2 id="plany-na-budushchee"&gt;Планы на будущее&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Использование &lt;a href="https://www.insight-it.ru/goto/6984b642/" rel="nofollow" target="_blank" title="http://incubator.apache.org/mesos"&gt;Mesos&lt;/a&gt; для
    распределения и изоляции вычислительных ресурсов.&lt;/li&gt;
&lt;li&gt;Изменение кода "на лету", сейчас для этого нужно остановить старую
    топологию и запустить новую, что может означать простой в пару
    минут.&lt;/li&gt;
&lt;li&gt;Автоматическое определения необходимого уровня параллельности и
    адаптация под изменения в интенсивности входящего потока сообщений.&lt;/li&gt;
&lt;li&gt;Еще более высокоуровневые абстракции.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="podvodim-itogi"&gt;Подводим итоги&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;На самом деле подход, лежащий в основе Storm, не является чем-то
кардинально-новым. Помимо упоминавшегося выше S4 можно найти еще
несколько альтернатив, пускай и менее близких по идеологии. Подробнее
про эту тему можно узнать погуглив &lt;strong&gt;&lt;a href="https://www.insight-it.ru/goto/c81ea66c/" rel="nofollow" target="_blank" title="http://www.google.com/search?q=complex+event+processing"&gt;complex event processing&lt;/a&gt;&lt;/strong&gt;
или &lt;strong&gt;&lt;a href="https://www.insight-it.ru/goto/14ea9c79/" rel="nofollow" target="_blank" title="http://www.google.com/search?q=real-time+stream+processing"&gt;real-time stream processing&lt;/a&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Storm&lt;/strong&gt; выделяет из их числа простота, гибкость, масштабируемость и
отказоустойчивость в одном флаконе. Обеспечивает это в первую очередь
простая и понятная архитектура, основанная на (уже) проверенном временем
и многими проектами распределенном координаторе в виде &lt;strong&gt;Zookeeper&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Хоть за проектом и стоит крупный интернет-проект в лице
&lt;a href="https://www.insight-it.ru/highload/2011/arkhitektura-twitter-dva-goda-spustya/"&gt;Twitter&lt;/a&gt;,
он достаточно молод и нужно быть морально готовым к возможным сбоям и
неудачным моментам. Плюс не забывайте, что существенная часть написана
на &lt;strong&gt;Clojure&lt;/strong&gt; - для, пожалуй, большинства разработчиков изучение
исходников проекта будет капитальным "выносом мозга". Мое первое
знакомство с &lt;strong&gt;Lisp&lt;/strong&gt; &lt;em&gt;(Clojure - его диалект, работающий в
JVM)&lt;/em&gt;&amp;nbsp;надолго засело в памяти из-за обилия скобочек за каждым углом :)&lt;/li&gt;
&lt;li&gt;В любом случае из доступных &lt;a href="/tag/opensource/"&gt;opensource&lt;/a&gt; реализаций
систем для распределенных вычислений в реальном времени &lt;strong&gt;Storm&lt;/strong&gt;&amp;nbsp;на мой
взгляд является наиболее перспективным для применения в
интернет-проектах.&lt;/li&gt;
&lt;li&gt;Если Вашему проекту нужна лишь одна-две топологии и особо большого
кластера не планируется, то подобную схему достаточно не сложно
реализовать и просто посредством &lt;strong&gt;Zookeeper&lt;/strong&gt; + &lt;strong&gt;ZeroMQ&lt;/strong&gt; или
альтернативных технологий. Это избавит проект от возможных заморочек с
Clojure и другими "особенностями" Storm, ценой вероятно существенно
большей собственной кодовой базы, которую придется самостоятельно
тестировать и поддерживать. Какой путь ближе - команда каждого проекта
решает для себя сама.&lt;/li&gt;
&lt;li&gt;Помимо различных вариаций&amp;nbsp;&lt;strong&gt;веб-аналитики&lt;/strong&gt; заманчивыми применениями
подобной системы в Интернете может стать:&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;построение индекса для поисковых систем&lt;/strong&gt;, на сколько я знаю от
&lt;a href="/tag/mapreduce/"&gt;MapReduce&lt;/a&gt; здесь отказался только
&lt;a href="https://www.insight-it.ru/highload/2011/arkhitektura-google-2011/"&gt;Google&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;поведенческий таргетинг для рекламы&lt;/strong&gt; - собираем действия
пользователей и делаем на их основе выводы в реальном времени;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ведение рейтингов чего-либо в реальном времени&lt;/strong&gt; - в зависимости
от специфики проекта можно определять и показывать лучшие, самые
просматриваемые или самые комментируемые
статьи/фото/видео/музыку/товары/комментарии/что-нибудь-еще;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;предлагаем свои варианты в комментариях&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Удачи в построении приложений для вычислений в реальном времени и &lt;a href="/feed/"&gt;до встречи на страницах &lt;strong&gt;Insight IT&lt;/strong&gt;&lt;/a&gt;!&lt;/p&gt;
&lt;h2 id="istochniki-informatsii"&gt;Источники информации&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/6f56bb97/" rel="nofollow" target="_blank" title="http://www.infoq.com/presentations/Storm"&gt;Видео презентации проекта&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/fbfa7e01/" rel="nofollow" target="_blank" title="http://www.slideshare.net/nathanmarz/storm-distributed-and-faulttolerant-realtime-computation"&gt;Слайды с презентации проекта&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/a027c9d7/" rel="nofollow" target="_blank" title="https://github.com/nathanmarz/storm"&gt;Репозиторий проекта&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sat, 31 Mar 2012 00:08:00 +0400</pubDate><guid>tag:www.insight-it.ru,2012-03-31:highload/2012/twitter-storm/</guid><category>Clojure</category><category>JVM</category><category>opensource</category><category>real time</category><category>Storm</category><category>Thrift</category><category>Twitter</category><category>Twitter Storm</category><category>ZeroMQ</category><category>ZooKeeper</category></item><item><title>Архитектура LiveJournal</title><link>https://www.insight-it.ru//highload/2008/arkhitektura-livejournal/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/e53eaf70/" rel="nofollow" target="_blank" title="http://www.livejournal.com"&gt;LiveJournal&lt;/a&gt; был одним из первых сервисов,
бесплатно предоставляющих всем желающим личный блог. Практически с
самого начала своего существования в далеком 1999 году проект столкнулся
с непрерывно растущим потоком желающих воспользоваться услугами сервиса.
Как же проекту удалось справиться с предоставлением маленького кусочка
интернета каждому желающему, обойдя при этом всех конкурентов?
&lt;!--more--&gt;&lt;/p&gt;
&lt;h3 id="istochniki-informatsii"&gt;Источники информации&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Возможно Вы ожидали увидеть здесь очередной перевод статьи с
английского, но тогда придется Вас разочаровать, на этот раз я решил
попробовать свои силы в самостоятельном написании статьи на такую
серьезную тему. Просьба особо сильно помидорами в меня не кидаться :)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Основным источником информации послужила &lt;a href="https://www.insight-it.ru/goto/a945bdaf/" rel="nofollow" target="_blank" title="http://video.google.com/videoplay?docid=-8953828243232338732"&gt;презентация Brad Fitzpatrick&lt;/a&gt;
в Токио.&lt;/p&gt;
&lt;h3 id="platforma"&gt;Платформа&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt; (&lt;a href="/tag/debian/"&gt;Debian Sarge&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/perl/"&gt;Perl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/apache/"&gt;Apache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt; 4.0/4.1 в основном с InnoDB&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/perlbal/"&gt;Perlbal&lt;/a&gt;, веб-сервер и балансировщик нагрузки&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; для распределенного кэширования&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/mogilefs/"&gt;MogileFS&lt;/a&gt;, распределенная файловая система&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/gearman/"&gt;Gearman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/theshwartz/"&gt;TheShwartz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="/tag/djabberd/"&gt;djabberd&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="statistika"&gt;Статистика&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;на данный момент 15320315 учетных записей; &lt;em&gt;(10.04.08)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;из них активно используется 551589;&lt;/li&gt;
&lt;li&gt;наиболее активно сервис используется в США и Российской федерации, а
    2/3 пользователей - девушки и женщины;&lt;/li&gt;
&lt;li&gt;более 15 миллионов новых записей в блогах за месяц;&lt;/li&gt;
&lt;li&gt;более 50 миллионов просмотров страниц в день, при пиковой нагрузке -
    несколько тысяч в секунду &lt;em&gt;(сильно устаревшие цифры, 2004 год);&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;связь с внешним миром осуществляется через два BIG-IP (активный + в
    режиме ожидания) с автоматическим восстановлением работоспособности
    в случае сбоя в работе одного из них, защитой от DDoS, L7 набором
    правил, включая TCL;&lt;/li&gt;
&lt;li&gt;более сотни серверов, насчет конфигурации известен только тот факт,
    что практически на каждом сервере установлены огромные объемы
    оперативной памяти (более 12 GB) для эффективного кэширования.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="istoriia"&gt;История&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Все началось с одного обычного сервера. Он выполнял роль как
    веб-сервера так и базы данных. Единственный плюс такого подхода к
    организации работы оборудования - достаточно дешево. Само собой
    достаточно скоро этот сервер перестал справляться с нагрузкой.&lt;/li&gt;
&lt;li&gt;Следующим шагом было разнесение веб-сервера и базы данных на разные
    серверы, всего их получилось два. По прежнему имелось два узла, сбой
    в которых означал недоступность сервиса. По прежнему вычислительная
    мощность такой системы оставалась более чем скромной.&lt;/li&gt;
&lt;li&gt;Первым из тех двух серверов, как ни странно, перестал справляться с
    нагрузкой веб-сервер - докупили еще два. Веб-сервера три, внешний
    IP - один, теперь приходится как-то распределять нагрузку! А как
    добавить еще одну базу данных?&lt;/li&gt;
&lt;li&gt;Новый сервер баз данных был подключен в роли slave к исходному,
    данные в нем обновлялись с помощью репликации, а обрабатывал он
    только операции чтения, оставив все операции записи первому серверу.&lt;/li&gt;
&lt;li&gt;Есть предположения о том, к чему привело дальнейшее добавление новых
    серверов? Правильно - к полнейшему хаосу! Со временем стала
    возникать проблема масштабируемости баз данных. Операции чтения
    производились на каком-то одном сервере, но когда приходил запрос на
    запись данных, так или иначе данные приходилось производить
    обновление на каждом из slave серверов. В итоге выполнение
    синхронизации данных стало занимать подавляющее большинство
    процессорного времени slave серверов, что привело к отсутствию
    возможности продолжать масштабирование просто добавлением
    дополнительных серверов.&lt;/li&gt;
&lt;li&gt;Пришло время задуматься над архитектурой системы и распределением
    операций записи. Основной целью стало избавиться от такой серьезной
    избыточности данных, так как это было практически пустой тратой
    времени копировать одни и те же данные на десяток машин, да еще и с
    RAID на каждой из них.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Наиболее эффективным подходом в такой ситуации является
сегментирование базы данных. Все серверы баз данных разбиваются на
небольшие кластеры. Каждый пользователь системы прозрачно
привязывается к определенному кластеру, таким образом когда он
обновляет свой блог или какие-либо еще данные, запись ведется в
рамках только небольшой группы серверов, такой же принцип справедлив
и для чтения.&lt;/p&gt;
&lt;p&gt;Применительно к LiveJournal эту схему лучше всего демонстрирует один
из слайдов презентации, указанной в источниках информации:
&lt;img alt="Сегментирование базы данных в Livejournal" class="responsive-img" src="https://www.insight-it.ru/images/lj-scheme.jpeg" title="Механизм работы сегментированной базы данных в LiveJournal"/&gt;&lt;/p&gt;
&lt;p&gt;При работе такой системы не используется &lt;code&gt;auto_increment&lt;/code&gt; в
&lt;a href="/tag/mysql/"&gt;MySQL&lt;/a&gt;, а также используется составной primary key из
номера пользователя и номера записи. Таким образом пространство имен
объектов разбито на группы, соответствующие конкретному
пользователю.&lt;/p&gt;
&lt;p&gt;Дальнейшим развитием решения проблемы излишней избыточности данных
может послужить отказ от кластеров, аналогичных по структуре
исходному для хранения сегментов базы данных. Это может быть как
вариант с общим на несколько серверов хранилищем данных, так и более
низкоуровневая репликация данных средствами &lt;abbr title="Distributed Replicated Block Device"&gt;DRBD&lt;/abbr&gt; в
совокупности с HeartBeat. Каждый из возможных вариантов
кластеризации MySQL имеет массу положительных и отрицательных
сторон, так что конкретного лидера среди них выделить достаточно
сложно. Возможно именно это и подтолкнуло разработчиков построить
собственное решение, комбинируя их с целью получения наилучшего
эффекта.&lt;/p&gt;
&lt;h3 id="programmnoe-obespechenie"&gt;Программное обеспечение&lt;/h3&gt;
&lt;p&gt;В ситуации, когда не удавалось найти готового программного решения для
какой-то конкретной задачи, они не боялись взяться за написание его
самостоятельно, это стало одним из основных компонентов успеха проекта.
Существенная часть программной платформы LiveJournal написана специально
для этого проекта и выпущено под свободной лицензией с открытым исходным
кодом, доступным в &lt;a href="https://www.insight-it.ru/goto/f135e7bd/" rel="nofollow" target="_blank" title="http://code.sixapart.com/"&gt;официальном SVN репозитории&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;memcached&lt;/h4&gt;
&lt;p&gt;Залогом быстрой загрузки любой страницы крупного интернет-проекта
является кэширование. Но как всегда возникает вопрос: а на каком уровне
обработки данных его стоит выполнять? Для динамических страниц
недопустимо кэширование на уровне готовых страниц. Можно кэшировать на
уровне &lt;code&gt;mod_perl&lt;/code&gt;, но по сути это пустая трата оперативной памяти, так
как создастся отдельный кэш для каждого потока &lt;a href="/tag/apache/"&gt;Apache&lt;/a&gt;, и
количество промахов мимо кэша будет огромно. Кэширование запросов MySQL
или HEAP таблицы также не дали бы требуемого результата ввиду
чрезвычайной распределенности базы данных.&lt;/p&gt;
&lt;p&gt;Выходом из сложившейся ситуации стало написание собственной
распределенной системы кэширования объектов, получившей название
&lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;. Она позволяет:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;использовать для кэширования свободную оперативную память
    практически любого компьютера, задействованного в системе;&lt;/li&gt;
&lt;li&gt;кэшировать объекты практически любого языка программирования в
    сериализованном виде: &lt;a href="/tag/perl/"&gt;Perl&lt;/a&gt;, &lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;,
    &lt;a href="/tag/java/"&gt;Java&lt;/a&gt;, &lt;a href="/tag/c/"&gt;C++&lt;/a&gt; и так далее;&lt;/li&gt;
&lt;li&gt;использовать для передачи кэшируемых данных простой протокол, не
    требующий избыточности данных;&lt;/li&gt;
&lt;li&gt;избегать даже теоретической возможности полного сбоя работы
    кэшируещей системы в связи с полной равнозначностью серверов;&lt;/li&gt;
&lt;li&gt;достигать превосходной производительности при формировании HTML-кода
    страниц;&lt;/li&gt;
&lt;li&gt;в разы снизить нагрузку на базы данных в проекте любого масштаба.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Этот продукт на практике оказался более чем эффективен, о чем
свидетельствует его более чем успешное использование во многих
крупнейших веб-проектах.&lt;/p&gt;
&lt;h4&gt;Perlbal&lt;/h4&gt;
&lt;p&gt;При решении вопроса, связанного с балансировкой нагрузки между
веб-серверами, пришлось перепробовать далеко не один десяток готовых
решений, но, к сожалению, ни один из них не смог удовлетворить все
потребности проекта. Не растерявшись, разработчики написали свое решение
этой задачи и назвали его &lt;a href="/tag/perlbal/"&gt;Perlbal&lt;/a&gt;. Конкурентов у него
множество, начиная от решений на уровне оборудования, например от
Foundry, заканчивая proxy балансировщиками нагрузки встроенные в более
популярные веб-сервера, но, тем не менее, продукт получился достаточно
конкурентноспособным. Он удовлетворял всем требованиям, выдвигаемым
разработчиками проекта:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;быстрый;&lt;/li&gt;
&lt;li&gt;небольшой размер;&lt;/li&gt;
&lt;li&gt;"сообразительный";&lt;/li&gt;
&lt;li&gt;обработка "мертвых" узлов;&lt;/li&gt;
&lt;li&gt;может выступать как в роли reverse proxy, так и балансировщика
    нагрузки;&lt;/li&gt;
&lt;li&gt;базовый функционал классического веб-сервера;&lt;/li&gt;
&lt;li&gt;реализация внутреннего перенаправления данных;&lt;/li&gt;
&lt;li&gt;поддержка некоторых менее существенных трюков, реализованных обычно
    в виде plug-in'ов.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="/tag/perlbal/"&gt;Perlbal&lt;/a&gt; не так активно используется вне LiveJournal, по
сравнению с &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, но для решения конкретной
задачи он подошел как нельзя лучше.&lt;/p&gt;
&lt;h4&gt;MogileFS&lt;/h4&gt;
&lt;p&gt;Идея распределенных файловых систем далеко не нова, достаточно вспомнить
лишь &lt;a href="/tag/gfs/"&gt;GFS&lt;/a&gt; или любой ее opensource аналог. Сам факт создания
такой системы был очень легок, изначальная версия была написана за одни
выходные, но при доведении ее до требуемого уровня качества пришлось
попотеть. Решение о ее создании было развитием идеи распределения
операций записи. Общая принцип хранения файлов прост: каждый файл в ФС
относится к определенному классу файлов, который определяет все правила
работы с файлом, в основном механизм его реплицирования, об остальном
заботится сама система.&lt;/p&gt;
&lt;p&gt;Как и все файловые системы этого класса,
&lt;acronym title="oMgFileS"&gt;MogileFS&lt;/acronym&gt; работает на уровне
пользовательских приложений и использует достаточно тривиальные протокол
передачи данных и общую архитектуру: клиенты, управляющие серверы,
абстрактные базы данных, сервера для хранения самих данных - в этом
плане ничего нового придумано не было. Доступ к файлам осуществляется с
помощью HTTP-запросов PUT/GET либо через виртуальный NFS-раздел.
Единственной особенностью можно назвать уклон в построение собой
абстрактной прослойки между приложением и собственно кластером базы
данных (в случае LiveJournal - сегмента), используемой в роли
альтернативы более тривиальной master/slave схемы.&lt;/p&gt;
&lt;h4&gt;Gearman&lt;/h4&gt;
&lt;p&gt;&lt;acronym title="manaGer"&gt;Gearman&lt;/acronym&gt; по сути прост до безобразия,
но это не мешает ему быть чрезвычайно эффективным. Возможно Вы уже
догадались в чем суть этого еще одного продукта, написанного специально
для LJ, если уже навели курсор на акроним в начале этого абзаца, если же
нет - поясню: он управляет общей работой системы средствами
клиент-серверной архитектуры и высокопроизводительного бинарного
протокола. С их помощью он способен удаленно вызывать практически любые
процедуры на удаленных серверах с минимальными задержками во времени.
Казалось бы ничего особенного он сам по себе не делает, но на самом деле
он выполняет очень важную функцию: увеличивает степень параллельности
выполнения операций, необходимых для полноценного функционирования
проекта. Единственное &lt;strong&gt;но&lt;/strong&gt; в работе этого механизма заключается в том,
что он не предоставляет никаких гарантий успешности выполнения работ.&lt;/p&gt;
&lt;p&gt;В рамках LiveJournal &lt;acronym title="manaGer"&gt;Gearman&lt;/acronym&gt;
применяется в основном для:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;обработка изображений средствами Image::Magick вне perl-приложений;&lt;/li&gt;
&lt;li&gt;создание pool'а DBI соединений (DBD::Gofer + Gearman);&lt;/li&gt;
&lt;li&gt;уменьшением нагрузки, создаваемой отдельными компонентами системы;&lt;/li&gt;
&lt;li&gt;улучшения субъективного впечатления пользователей о быстродействии
    сервиса, благодаря выполнению части работ параллельно в фоновом
    режиме;&lt;/li&gt;
&lt;li&gt;выполнение блокирующего ресурсы кода отдельно от обработчиков
    различных событий.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;TheShwartz&lt;/h4&gt;
&lt;p&gt;В качестве альтернативы gearman'у для работ, для выполнения которых
необходимы некоторые гарантии успешности, а также некоторая
стабильность, была разработана эта библиотека. Общая схема работы
осталась та же: клиент-серверная, но за стабильность приходится
платить - производительность существенно ниже, возможно возникновение
задержек.&lt;/p&gt;
&lt;p&gt;Хоть эти два продукта и выполняют схожие функции, используются они
обычно в совокупности друг с другом, просто-напросто обрабатывая разные
типы работ.&lt;/p&gt;
&lt;p&gt;Основными сферами применения TheShwartz в LJ являются:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;отправка электронной почты (SMTP клиент);&lt;/li&gt;
&lt;li&gt;LJ Notifications: каждое событие может вызывать за собой цепочку из
    тысяч уведомлений по электронной почте, SMS, XMPP и так далее;&lt;/li&gt;
&lt;li&gt;отправка RPC сообщений внешним сервисам;&lt;/li&gt;
&lt;li&gt;внедрение Atom потоков;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;djabberd&lt;/h4&gt;
&lt;p&gt;Как всегда следуя принципу "чем проще - тем лучше", разработки LJ
написали этот крошечный daemon, лежащий в основе их Jabber/LJTalk. Он
способен спокойно работать с более чем 300 тысячами соединений,
используя очень скромное количество оперативной памяти для поддержания
каждого соединения.&lt;/p&gt;
&lt;p&gt;Основной причиной для написания собственного Jabber-сервера, стало
недостаточная расширяемость и масштабируемость существующих решений.
Была необходимость в реализации многих нестандартных функций, вроде
индивидуальных обработчиков пользовательских изображений и личных
данных, обычно в других решениях было доступно только изменение методов
аутентификации.&lt;/p&gt;
&lt;h3 id="podvodim-itogi"&gt;Подводим итоги&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Если перед Вами появилась нетривиальная задача - не бойтесь написать
    программное обеспечение для ее решения самостоятельно! Пускай,
    возможно, это потребует некторых дополнительных усилий, но масса
    преимуществ, связанных с полным соответствием требованиям
    конкретного проекта, превосходит все издержки дополнительной
    разработки.&lt;/li&gt;
&lt;li&gt;Невозможно масштабировать проект просто постоянно добавляя новые
    сервера, рано или поздно все же прийдется задуматься об его
    архитектуре;&lt;/li&gt;
&lt;li&gt;Распределение нагрузок и параллельное операций порой заслуживают
    того, чтобы разработчики обратили на них внимание;&lt;/li&gt;
&lt;li&gt;"Мы ненавидим изобретать колесо! Но тем не менее, если колесо не
    существует или оно квадратное, то мы не боимся изобретать круглое
    колесо." (с)&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Thu, 10 Apr 2008 00:24:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-04-10:highload/2008/arkhitektura-livejournal/</guid><category>Apache</category><category>Debian</category><category>djabberd</category><category>gearman</category><category>Memcached</category><category>MogileFS</category><category>MySQL</category><category>opensource</category><category>Perl</category><category>Perlbal</category><category>TheShwartz</category><category>архитектура</category><category>архитектура LiveJournal</category><category>Масштабируемость</category></item><item><title>Hypertable</title><link>https://www.insight-it.ru//storage/2008/hypertable/</link><description>&lt;p&gt;&lt;img alt="Hypertable" class="right" src="https://www.insight-it.ru/images/hypertable-logo.gif" title="Hypertable"/&gt;
&lt;a href="https://www.insight-it.ru/goto/63463036/" rel="nofollow" target="_blank" title="http://www.hypertable.org"&gt;Hypertable&lt;/a&gt; является еще одним opensource
проектом, направленным на воспроизведение функционала
&lt;a href="/tag/bigtable/"&gt;BigTable&lt;/a&gt; от &lt;a href="/tag/google/"&gt;Google&lt;/a&gt;. Поставленная перед
проектом цель заключается в реализации системы хранения данных на базе
распределенной файловой системы, позволяющей перейти на новый уровень
производительности при работе с гигантскими объемами данных.
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;Принцип работы &lt;a href="/tag/hypertable/"&gt;Hypertable&lt;/a&gt; прост до безобразия:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Hypertable хранит данные в табличном формате, сортируя записи по
    основному ключу;&lt;/li&gt;
&lt;li&gt;для хранимых данных не используются какие-либо типы данных, любая
    ячейка интерпретируется как байтовая строка;&lt;/li&gt;
&lt;li&gt;масштабируемость достигается путем разбиения таблиц на смежные
    интервалы строк и хранения их на разных физических машинах;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;в системе используется два типа серверов:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Master Server&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&amp;ndash; как и во многих других подобных системах мастер-сервер
выполняет обязанности скорее административного характера: он
управляет работой Range серверов, работает с метаданными
(которые хранятся просто в отдельной таблице, наравне с
остальными).&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Range Server&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;&amp;ndash; их задача стоит в собственно в хранении диапазонов строк из
различных таблиц. Каждый сервер может хранить несколько
несмежных диапазонов строк, если диапазон превышает по объему
определенный лимит (по-умолчанию - 200 MB), то он разбивается на
пополам и одна половина обычно перемещяется на другой сервер.
Если же на одном из серверов подходит к концу дисковое
пространство, то под руководством мастер-сервера часть
диапазонов с него перераспределяется на менее загруженные Range
серверы.&lt;/dd&gt;
&lt;/dl&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Еще одним компонентом системы является Hyperspace, этот сервер
    предоставляет указатель на основную таблицу с метаданными, а также
    пространство имен. Помимо этого этот сервис выступает в роли
    lock-механизма для клиентов системы.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;В качестве основы для этой системы может использоваться как входящая в
состав &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; файловая система &lt;a href="/tag/hdfs/"&gt;HDFS&lt;/a&gt;, так и
&lt;a href="/tag/kfs/"&gt;KosmosFS&lt;/a&gt;, о которой я недавно
&lt;a href="https://www.insight-it.ru/storage/2008/fajjly-v-kosmose/"&gt;рассказывал&lt;/a&gt;. Это позволяет
Hypertable выступать в роли конкурента для &lt;a href="/tag/hbase/"&gt;HBase&lt;/a&gt; в рамках
проекта &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;HBase и Hypertable выполняют достаточно похожие функции и преследуют
практически одни и те же цели, но есть некоторые ньюансы. Одним из
глобальных различий в этих системах является языки программирования, с
использованием которого они реализованы. HBase написана на
&lt;a href="/tag/java/"&gt;Java&lt;/a&gt;, в то время как разработчики Hypertable предпочли
&lt;a href="/tag/c/"&gt;C++&lt;/a&gt;. Это повлекло за собой массу различий в инкапсулированной
реализации различных операций.&lt;/p&gt;
&lt;p&gt;Для доступа к данным каждая из систем использует язык HQL, только в
одном случае аббревиатура расшифровывается как HBase Query Language, а в
другом - Hypertable Query Language (как эгоистично :) ). По сути и то и
другое является сильно упрощенным диалектом &lt;a href="/tag/sql/"&gt;SQL&lt;/a&gt;, что
позволяет сократить знакомство с синтаксисом HQL до пары минут при
достаточном знании классического SQL. Хотелось бы отметить, что вся
простота в сравнении с классическим SQL и реляционными СУБД вполне
обоснована: обе системы хранения данных предназначены для использования
в совокупности с &lt;a href="/tag/mapreduce/"&gt;MapReduce&lt;/a&gt; программами, что делает их
просто хранилищем данных, а не средством их обработки.&lt;/p&gt;
&lt;p&gt;После небольшого лирического отступления в виде сравнения с HBase
хотелось бы все же вернуться к теме нашего разговора, а именно к
организации хранения данных в Hypertable. Данные хранятся в виде пар
ключ:значение, причем храняться все версии строк с указанием времени,
когда они были созданы. Таким образом легко проследить за процессом
изменения данных во времени, а также узнать какие именно операции
проводились над ними в прошлом. Стандартный механизм работы с версиями
данных может быть переопределен на хранения лишь фиксированного
количества версий строки, позволяя использовать удаление устаревших
записей для освобождения дополнительного дискового пространства.&lt;/p&gt;
&lt;p&gt;Для более эффективной работы с обновлением случайных ячеек таблиц
используется кэширование. Поступающие данные собираются в оперативной
памяти и при достижении определенного лимита сжимаются и записываются на
диск.&lt;/p&gt;
&lt;p&gt;Для более эффективной работы с распределенной файловой системой
используется механизм под названием &lt;em&gt;Access Groups&lt;/em&gt;. Суть заключается в
объединении колонок таблиц в группы, в которых они чаще всего
используется вместе. Такие группы данных по возможности храняться вместе
на физических носителях. Если запрос включает в себя только данные из
колонок одной группы доступа, то с дисков считывается только эти
колонки, в противном случае приходиться работать со всей строкой
целиком. Такой подход позволяет существенно оптимизировать работу
операций ввода/вывода.&lt;/p&gt;
&lt;p&gt;Проект еще находится в стадии разработки и до стабильного релиза ему еще
далеко, но тем не менее он уже вполне может себя показать в качестве
конкурента как для других систем подобного класса, так и для более
стандартных реляционных баз данных. Основными недостающими моментами в
этой системе в данной системе является отсутствие некоторого порой
необходимого функционала в HQL, а такжы некоторые проблемы с
отказоустойчивостью, вызванные единственностью в рамках системы Master и
Hyperspace серверов.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sat, 05 Apr 2008 20:27:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-04-05:storage/2008/hypertable/</guid><category>C++</category><category>GPL</category><category>Hadoop</category><category>HDFS</category><category>HQL</category><category>Hypertable</category><category>KFS</category><category>opensource</category></item><item><title>Gentoo Linux + Sony Vaio = ♥</title><link>https://www.insight-it.ru//linux/2008/gentoo-linux-sony-vaio/</link><description>&lt;blockquote&gt;
&lt;p&gt;Gentoo is all about choices&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img alt="Gentoo Linux" class="left" src="https://www.insight-it.ru/images/gentoo.png" title="Gentoo Linux"/&gt;&lt;/p&gt;
&lt;p&gt;Абсолютно не важно, держите ли Вы в руках блестящую болванку с надписью
&lt;em&gt;"Прощай, предустановленная Vista!"&lt;/em&gt; или только подумываете о том, чтобы
избавить свой ноутбук от тяжести этой ноши. Прочитав это повествование,
Вы сможете представить себе процесс установки альтернативной
операционной системы на ноутбук на примере &lt;em&gt;&lt;a href="/tag/gentoo/"&gt;Gentoo&lt;/a&gt;
&lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;&lt;/em&gt; и &lt;em&gt;&lt;a href="/tag/sony-vaio/"&gt;Sony Vaio&lt;/a&gt;&lt;/em&gt;. Я постараюсь
освятить все особенности этого процесса, а также по возможности дать
советы по избежанию потенциальных проблем. Не надейтесь найти здесь
пересказ &lt;a href="https://www.insight-it.ru/goto/760b4056/" rel="nofollow" target="_blank" title="Gentoo Hanbook"&gt;Gentoo
Handook&lt;/a&gt;,
ее стоит прочитать в любом случае, если Вы на самом деле задумали
установить эту очень серьезную &lt;a href="/tag/os/"&gt;операционную систему&lt;/a&gt;.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Сам я занимался этим делом уже более полугода назад на ноутбуке &lt;strong&gt;Sony
Vaio VGN-FE41ZR&lt;/strong&gt;, не знаю почему мой выбор в свое время пал именно на
эту модель, были доступны и более производительные и "навороченные" -
видимо приглянулась она мне чем-то. Далее речь пойдет именно об этой
модели ноутбука, но думаю большая часть написанного далее будет
справедлива и для других моделей линейки &lt;a href="/tag/sony-vaio/"&gt;Sony Vaio&lt;/a&gt;.
Поначалу процесс установки и настройки был очень непрост, ведь часто
приходилось пользоваться методом "проб и ошибок", да и достойную
документацию найти удавалось далеко не по каждому вопросу. Все про все
заняло далеко не один мой летний вечер, терпения потребовалось изрядное
количество, но полученный в итоге результат до сих пор не дает повода
пожалеть о потраченном свободном времени.&lt;/p&gt;
&lt;p&gt;Как я уже успел намекнуть во вступлении, начинается все с болванки на
которую записан &lt;a href="https://www.insight-it.ru/goto/3438dd73/" rel="nofollow" target="_blank" title="http://www.gentoo.org/main/ru/where.xml"&gt;тот самый волшебный
образ&lt;/a&gt;. Никто не мешает выбрать
любой из доступных вариантов, но предположим, что выбор пал на
&lt;a href="/tag/gentoo/"&gt;Gentoo&lt;/a&gt; &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt; LiveCD 2007.0. Загрузка
ноутбука с этого диска проходит плавно и непринужденно, ровно как и сама
работа с уже загруженным LiveCD как в консоли, так и в используемом там
рабочем окружении - &lt;em&gt;Gnome&lt;/em&gt;. Следуя инструкциям из &lt;em&gt;настольной книги&lt;/em&gt;
начать установку операционной системы очень нетрудно, но если честно у
меня прочитав пару раз этот немаленьких размеров текст возникла мысль
попытаться сэкономить некоторое количество времени, воспользовавшись
услугами двух предложенных автоматических инсталляторов - с графическим
и консольным пользовательским интерфейсом - не повторяйте этой ошибки,
так как качество реализации обоих вариантов на данный момент оставляет
желать лучшего, заставить успешно установить систему один из них может
занять ничуть не меньше времени, чем ручная установка. Лично мне
приручить ни один из автоматических инсталлятора так и не удалось, но
как ни странно тоже не пришлось жалеть об этом факте - как оказалось
ручная установка очень качественно позволяет разобраться в структуре
&lt;a href="/tag/os/"&gt;операционной системы&lt;/a&gt; вцелом, ровно как и в принципе работы
отдельных ее компонентов.&lt;/p&gt;
&lt;p&gt;Следовать инструкциям из &lt;em&gt;Книги&lt;/em&gt; я думаю у всех должно неплохо
получаться, единственное что могу порекомендовать: делайте это
неторопясь, стараясь как можно подробнее осознавать что, как и зачем Вы
делаете. Здесь же я хочу останавливаться лишь на специфических моментах
для этой модели ноутбуков.&lt;/p&gt;
&lt;h3 id="iadro"&gt;Ядро&lt;/h3&gt;
&lt;p&gt;Как известно, для &lt;a href="/tag/gentoo/"&gt;Gentoo&lt;/a&gt; доступно несколько вариантов
ядер, в процессе установки мой выбор пал на &lt;strong&gt;suspend2-sources&lt;/strong&gt;, но со
временем полностью перебрался на &lt;strong&gt;gentoo-sources&lt;/strong&gt;, так как я понял,
что сами suspend-to-ram и suspend-to-hdd мне абсолютно не нужны, но
suspend2 слегка отстают от gentoo по версиям. Тем более, насколько я
знаю, в современных версиях основной ветки ядра suspend тоже
поддерживается на достойном уровне (но так как мне он не нужен -
пробовать на собственном опыте не доводилось).&lt;/p&gt;
&lt;p&gt;Поначалу осознать как именно необходимо настроить ядро довольно
непросто, часто забываешь какой-нибудь драйвер или маленькую опцию,
сильно влияющую на ту или иную часть системы, или наоборот включаешь
множество абсолютно бесполезных компонентов. Вариантов решения этой
ситуации есть несколько:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Просто скопировать ядро с LiveCD.&lt;/em&gt; Этот вариант является самым
    простым в плане реализации, систему с его помощью запустить вполне
    реально - пробовал, но в плане производительности ему до идеала
    о-о-очень далеко.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Собрать ядро с помощью &lt;strong&gt;genkernel&lt;/strong&gt; и стандартной его
    конфигурации.&lt;/em&gt; Прочитав &lt;strong&gt;man genkernel&lt;/strong&gt; это занятие тоже
    становится простым и привычным. Именно этот вариант я и выбрал в
    первый раз, слегка подредактировав конфигурационный файл с помощью
    &lt;strong&gt;&amp;ndash;&amp;ndash;menuconfig&lt;/strong&gt; в тех местах, где был точно уверен что это не
    повлияет на функциональность и положительно повлияет на
    производительность. Естественно этот вариант тоже годится только на
    первое время.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Ручная сборка классическим способом - &lt;strong&gt;make&lt;/strong&gt;, с использованием
    конфигурационного файла, взятого с LiveCD&lt;/em&gt;. Чисто теоретически
    возможно, но не могу порекомендовать этот способ, при его реализации
    возникает существенно больше проблем, до конца решить которые мне
    так и не удалось в процессе установки, а в последующем как-то не
    возникало желания возвращаться к ручной сборке ядра, так как привык
    к &lt;strong&gt;genkernel&lt;/strong&gt; - просто и удобно.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Метод "проб и ошибок".&lt;/em&gt; Если есть желание и возможность потратить
    существенное количество времени на подбор оптимальной конфигурации
    ядра прямо в процессе установки - почему бы этим и не заняться?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Вне зависимости от выбранного варианта сборки ядра, рано или поздно Вы
получите успешно загружающуюся без помощи LiveCD систему (естественно
имеется ввиду, что в консоль, о X-ах говорить еще рано), о которой и
пойдет речь дальше.&lt;/p&gt;
&lt;h3 id="set"&gt;Сеть&lt;/h3&gt;
&lt;p&gt;Первым делом, конечно же появляется желание выползти на просторы Сети,
даже скорее не желание, а необходимость, ведь жизнь компьютера без Сети
хоть и возможна, но грустна и нелегка.&lt;/p&gt;
&lt;p&gt;Как известно, у большинства ноутбуков дорога в Сеть может пролегать по
трем маршрутам:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Сетевая карта - Ethernet&lt;/li&gt;
&lt;li&gt;Беспроводная сеть - WiFi&lt;/li&gt;
&lt;li&gt;Старый-добрый модем&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Из всех трех вариантов мне довелось опробовать только первые два,
испытать модем в полевых условиях, к сожалению, не удалось в связи с
отсутствием как возможности, так и желания.&lt;/p&gt;
&lt;h4&gt;Ethernet&lt;/h4&gt;
&lt;p&gt;Воткнув заветный штекер RJ45 в соответствующий разъем, я с удивлением
обнаружил с помощью команды &lt;strong&gt;ifconfig&lt;/strong&gt;, что на этом мои телодвижения
по получению доступа в Интернет благополучно закончились. Все драйвера
оказались на месте, DHCP-клиент без моего вмешательства получил
IP-адрес, все необходимые настройки по-умолчанию были выбраны верно -
вобщем в этом плане все отлично.&lt;/p&gt;
&lt;p&gt;Конечно далеко не у всех локальная сеть организована таким же образом,
как и у меня, возможно придется поизучать man &lt;strong&gt;ifconfig&lt;/strong&gt;'а или
повозиться с VPN-соединением.&lt;/p&gt;
&lt;h4&gt;WiFi&lt;/h4&gt;
&lt;p&gt;С беспроводным соединением все прошло далеко не так гладко, как хотелось
бы. Первой задачей стояло определение того, какой же драйвер необходим
для функционирования соответствующего устройства. Вариантов ответа на
этот вопрос в Сети нашлось множество, но какой именно подошел бы
именно к моей модели ноутбука было как минимум не очевидно.&lt;/p&gt;
&lt;p&gt;Попробовав несколько вариантов, мне удалось-таки установить беспроводное
соединение с помощью драйвера под названием &lt;strong&gt;ipw3945&lt;/strong&gt; и сопутствующего
ему daemon'а &lt;strong&gt;ipw3945d&lt;/strong&gt;. Подробно весь процесс описывать не буду, я
думаю при необходимости подробную инструкцию найти особого труда не
составит.&lt;/p&gt;
&lt;p&gt;Я еще не упоминал, что в качестве рабочего окружения предпочитаю
использовать KDE, как-то с самого начала к нему привык, как внешне так и
внутренне он меня более чем устраивает. Не сочтите предыдущее
предложение за отступ от темы, я всеголишь хотел как-то объяснить
переход к разговору об утилите, предоставляющей GUI к работе с
беспроводными соединениями, - &lt;strong&gt;KWifiManager&lt;/strong&gt;. Утилитка достаточно
своеобразная, манера ее поведения поначалу сильно удивляла, но со
временем привыкаешь. Особенно странно она производит выбор беспроводной
сети, к которой подключаться. Не смотря на установленную в настройках
мою домашнюю сеть, как сеть по-умолчанию, она все равно частенько
пытается залезть к соседям или еще куда. И что самое интересное -
вернуть ее на &lt;em&gt;путь истинный&lt;/em&gt; ее же средствами мне обычно так и не
удается. Из-за этого пришлось написать bash-скрипт, который помогает
укратить эту утилиту. Включать в текст записи его особо желания нету,
если кто хочет его заполучить: оставьте соответствующий комментарий -
выложу.&lt;/p&gt;
&lt;h3 id="alternativa-konsoli"&gt;Альтернатива консоли&lt;/h3&gt;
&lt;p&gt;Консоль - штука конечно полезная, но со временем пользоваться только ей
на домашнем компьютере все же надоедает, хочется чего-то большего -
например, компании состоящей из X-сервера, Xorg и какого-либо рабочего
окружения (как я уже успел упомянуть - в его роли я предпочитаю
использовать &lt;a href="/tag/kde/"&gt;KDE&lt;/a&gt;, о нем и буду дальше говорить, но Ваш выбор
это естественно ни капли не ограничивает).&lt;/p&gt;
&lt;p&gt;Проблем как ни странно с этим пунктом нашей программы не возникло
никаких - официальная документация по этому поводу обширна, и чуть ли не
гарантированно приводит к положительным результатам. Все прекрасно
собирается (правда долговато) и не менее прекрасно работает.&lt;/p&gt;
&lt;p&gt;Одно время конечно возникали некоторые трудности, например в одной из
версий X-сервера была неприятная недоработка с LED'ами на клавиатуре -
не было видно нажат ли Caps Lock, или при одной конкретной комбинации
программного обеспечения и ядра системы по странному стечению
обстоятельств частоиспользуемая клавиша &lt;strong&gt;F2&lt;/strong&gt; приводила к сворачиванию
X-сервера и возвращению в консоль, что тоже доставляло массу неудобств.
На данный же момент все проблемы такого рода решены руками огромного
&lt;a href="/tag/opensource/"&gt;opensource&lt;/a&gt;-сообщества и все снова замечательно
работает точно также как и полгода назад сразу после установки системы.&lt;/p&gt;
&lt;p&gt;Через некоторое время после установки &lt;a href="/tag/kde/"&gt;KDE&lt;/a&gt; мне все же
захотелось привести его в более приятный моим глазам внешний вид.
Вооружившись любимым графическим редактором под названием &lt;strong&gt;The GIMP&lt;/strong&gt; я
принялся за дело. В итоге получилось нечто странное, которое выглядит
примерно вот так:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Screenshot" class="responsive-img" src="https://www.insight-it.ru/images/screenshot-desktop.jpg" title="KDE 3.5.8 Screenshot"/&gt;&lt;/p&gt;
&lt;h3 id="video"&gt;Видео&lt;/h3&gt;
&lt;p&gt;Используемый по-умолчанию видеодрайвер &lt;em&gt;vesa&lt;/em&gt; оставляет желать лучшего,
этот факт заметен сразу же после первой загрузки рабочего окружения, а
значит ничего не остается кроме как искать ему замену. Искать долго не
придется - отличный видеодрайвер для присутствующей в внутри этого
ноутбука &lt;em&gt;Nvidia GeForce 7600&lt;/em&gt; легко доступен через Portage, называется
он, как ни странно, &lt;strong&gt;nvidia-drivers&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Впечатления он оставляет только положительные: легко настраивается,
достаточно производительный, поддерживает множество технологий, в том
числе пресловутый Composite Extension в Xorg, который необходим для
работы большинства (если не всех) трехмерных приложений.&lt;/p&gt;
&lt;h3 id="audio"&gt;Аудио&lt;/h3&gt;
&lt;p&gt;С ним все еще проще - достаточно лишь не забыть включить &lt;strong&gt;ALSA&lt;/strong&gt; и
&lt;strong&gt;Intel HD Audio&lt;/strong&gt; в конфигурации ядра.&lt;/p&gt;
&lt;p&gt;Качество конечно не идеальное, но для такого класса устройств звук
вполне "на уровне", для просмотра фильмов и негромкого воспроизведения
музыки более чем достаточно.&lt;/p&gt;
&lt;h3 id="bluetooth"&gt;Bluetooth&lt;/h3&gt;
&lt;p&gt;Синий зуб прекрасно чувствует себя под руководством встроенного в ядра
драйвера &lt;strong&gt;BlueZ&lt;/strong&gt;, с работой в качестве GUI для работы с этим
устройством также неплохо справляются KDE'шные утилиты KBluetooth и
компания.&lt;/p&gt;
&lt;p&gt;На роль помощника в тестировании и настройке bluetooth'а я не смог
придумать ничего лучше, чем выбрать свой старенький телефон &lt;em&gt;Qtek S200&lt;/em&gt;.
Передача файлов заработала безукоризненно в обоих направлениях, а вот с
использованием телефона в роли GPRS-модема пришлось изрядно повозиться:
узнать необходимые настройки соединения на сайте оператора, найти хотябы
примерно подходящую документацию по данному вопросу, настроить все как
положено. Когда дело дошло до процесса дозвона по указанному номеру,
телефон по каким-то причинам отказывался реагировать на запросы
компьютера. Попытки понять в чем же причина длились достаточно долго,
пока я не наткнулся в интернете на подробное техническое описание своего
телефона, где было сказано, что он просто-напросто не поддерживает
доступ у своему GPRS-модему через bluetooth-соединение. Узнав об этом
факте я решил больше себя не мучать и бросил эту затею, но чисто
технически с другим телефоном оно должно было заработать, но на практике
проверить руки так до сих пор и не дошли.&lt;/p&gt;
&lt;h3 id="raznye-melochi"&gt;Разные мелочи&lt;/h3&gt;
&lt;p&gt;Устав от продолжительной установки и настройки системы, на вещи,
которыми я не планировал активно пользоваться, я не тратил много
времени, по-этому упомяну их лишь вкратце.&lt;/p&gt;
&lt;p&gt;Очень удивил меня тот факт, что для приведения к жизни различных
нестандартных кнопок вроде регулировки громкости, S1, S2 и Fn необходима
достаточно серьезная "работа напильником": модули ядра вроде &lt;strong&gt;sonypi&lt;/strong&gt;
способны оживить их лишь частично, для полного их функционирования
возможно придется изрядно покопаться в конфигурационных файлах, а также
написать/найти некоторое количество bash-скриптов. Надеюсь в будущем
найду в себе силы довести это дело до конца, правда особого дискомфорта
от ненастроенных кнопок я не испытываю - не успел к ним привыкнуть, да и
реализованного на уровне оборудования mute sound мне вполне хватает.&lt;/p&gt;
&lt;p&gt;Регулировка яркости дисплея работает прекрасно через консоль с помощью
утилиты &lt;strong&gt;nvclock&lt;/strong&gt;, но какого-либо GUI к ней мне найти не удалось, т.к.
особой необходимости в этом не испытываю - все равно предпочитаю держать
экран максимально ярким, лишь в очень редких случаях возникает
необходимость его приглушить, но в таких случаях обычно проще бывает
нажать &lt;strong&gt;Alt+F2&lt;/strong&gt; и набрать необходимую команду.&lt;/p&gt;
&lt;p&gt;Встроенная камера заслуживает отдельного разговора. С одной стороны
драйвера под нее есть и легко доступны, весь необходимый набор модулей
для ядра - &lt;strong&gt;v4l, gspcav1&lt;/strong&gt;, установить абсолютно не проблема. Найдя
неплохую статейку в вики я достаточно быстро разобрался с их установкой,
но после этого возник вопрос: а зачем оно собственно говоря надо? Как
оказалось, камера является абсолютно бесполезным для меня device'ом, и я
даже не придумал никакого адекватного способа проверить ее
работоспособность. Так эти драйвера и находятся установленными в системе
непонятно зачем.&lt;/p&gt;
&lt;p&gt;Порт IEEE 1394 aka FireWire опробовать в действии не удалось, так как я
не являюсь обладателем устройств, его использующих, но я не вижу
каких-либо причин для того, чтобы он не работал: если мне не изменяет
память, то он фигурировал в настройках ядра наравне с USB, который
замечательно работает.&lt;/p&gt;
&lt;p&gt;Cardreader'ов в комплекте было два - один встроенный для MemoryStick, и
внешний в 34мм-слот для SD/MMC. Насчет первого не могу ничего сказать,
так как карточек таких у меня не нашлось, а второй отлично определился
без каких-либо дополнительных действий с моей стороны.&lt;/p&gt;
&lt;p&gt;Про DVD-привод, miniJack и прочие стандартные вещи наверное и упоминать
смысла нет - с ними все в порядке.&lt;/p&gt;
&lt;h3 id="podvedem-itogi"&gt;Подведем итоги&lt;/h3&gt;
&lt;p&gt;Как Вы уже успели заметить, в целом процесс установки этого одного из
самых "сложных" дистрибутивов &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt; на ноутбук является
далеко не элементарной задачей. Когда я писал этот текст, передо мной не
стояло задачи убедить как можно больше читателей последовать по тому
пути, что выбрал я и стать активным пользователем операционной системы
под гордым названием &lt;em&gt;&lt;a href="/tag/gentoo/"&gt;Gentoo&lt;/a&gt; &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;&lt;/em&gt;, я
всеголишь хотел показать Вам выбор, который стоит перед каждым
пользователем персональных компьютеров, как настольных, так и
портативных.&lt;/p&gt;
&lt;p&gt;На закуску я хотел бы поделиться своими впечатлениями насчет активной
эксплуатации такой системы на протяжении достаточного длительного
периода времени. Промолчав про несравнимую производительность и
стабильность, сразу перейду к тому, как я использую свой ноутбук: в
основном для меня он просто является устройством, позволяющим
пользоваться всем разнообразием услуг Сети: общаться, получать
разного рода информацию, делиться информацией. Помимо этого я
подрабатываю программированием на некоторых языках программирования, а
также удаленным администрированием. Для каждой из этих задач существует
огромнейший набор вариантов воплощения их в жизнь, и выбор каким из них
мне пользоваться в каждой конкретной ситуации остается за мной, за
&lt;em&gt;пользователем&lt;/em&gt;, а не за производителями программного обеспечения,
которые навязывают своим клиентам свои решения.&lt;/p&gt;
&lt;p&gt;Закончить хотелось бы той же цитатой из &lt;em&gt;Gentoo Handbook&lt;/em&gt;, которую я
использовал в эпиграфе к этой статье: &lt;em&gt;"Gentoo is all about choices."&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Tue, 22 Jan 2008 01:06:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-01-22:linux/2008/gentoo-linux-sony-vaio/</guid><category>gentoo</category><category>gentoo linux</category><category>Linux</category><category>notebook</category><category>opensource</category><category>sony</category><category>sony vaio</category><category>sony vaio fe41zr</category><category>sony vaio vgn-fe41zr</category><category>линукс</category><category>ноутбук</category><category>ОС</category></item><item><title>Unix way</title><link>https://www.insight-it.ru//linux/2008/unix-way/</link><description>&lt;p&gt;На эту тему в Сети можно найти несметное количество статей и обсуждений,
не удивлюсь если Вам уже доводилось читать что-либо подобное в прошлом
или может быть работать в одной из множества операционных систем,
разработанных с использованием этой идеологии. За этим словосочетанием
скрывается целая философия разработки программного обеспечения, начавшая
свое развитие в середине 90-х годов прошлого века и воплощенная в
огромном количестве операционных систем и в еще большем количестве
&lt;a href="/tag/opensource/"&gt;opensource&lt;/a&gt; проектов. В этом тексте я хочу поведать
Вам свой взгляд на эту философию с двух точек зрения: программиста и
пользователя.&lt;/p&gt;
&lt;p&gt;Наиболее точно охарактеризовать то, о чем пойдет речь можно лишь
процитировав одного из основателей традиций &lt;a href="/tag/unix/"&gt;Unix&lt;/a&gt; и
разработчика &lt;a href="/tag/tekhnologiya/"&gt;технологии&lt;/a&gt; под названием "Unix
pipes" - &lt;a href="https://www.insight-it.ru/goto/7c67426e/" rel="nofollow" target="_blank" title="http://www.cs.dartmouth.edu/~doug/"&gt;Douglas'а Mcllroy'а&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"This is the Unix philosophy:
- Write programs that do one thing and do it well.
- Write programs to work together.
- Write programs to handle text streams, because that is a universal interface."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;!--more--&gt;
&lt;p&gt;Для начала воспроизведу суть цитаты для тех читателей, кто возможно не
знает в достаточной степени английского языка:&lt;/p&gt;
&lt;p&gt;&lt;cite&gt;Философия написания программ для &lt;a href="/tag/unix/"&gt;Unix&lt;/a&gt; заключается в
написании программ, качественно решающих строго одну задачу, но при этом
тесно работающих вместе. В качестве стандартного универсального
интерфейса между ними предлагается использование стандартных потоков
текстовых данных.&lt;/cite&gt;&lt;/p&gt;
&lt;p&gt;Сразу же позволю себе слегка отойти от темы, упомянув что существует
также и абсолютно противоположный подход к написанию программного
обеспечения, который стоит упомянуть для того, чтобы "почувствовать
разницу". Он используется в большинстве
&lt;abbr title="Платное программное обеспечение с закрытым кодом"&gt;проприетарных&lt;/abbr&gt;
программ и заключается в нагромождении максимального количества
функционала внутри одного программного продукта, в большинстве случаев с
целью получения дополнительных возможностей для построения рекламной
компании и, как следствие, более выгодного ведения продаж. К сожалению,
при таком подходе разработчики часто забывают о качестве ПО, о
возможностях расширение, удобстве использования, возможностях
модификации со стороны пользователя и многом другом, но зато в итоге
получают продукт, о котором можно указать "установил - и сразу что-то
как-то работает", но что именно, как оно работает, и как долго еще
сможет работать до тех пор пока не начнутся неполадки, и как с ними
бороться в случае если они появятся - остается загадкой для как для
подавляющего большинства пользователей, так и не редко для самих
разработчиков тоже.&lt;/p&gt;
&lt;p&gt;Закончив лирическое отступление, хочется взглянуть на нашу философию с
точки зрения программиста.&lt;/p&gt;
&lt;h3 id="vzgliad-s-tochki-zreniia-programmista"&gt;Взгляд с точки зрения программиста&lt;/h3&gt;
&lt;p&gt;Философия &lt;a href="/tag/unix/"&gt;Unix&lt;/a&gt; предлагает программисту набор элементарных
правил, соблюдение которых не только упростит работу программиста, но и
позволит расширить сферу применения получившегося программного продукта
с помощью различных вариантов интеграции с другими программами.&lt;/p&gt;
&lt;p&gt;Как же это выглядит?&lt;/p&gt;
&lt;h4&gt;Одна задача - одна программа&lt;/h4&gt;
&lt;p&gt;С помощью этого правила список действий, требуемых от программиста для
написания готовой программы, резко сокращается до двух позиций, одной из
которых является собственно реализация задачи. Задачи эти чаще всего
элементарны до безобразия и заключается в переработки входных данных,
например: вывод содержимого указанного каталога, подсчет длины
указанного файла, фильтрация входных данных, отправка локального
электронного письма на удаленный сервер (да-да, для приема, сортировки,
хранения, чтения, редактирования и отправки электронных писем могут
использоваться отдельные программы).&lt;/p&gt;
&lt;p&gt;Подобное множество программ решающих элементарные задачи делает
количество способов решения какой-либо комплексной задачи стремящимся к
бесконечности, ведь при наличии стандартизованного интерфейса
комбинировать программы можно в любой последовательности. Для расширения
возможностей такого рода комбинирования используются различные
скриптовые языки, которых существует достаточно много, наиболее
распространенным из которых являются bash скрипты, основанные на
командах одноименной оболочки командной строки, используемой
по-умолчанию во всех (хотя возможно стоило не использовать громких слов
и написать "в большинстве") дистрибутивах &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Unix pipes&lt;/h4&gt;
&lt;p&gt;Этот механизм является основным способом реализации столько раз
упоминавшегося выше интерфейса между элементарными программами.
Реализация его поддержки является как раз второй задачей, которая
ставится перед программистом, идущим по пути &lt;a href="/tag/unix/"&gt;Unix&lt;/a&gt;. С
использованием большинства языков программирования она является
тривиальной, особенно это справедливо для C.&lt;/p&gt;
&lt;p&gt;На подробностях реализации останавливаться не будем, по этому позволю
себе плавно перейти к следующему разделу и продолжить эту тему уже там.&lt;/p&gt;
&lt;h3 id="vzgliad-s-tochki-zreniia-polzovatelia"&gt;Взгляд с точки зрения пользователя&lt;/h3&gt;
&lt;p&gt;Слово pipes можно переводить по-разному, мне больше нравится вариант
&lt;em&gt;потоки&lt;/em&gt;, но также часто используется и дословный перевод - &lt;em&gt;трубы&lt;/em&gt;.
Также имеет смысл сразу сказать, что его реализация полностью
основывается на командной строке и командах различных ее оболочек, а
также тесно интегрирована с устройствами компьютера и файловой системой.&lt;/p&gt;
&lt;p&gt;У каждой элементарной программы, соответствующей этой идеологии, должен
быть входной и выходной стандартные текстовые потоки - &lt;strong&gt;stdin&lt;/strong&gt; и &lt;strong&gt;stdout&lt;/strong&gt; соответственно. Механизм unix pipes позволяет перенаправлять эти потоки любой программы произвольным образом с помощью трех простых операторов: &lt;code&gt;|&lt;/code&gt;, &lt;code&gt;&amp;gt;&lt;/code&gt; и &lt;code&gt;&amp;lt;&lt;/code&gt;. Первый из них - &lt;code&gt;|&lt;/code&gt; перенаправляет stdout команды слева от него в stdin команды справа, а &lt;code&gt;&amp;gt;&lt;/code&gt; и &lt;code&gt;&amp;lt;&lt;/code&gt; предназначены для перенаправление потоков в/из файлы по схожему принципу.&lt;/p&gt;
&lt;p&gt;Предлагаю рассмотреть этот механизм на примерах. Возьмем несколько
базовых утилит, имеющихся на практически любой unix-like системе:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;cat&lt;/code&gt; - вывод содержимого указанного первым параметром файла в
    stdout (по умолчанию stdout в большинстве программ направляется в
    консоль)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;less&lt;/code&gt; - постраничный вывод текста, полученного в stdin в stdout
    (переключение страниц и некоторые другие функции производятся с
    клавиатуры, возможны и другие варианты использования, но они нам не
    нужны)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;grep&lt;/code&gt; - построчная фильтрация текста, полученного в stdin, вывод
    только строк, содержащих текст, указанный первым аргументом, и вывод
    результата в stdout.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Начнем с примера, позволяющего прочитать постранично любой файл:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat readme.txt &lt;span class="p"&gt;|&lt;/span&gt; less
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Не смотря на наличие более простых методов достижения той же цели, этот
пример наглядно демонстрирует процесс перенаправления ввода-вывода,
другими словами с помощью оператора &lt;code&gt;|&lt;/code&gt; была создана так называемая pipe,
которая и дала название этому механизму. Пример, демонстрирующий
перенаправление в файл будет столь же элементарным, хотя может быть с
первого взгляда покажется "пострашнее":&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat readme.txt &lt;span class="p"&gt;|&lt;/span&gt; grep unix &amp;gt; readme.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Этот пример должен был бы удалить из файла все строки, где нет слова
"unix". &lt;em&gt;Маленькое замечание:&lt;/em&gt; при использовании такого перенаправления,
перед началом передачи данных файл обнуляется. В этом и заключается
ошибка данного примера: файл очищается до того, как поток данных успел
пройти через фильтрацию &lt;strong&gt;grep&lt;/strong&gt;, что приводит к просто очистке файла.
Если же Вам все же нужен отфильтрованный список строк - стоит разместить
в другом файле (которым можно было бы подменить исходный при
необходимости), просто поменяв его название:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat readme.txt &lt;span class="p"&gt;|&lt;/span&gt; grep unix &amp;gt; meread.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Если же Вы хотите избежать очищения файла, в который производится
запись, необходимо написать символ &lt;code&gt;&amp;gt;&lt;/code&gt; дважды, тогда новые данные
припишутся в конец:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat readme.txt &lt;span class="p"&gt;|&lt;/span&gt; grep unix &amp;gt;&amp;gt; readme.txt
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;В unix-like системах есть еще одна интересная особенность, косвенно
связанная с этим механизмом: &lt;em&gt;все устройства являются файлами&lt;/em&gt; и
соответственно, прикреплены к файловой системе, для них выделена
отдельная директория, по традиции называемая &lt;code&gt;/dev&lt;/code&gt;. Работа с ними также
ведется на тех же правах что и с обычными файлами, например набрав в
консоли:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat readme.txt &amp;gt; /dev/dsp
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;в ответ от компьютера Вы услышите некоторый звук, издаваемый из колонок
или наушников.&lt;/p&gt;
&lt;h4&gt;Подводим итоги&lt;/h4&gt;
&lt;p&gt;С точки зрения простого пользователя использование opensource решений,
построенных на базе философии unix, является как минимум нетривиальной
задачей - ведь от него требуется как минимум понимание насколько мощная
и гибкая система попала ему/ей в руки. Отсутствие единственного верного
способа решения той или иной задачи ставит большинство людей попросту в
тупик, у них начинают разбегаться глаза от десятков тысяч программ,
доступа к которым есть у всех пользователей unix-like операционных
систем, с помощью набора простой волшебной команды в консоли, состоящей
не более чем из трех-четырех слов.&lt;/p&gt;
&lt;p&gt;Но если пользователь находит в себе силы понять что за зверь попал ему в
руки, он сможет превратить любой компьютер в универсальное устройство по
решению любых задач именно тем способом, который удобен &lt;em&gt;пользователю&lt;/em&gt;,
а не который навязали ему &lt;em&gt;производители&lt;/em&gt;
&lt;abbr title="Платное программное обеспечение с закрытым кодом"&gt;проприетарного&lt;/abbr&gt;
програмного обеспечения.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sun, 06 Jan 2008 19:30:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-01-06:linux/2008/unix-way/</guid><category>Linux</category><category>opensource</category><category>Unix</category><category>Unix way</category><category>идеология</category><category>Программирование</category><category>программное обеспечение</category><category>философия</category></item></channel></rss>
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/informatsionnye-tekhnologii/feed/index.xml" rel="self"></atom:link><lastBuildDate>Tue, 27 May 2008 19:35:00 +0400</lastBuildDate><item><title>it's a pic</title><link>https://www.insight-it.ru//misc/2008/its-a-pic/</link><description>&lt;p&gt;&lt;img alt="it's a pic logo" class="left" src="https://www.insight-it.ru/images/itsapic-logo.png" title="логотип"/&gt;
Не удивлюсь, если заголовок этого поста вам не сказал ровным счетом
ничего - это вполне логично. Именно эту ситуацию я и хотел бы сегодня
исправить: &lt;strong&gt;it's a pic&lt;/strong&gt; представляет собой...
&lt;!--more--&gt;
...очередной интернет-проект. Хотели увидеть что-то более
грандиозное? - читайте дальше!&lt;/p&gt;
&lt;p&gt;Начать наверное стоит с обозначения основной сути: поисковая система
изображений, ориентированная на глобальный рынок. Да-да, мы уже видели
поиск картинок в исполнении Google/Yahoo!/MSN/Яндекс/Рамблер (нужное
подчеркнуть) - скажете вы, так в чем же разница?&lt;/p&gt;
&lt;p&gt;Сейчас объясню. Никогда не возникало мысли, что частенько поиск картинок
в обычных поисковых системах по большей части выдает всякий бред, очень
слабо коррелирующий с тем, что Вы на самом деле искали? Основная их
проблема заключается в том, что способов провести ассоциацию между
текстом и изображением не так-то много. Чаще всего в их распоряжении
лишь HTML-документы, ссылающиеся на изображение. То есть на основании
атрибута &lt;code&gt;alt&lt;/code&gt; у тэга &lt;code&gt;&amp;lt;img /&amp;gt;&lt;/code&gt; и изредка anchor-текста обычных
ссылок, поисковая система должна составить представление о том, что же
на самом деле изображено в графическом файле. Варианты ручного
построения таких соответствий тоже существуют, но либо нужно платить
огромнейшему количеству человек за рутинную работу (что-то на грани
фантастики - количество изображений в Сети измеряется числом с слишком
большим количеством нулей) или подталкивать людей заниматься этим
бесплатно, оформив это, например, в виде online-игры. Обычно в таких
играх двум участникам одновременно предоставляется один и тот же набор
изображений, а их задачей является последовательно вводить свои
ассоциации связанные с текущим изображением. Если они оба ввели одно и
то же слово - оно ассоциируется с изображением, а пользователям
начисляются виртуальные очки. В общем поиск изображений по ключевым
словам - задача, связанная с массой проблем и неточностей.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It's a pic&lt;/strong&gt; является как раз поисковой системой, призванной избавить
людей, ищущих изображения от всех этих проблем с неточностью и
некорректностью результатов. Чтобы не придумывать каких-то временных
решений проблемы было решено искоренить основательно: основная идея
заключается в использовании в качестве критерия поиска не набор ключевых
слов, а просто изображение. Сказать, что два изображения похожи,
компьютеру намного проще, чем сказать что на картинке нарисован,
например, жираф - именно на это и делает ставку этот проект.&lt;/p&gt;
&lt;p&gt;Выглядит это примерно следующим образом: допустим Вы хотите найти
побольше изображений заката и выбрать наиболее приглянувшееся, для этого
достаточно загрузить в систему с локального компьютера изображение
заката (хотя если оно уже присутствует в Сети - можно и просто указать
URL) и собственно говоря нажать кнопку "Найти" - вот и все! Вот ваши
результаты:&lt;/p&gt;
&lt;p&gt;&lt;img alt="пример работы it's a pic" class="responsive-img" src="https://www.insight-it.ru/images/itsapic-scr.jpg" title="пример работы"/&gt;&lt;/p&gt;
&lt;p&gt;Наверное Вы уже заметили, что написав приличную часть поста я так до сих
пор и не дал ссылки на саму поисковую систему. У этого есть достаточно
простая причина - проект находится в стадии закрытого
&amp;beta;-тестирования (что вы собственно говоря могли
прочитать и на скриншоте чуть выше). Так что недостаточная точность
поиска вполне объясняется скромной базой данных изображений - можно
заметить на все том же скриншоте семизначную цифру количества
изображений в его базе. Но даже из такого небольшого количества
изображений системе удается достаточно точно выбрать похожие на образец
экземпляры и отсортировать их в соответствии с их релевантностью
оригиналу.&lt;/p&gt;
&lt;p&gt;Наверняка у Вас снова напрашивается вопрос: а как же я собственно попал
в закрытую бету проекта и узнал так много о нем еще до его запуска? Нет,
мне никто так до сих пор и не дает эксклюзивной информации о проектах,
но эта информация была получена и не из Сети. Не буду тянуть и раскрою
все карты: я просто-напросто с недавних пор участвую в этом проекте.
Собственно говоря одной из основных моих задач является вывод этой
системы из закрытой бета-версии в открытую, то есть обеспечить
работоспособность алгоритмов при несколько больших нагрузках, чем
один-два разработчика одновременно, ищущих что-то просто для проверки и
тестирования.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Tue, 27 May 2008 19:35:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-05-27:misc/2008/its-a-pic/</guid><category>it's a pic</category><category>online</category><category>архитектура</category><category>изображение</category><category>информационные технологии</category><category>поиск</category><category>поисковые системы</category></item><item><title>Масштабируемые веб-архитектуры</title><link>https://www.insight-it.ru//theory/2008/masshtabiruemye-veb-arkhitektury/</link><description>&lt;p&gt;&lt;img alt="Масштабируемость" class="right" src="https://www.insight-it.ru/images/display.png"/&gt;
Уже немало слов было сказано по этой теме как в моем блоге, так и за
его пределами. Мне кажется настал подходящий момент для того, чтобы
перейти от частного к общему и попытаться взглянуть на данную тему
отдельно от какой-либо успешной ее реализации.&lt;/p&gt;
&lt;p&gt;Приступим?
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;Для начала имеет смысл определиться с тем, о чем мы вообще будем
говорить. В данном контексте перед веб-приложением ставятся три основные
цели:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;масштабируемость&lt;/strong&gt; - способность своевременно реагировать на
    непрерывный рост нагрузки и непредвиденные наплывы пользователей;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;доступность&lt;/strong&gt; - предоставление доступа к приложению даже в случае
    чрезвычайных обстоятельств;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;производительность&lt;/strong&gt; - даже малейшая задержка в загрузке страницы
    может оставить негативное впечатление у пользователя.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Основной темой разговора будет, как не трудно догадаться,
масштабируемость, но и остальные цели не думаю, что останутся в стороне.
Сразу хочется сказать пару слов про доступность, чтобы не возвращаться к
этому позднее, подразумевая как "само собой разумеется": любой сайт так
или иначе стремится к тому, чтобы функционировать максимально стабильно,
то есть быть доступным абсолютно всем своим потенциальным посетителям в
абсолютно каждый момент времени, но порой случаются всякие
непредвиденные ситуации, которые могут стать причиной временной
недоступности. Для минимизации потенциального ущерба доступности
приложения необходимо избегать наличия компонентов в системе,
потенциальный сбой в которых привел бы к недоступности какой-либо
функциональности или данных (или хотябы сайта в целом). Таким образом
каждый сервер или любой другой компонент системы должен иметь хотябы
одного дублера (не важно в каком режиме они будут работать: параллельно
или один "подстраховывает" другой, находясь при этом в пассивном
режиме), а данные должны быть реплицированы как минимум в двух
экземплярах (причем желательно не на уровне RAID, а на разных физических
машинах). Хранение нескольких резервных копий данных где-то отдельно от
основной системы (например на специальных сервисах или на отдельном
кластере) также поможет избежать многих проблем, если что-то пойдет не
так. Не стоит забывать и о финансовой стороне вопроса: подстраховка на
случай сбоев требует дополнительных существенных вложений в
оборудование, которые имеет смысл стараться минимизировать.&lt;/p&gt;
&lt;p&gt;Масштабируемость принято разделять на два направления:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Вертикальная масштабируемость&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Увеличение производительности каждого компонента системы c целью
повышения общей производительности.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Горизонтальная масштабируемость&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Разбиение системы на более мелкие структурные компоненты и
разнесение их по отдельным физическим машинам (или их группам) и/или
увеличение количества серверов параллельно выполняющих одну и ту же
функцию.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Так или иначе, при разработке стратегии роста системы приходится искать
компромис между ценой, временем разработки, итоговой производительность,
стабильностью и еще массой других критериев. С финансовой точки зрения
вертикальная масштабируемость является далеко не самым привлекательным
решением, ведь цены на сервера с большим количеством процессоров всегда
растут практически экспоненциально относительно количества процессоров.
Именно по-этому наиболее интересен горизонтальный подход, так как именно
он используется в большинстве случаев. Но и вертикальная
масштабируемость порой имеет право на существование, особенно в
ситуациях, когда основную роль играет время и скорость решения задачи, а
не финансовый вопрос: ведь купить БОЛЬШОЙ сервер существенно быстрее,
чем практически заново разрабатывать приложения, адаптируя его к работе
на большом количестве параллельно работающих серверов.&lt;/p&gt;
&lt;p&gt;Закончив с общими словами давайте перейдем к обзору потенциальных
проблем и вариантов их решений при горизонтальном масштабировании.
Просьба особо не критиковать - на абсолютную правильность и
достоверность не претендую, просто "мысли вслух", да и даже упомянуть
все моменты данной темы у меня определенно не получится.&lt;/p&gt;
&lt;h3 id="servery-prilozhenii"&gt;Серверы приложений&lt;/h3&gt;
&lt;p&gt;В процессе масштабирования самих приложений редко возникают проблемы,
если при разработке всегда иметь ввиду, что каждый экземпляр приложения
должен быть непосредственно никак не связан со своими "коллегами" и
должен иметь возможность обработать абсолютно любой запрос пользователя
вне зависимости от того где обрабатывались предыдущие запросы данного
пользователя и что конкретно он хочет от приложения в целом в текущий
момень.&lt;/p&gt;
&lt;p&gt;Далее, обеспечив независимость каждого отдельного запущенного
приложения, можно обрабатывать все большее и большее количество запросов
в единицу времени просто увеличивая количество параллельно
функционирующих серверов приложений, участвующих в системе. Все
достаточно просто (относительно).&lt;/p&gt;
&lt;h3 id="balansirovka-nagruzki"&gt;Балансировка нагрузки&lt;/h3&gt;
&lt;p&gt;Следущая задача - равномерно распределить запросы между доступными
серверами приложений. Существует масса подходов к решению этой задачи и
еще больше продуктов, предлагающих их конкретную реализацию.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Оборудование&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Сетевое оборудование, позволяющее распределять нагрузку между
несколькими серверами, обычно стоит достаточно внушительные суммы,
но среди прочих вариантов обычно именно этот подход предлагает
наивысшую производительность и стабильность (в основном благодаря
качеству, плюс такое оборудование иногда поставляется парами,
работающими по принципу
&lt;a href="https://www.insight-it.ru/goto/a40f2b94/" rel="nofollow" target="_blank" title="http://en.wikipedia.org/wiki/Heartbeat_%28program%29"&gt;HeartBeat&lt;/a&gt;).
В этой индустрии достаточно много серьезных брендов, предлагающих
свои решения - есть из чего выбрать: &lt;em&gt;Cisco&lt;/em&gt;, &lt;em&gt;Foundry&lt;/em&gt;, &lt;em&gt;NetScalar&lt;/em&gt;
и многие другие.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Программное обеспечение&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;В этой области еще большее разнообразие возможных вариантов.
Получить программно производительность сопоставимую с аппаратными
решениями не так-то просто, да и HeartBeat придется обеспечивать
программно, но зато оборудование для функционирования такого решения
представляет собой обычный сервер (возможно не один). Таких
программных продуктов достаточно много, обычно они представляют
собой просто HTTP-серверы, перенаправляющие запросы своим коллегам
на других серверах вместо отправки напрямую на обработку
интерпретатору языка программирования. Для примера можно упомянуть,
скажем, &lt;a href="/tag/nginx/"&gt;nginx&lt;/a&gt; с &lt;code&gt;mod_proxy&lt;/code&gt;. Помимо этого имеют
место более экзотические варианты, основанные на DNS, то есть в
процессе определения клиентом IP-адреса сервера с необходимым ему
интернет-ресурсов адрес выдается с учетом нагрузки на доступные
сервера, а также некоторых географических соображений.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Каждый вариант имеет свой ассортимент положительных и отрицательных
сторон, именно по-этому однозначного решения этой задачи не существует -
каждый вариант хорош в своей конкретной ситуации. Не стоит забывать, что
никто не ограничивает Вас в использовании лишь одного из них, при
необходимости может запросто быть реализована и практически произвольная
комбинация из них.&lt;/p&gt;
&lt;h3 id="resursoemkie-vychisleniia"&gt;Ресурсоемкие вычисления&lt;/h3&gt;
&lt;p&gt;Во многих приложениях используются какие-либо сложные механизмы, это
может быть конвертирование видео, изображений, звука, или просто
выполнение каких-либо ресурсоемких вычислений. Такие задачи требует
отдельного внимания если мы говорим о Сети, так как пользователь
интернет-ресурса врядли будет счастлив наблюдать за загружающейся
несколько минут страницей в ожидании лишь для того, чтобы увидеть
сообщение вроде: "Операция завершена успешно!".&lt;/p&gt;
&lt;p&gt;Для избежания подобных ситуаций стоит постараться минимизировать
выполнение ресурсоемких операций синхронно с генерацией интернет
страниц. Если какая-то конкретная операция не влияет на новую страницу,
отправляемую пользователю, то можно просто организовать &lt;em&gt;очередь&lt;/em&gt;
заданий, которые необходимо выполнить. В таком случае в момент когда
пользователь совершил все действия, необходимые для начала операции,
сервер приложений просто добавляет новое задание в очередь и сразу
начинает генерировать следущую страницу, не дожидаясь результатов. Если
задача на самом деле очень трудоемкая, то такая очередь и обработчики
заданий могут располагаться на отдельном сервере или кластере.&lt;/p&gt;
&lt;p&gt;Если результат выполнения операции задействован в следующей странице,
отправляемой пользователю, то при асинхронном ее выполнении придется
несколько схитрить и как-либо отвлечь пользователя на время ее
выполнения. Например, если речь идет о конвертировании видео в &lt;strong&gt;flv&lt;/strong&gt;,
то например можно быстро сгенерировать скриншот с первым кадром в
процессе составления страницы и подставить его на место видео, а
возможность просмотра динамически добавить на страницу уже после, когда
конвертирование будет завершено.&lt;/p&gt;
&lt;p&gt;Еще один неплохой метод обработки таких ситуаций заключается просто в
том, чтобы попросить пользователя "зайти попозже". Например, если сервис
генерирует скриншоты веб-сайтов из различных браузеров с целью
продемонстрировать правильность их отображения владельцам или просто
интересующимся, то генерация страницы с ними может занимать даже не
секунды, а минуты. Наиболее удобным для пользователя в такой ситуации
будет предложение посетить страницу по указанному адресу через
столько-то минут, а не ждать у моря погоды неопределенный срок.&lt;/p&gt;
&lt;h3 id="sessii"&gt;Сессии&lt;/h3&gt;
&lt;p&gt;Практически все веб-приложения каким-либо образом взаимодействуют со
своими посетителями и в подавляющем большинстве случаев в них
присутствует необходимость отслеживать перемещения пользователей по
страницам сайта. Для решения этой задачи обычно используется механизм
&lt;em&gt;сессий&lt;/em&gt;, который заключается в присвоении каждому посетителю
уникального идентификационного номера, который ему передается для
хранения в cookies или, в случае их отсутствия, для постоянного
"таскания" за собой через GET. Получив от пользователя некий ID вместе с
очередным HTTP-запросом сервер может посмотреть в список уже выданных
номеров и однозначно определить кто его отправил. С каждым ID может
ассоциироваться некий набор данных, который веб-приложение может
использовать по своему усмотрению, эти данные обычно по-умолчанию
хранятся в файле во временной директории на сервере.&lt;/p&gt;
&lt;p&gt;Казалось бы все просто, но... но запросы посетителей одного и того же
сайта могут обрабатывать сразу несколько серверов, как же тогда
определить не был ли выдан полученный ID на другом сервере и где вообще
хранятся его данные?&lt;/p&gt;
&lt;p&gt;Наиболее распространенными решениями является централизация или
децентрализация сессионных данных. Несколько абсурдная фраза, но,
надеюсь, пара примеров сможет прояснить ситуацию:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Централизованное хранение сессий&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Идея проста: создать для всех серверов общую "копилку", куда они
смогут складывать выданные ими сессии и узнавать о сессиях
посетителей других серверов. В роли такой "копилки" теоретически
может выступать и просто примонтированная по сети файловая система,
но по некоторым причинам более перспективным выглядит использование
какой-либо СУБД, так как это избавляет от массы проблем, связанных с
хранением сессионных данных в файлах. Но в варианте с общей базой
данных не стоит забывать, что нагрузка на него будет неуклонно расти
с ростом количества посетителей, а также стоит заранее предусмотреть
варианты выхода из проблематичных ситуаций, связанных с
потенциальными сбоями в работе сервера с этой СУБД.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Децентрализованное хранение сессий&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Наглядный пример - хранение сессий в &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;,
изначально расчитанная на распределенное хранение данных в
оперативной памяти система позволит получать всем серверам быстрый
доступ к любым сессионным данным, но при этом (в отличии от
предыдущего способа) какой-либо единый центр их хранения будет
отсутствовать. Это позволит избежать узких мест с точек зрения
производительности и стабильности в периоды повышенных нагрузок.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;В качестве альтернативы сессиям иногда используют похожие по
предназначению механизмы, построенные на cookies, то есть все
необходимые приложению данные о пользователе хранятся на клиентской
стороне (вероятно в зашифрованном виде) и запрашиваются по мере
необходимости. Но помимо очевидных преимуществ, связанных с отсутствием
необходимости хранить лишние данные на сервере, возникает ряд проблем с
безопасностью. Данные, хранимые на стороне клиента даже в зашифрованном
виде, представляют собой потенциальную угрозу для функционирования
многих приложений, так как любой желающий может попытаться
модифицировать их в своих интересах или с целью навредить приложению.
Такой подход хорош только если есть уверенность, что абсолютно любые
манипуляции с хранимые у пользователей данными безопасны. Но можно ли
быть уверенными на 100%?&lt;/p&gt;
&lt;h3 id="staticheskii-kontent"&gt;Статический контент&lt;/h3&gt;
&lt;p&gt;Пока объемы статических данных невелики - никто не мешает хранить их в
локальной файловой системе и предоставлять доступ к ним просто через
отдельный легковесный веб-сервер вроде &lt;a href="/tag/lighttpd/"&gt;lighttpd&lt;/a&gt; (я
подразумеваю в основном разные формы медиа-данных), но рано или поздно
лимит сервера по дисковому пространству или файловой системы по
количеству файлов в одной директории будет достигнут, и придется думать
о перераспределении контента. Временным решением может стать
распределение данных по их типу на разные сервера, или, возможно,
использование иерархической структуры каталогов.&lt;/p&gt;
&lt;p&gt;Если статический контент играет одну из основных ролей в работе
приложения, то стоит задуматься о применении распределенной файловой
системы для его хранения. Это, пожалуй, один из немногих способов
горизонтально масштабировать объем дискового пространства путем
добавления дополнительных серверов без каких-либо кардинальных изменений
в работе самого приложения. На какой именно кластерной файловой системе
остановить свой выбор ничего сейчас советовать не хочу, я уже
опубликовал далеко не один обзор конкретных реализаций - попробуйте
прочитать их все и сравнить, если этого мало - вся остальная Сеть в
Вашем распоряжении.&lt;/p&gt;
&lt;p&gt;Возможно такой вариант по каким-либо причинам будет нереализуем, тогда
придется "изобретать велосипед" для реализации на уровне приложения
принципов схожих с сегментированием данных в отношении СУБД, о которых я
еще упомяну далее. Этот вариант также вполне эффективен, но требует
модификации логики приложения, а значит и выполнение дополнительной
работы разработчиками.&lt;/p&gt;
&lt;p&gt;Альтернативой этим подходам выступает использование так называемых
&lt;strong&gt;Content Delievery Network&lt;/strong&gt; - внешних сервисов, обеспечивающих
доступность Вашего контента пользователям за определенное материальное
вознаграждение сервису. Преимущество очевидно - нет необходимости
организовывать собственную инфраструктуру для решения этой задачи, но
зато появляется другая дополнительная статья расходов. Список таких
сервисов приводить не буду, если кому-нибудь понадобится - найти будет
не трудно.&lt;/p&gt;
&lt;h3 id="keshirovanie"&gt;Кэширование&lt;/h3&gt;
&lt;p&gt;Кэширование имеет смысл проводить на всех этапах обработки данных, но в
разных типах приложений наиболее эффективными являются лишь некоторые
методы кэширования.&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;СУБД&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Практически все современные СУБД предоставляют встроенные механизмы
для кэширования результатов определенных запросов. Этот метод
достаточно эффективен, если Ваша система регулярно делает одни и те
же выборки данных, но также имеет ряд недостатков, основными из
которых является инвалидация кэша всей таблицы при малейшем ее
изменении, а также локальное расположение кэша, что неэффективно при
наличии нескольких серверов в системе хранения данных.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Приложение&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;На уровне приложений обычно производится кэширование объектов любого
языка программирования. Этот метод позволяет вовсе избежать
существенной части запросов к СУБД, сильно снижая нагрузку на нее.
Как и сами приложения такой кэш должен быть независим от конкретного
запроса и сервера, на котором он выполняется, то есть быть доступным
всем серверам приложений одновременно, а еще лучше - быть
распределенным по нескольким машинам для более эффективной
утилизации оперативной памяти. Лидером в этом аспекте кэширования по
праву можно назвать &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, о котором я в свое
время уже успел &lt;a href="https://www.insight-it.ru/storage/2008/obzor-memcached/"&gt;подробно рассказать&lt;/a&gt;.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;HTTP-сервер&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Многие веб-серверы имеют модули для кэширования как статического
контента, так и результатов работы скриптов. Если страница редко
обновляется, то использование этого метода позволяет без каких-либо
видимых для пользователя изменений избегать генерации страницы в
ответ на достаточно большую часть запросов.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Reverse proxy&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Поставив между пользователем и веб-сервером прозрачный
прокси-сервер, можно выдавать пользователю данные из кэша прокси
(который может быть как в оперативной памяти, так и дисковым), не
доводя запросы даже до HTTP-серверов. В большинстве случаев этот
подход актуален только для статического контента, в основном разных
форм медиа-данных: изображений, видео и тому подобного. Это
позволяет веб-серверам сосредоточиться только на работе с самими
страницами.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Кэширование по своей сути практически не требует дополнительных затрат
на оборудование, особенно если внимательно наблюдать за использованием
оперативной памяти остальными компонентами серверами и утилизировать все
доступные "излишки" под наиболее подходящие конкретному приложению формы
кэша.&lt;/p&gt;
&lt;p&gt;Инвалидация кэша в некоторых случаях может стать нетривиальной задачей,
но так или иначе универсального решения всех возможных проблем с ней
связанных написать не представляется возможным (по крайней мере лично
мне), так что оставим этот вопрос до лучших времен. В общем случае
решение этой задачи ложится на само веб-приложение, которое обычно
реализует некий механизм инвалидации средствами удаления объекта кэша
через определенный &lt;em&gt;период времени&lt;/em&gt; после его создания или последнего
использования, либо "вручную" при возникновении определенных &lt;em&gt;событий&lt;/em&gt;
со стороны пользователя или других компонентов системы.&lt;/p&gt;
&lt;h3 id="bazy-dannykh"&gt;Базы данных&lt;/h3&gt;
&lt;p&gt;На закуску я оставил самое интересное, ведь этот неотъемлемый компонент
любого веб-приложения вызывает больше проблем при росте нагрузок, чем
все остальные вместе взятые. Порой даже может показаться, что стоит
вообще отказаться от горизонтального масштабирования системы хранения
данных в пользу вертикального - просто купить тот самый БОЛЬШОЙ сервер
за шести- или семизначную сумму не-рублей и не забивать себе голову
лишними проблемами.&lt;/p&gt;
&lt;p&gt;Но для многих проектов такое кардинальное решение (и то, по большому
счету, временное) не подходит, а значит перед ними осталась лишь одна
дорога - горизонтальное масштабирование. О ней и поговорим.&lt;/p&gt;
&lt;p&gt;Путь практически любого веб проекта с точки зрения баз данных начинался
с одного простого сервера, на котором работал весь проект целиком. Затем
в один прекрасный момент наступает необходимость вынести СУБД на
отдельный сервер, но и он со временем начинает не справляться с
нагрузкой. Подробно останавливаться на этих двух этапах смысла особого
нет - все относительно тривиально.&lt;/p&gt;
&lt;p&gt;Следующим шагом обычно бывает &lt;strong&gt;master-slave&lt;/strong&gt; с асинхронной репликацией
данных, как работает эта схема уже неоднократно упоминалось в блоге, но,
пожалуй, повторюсь: при таком подходе все операции записи выполняются
лишь на одном сервере (master), а остальные сервера (slave) получают
данные напрямую от "мастера", обрабатывая при этом лишь запросы на
чтение данных. Как известно, операции чтения и записи любого веб-проекта
всегда растут пропорционально росту нагрузки, при этом сохраняется почти
фиксированным соотношение между обоими типами запросов: на каждый запрос
на обновление данных обычно приходится в среднем около десятка запросов
на чтение. Со временем нагрузка растет, а значит растет и количество
операций записи в единицу времени, а сервер-то обрабатывает их всего
один, а затем он же еще и обеспечивает создание некоторого количества
копий на других серверах. Рано или поздно издержки операций репликации
данных станут быть настолько высоки, что этот процесс станет занимать
очень большую часть процессорного времени каждого сервера, а каждый
slave сможет обрабатывать лишь сравнительно небольшое количество
операций чтения, и, как следствие, каждый дополнительный slave-сервер
начнет увеличивать суммарную производительность лишь незначительно, тоже
занимаясь по большей части лишь поддержанием своих данных в соответствии
с "мастером".&lt;/p&gt;
&lt;p&gt;Временным решением этой проблемы, возможно, может стать замена
master-сервера на более производительный, но так или иначе не выйдет
бесконечно откладывать переход на следующий "уровень" развития системы
хранения данных: &lt;strong&gt;"sharding"&lt;/strong&gt;, которому я совсем недавно посвятил
&lt;a href="https://www.insight-it.ru/theory/2008/segmentirovanie-bazy-dannykh/"&gt;отдельный пост "Сегментирование баз данных"&lt;/a&gt;.
Так что позволю себе остановиться на нем лишь вкратце: идея заключается
в том, чтобы разделить все данные на части по какому-либо признаку и
хранить каждую часть на отдельном сервере или кластере, такую часть
данных в совокупности с системой хранения данных, в которой она
находится, и называют сегментом или &lt;em&gt;shard&lt;/em&gt;&amp;rsquo;ом. Такой подход позволяет
избежать издержек, связанных с реплицированием данных (или сократить их
во много раз), а значит и &lt;em&gt;существенно&lt;/em&gt; увеличить общую
производительность системы хранения данных. Но, к сожалению, переход к
этой схеме организации данных требует массу издержек другого рода. Так
как готового решения для ее реализации не существует, приходится
модифицировать логику приложения или добавлять дополнительную
"прослойку" между приложением и СУБД, причем все это чаще всего
реализуется силами разработчиков проекта. Готовые продукты способны лишь
облегчить их работу, предоставив некий каркас для построения основной
архитектуры системы хранения данных и ее взаимодействия с остальными
компонентами приложения.&lt;/p&gt;
&lt;p&gt;На этом этапе цепочка обычно заканчивается, так как сегментированные
базы данных могут горизонтально масштабироваться для того, чтобы в
полной мере удовлетворить потребности даже самых высоконагруженных
интернет-ресурсов. К месту было бы сказать пару слов и о собственно
самой структуре данных в рамках баз данных и организации доступа к ним,
но какие-либо решения сильно зависят от конкретного приложения и
реализации, так что позволю себе лишь дать пару общих рекомендаций:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Денормализация&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Запросы, комбинирующие данные из нескольких таблиц, обычно при
прочих равных требуют большего процессорного времени для выполнения,
чем запрос, затрагивающий лишь одну таблицу. А производительность,
как уже упоминалось в начале повествования, чрезвычайно важна на
просторах Сети.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Логическое разбиение данных&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Если какая-то часть данных всегда используется отдельно от основной
массы, то иногда имеет смысл выделить ее в отдельную независимую
систему хранения данных.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Низкоуровневая оптимизация запросов&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Ведя и анализируя логи запросов, можно определить наиболее медленные
из них. Замена найденных запросов на более эффективные с той же
функциональностью может помочь более рационально использовать
вычислительные мощности.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;В этом разделе стоит упомянуть еще один, более специфический, тип
интернет-проектов. Такие проекты оперируют данными, не имеющими четко
формализованную структуру, в таких ситуациях использование реляционных
СУБД в качестве хранилища данных, мягко говоря, нецелесообразно. В этих
случаях обычно используют менее строгие базы данных, с более примитивной
функциональностью в плане обработки данных, но зато они способны
обрабатывать огромные объемы информации не придираясь к его качеству и
соответствию формату. В качестве основы для такого хранилища данных
может служить кластерная файловая система, а для анализа же данных в
таком случае используется механизм под названием
&lt;a href="/tag/mapreduce/"&gt;MapReduce&lt;/a&gt;, принцип его работы я расскажу лишь вкратце,
так как в полном своем масштабе он несколько выходит за рамки данного
повествования.&lt;/p&gt;
&lt;p&gt;Итак, мы имеем на входе некие произвольные данные в не факт что
правильно соблюденном формате. В результате нужно получить некое
итоговое значение или информацию. Согласно данному механизму практически
любой анализ данных можно провести в следующие два этапа:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Основной целью данного этапа является представление произвольных
входных данных в виде промежуточных пар ключ-значение, имеющих
определенный смысл и формально оформленных. Результаты подвергаются
сортировке и группированию по ключу, а после чего передаются на
следующий этап.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Reduce&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Полученные после &lt;strong&gt;map&lt;/strong&gt; значения используются для финального
вычисления требуемых итоговых данных.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Каждый этап каждого конкретного вычисления реализуется в виде
независимого мини-приложения. Такой подход позволяет практически
неограниченно распараллеливать вычисления на огромном количестве машин,
что позволяет в мгновения обрабатывать объемы практически произвольных
данных. Для этого достаточно лишь запустить эти приложения на каждом
доступном сервере одновременно, а затем собрать воедино все результаты.&lt;/p&gt;
&lt;p&gt;Примером готового каркаса для реализации работы с данными по такому
принципу служит opensource проект Apache Foundation под названием
&lt;a href="https://www.insight-it.ru/storage/2008/hadoop/"&gt;&lt;em&gt;Hadoop&lt;/em&gt;&lt;/a&gt;, о котором я уже неоднократно
рассказывал ранее, да и &lt;a href="https://www.insight-it.ru/goto/1a5b89d0/" rel="nofollow" target="_blank" title="http://ru.wikipedia.org/wiki/Hadoop"&gt;статейку в Википедию&lt;/a&gt; написал в свое время.&lt;/p&gt;
&lt;h3 id="vmesto-zakliucheniia"&gt;Вместо заключения&lt;/h3&gt;
&lt;p&gt;Если честно, мне с трудом верится, что я смог написать настолько
всеобъемлющий пост и сил на подведение итогов уже практически не
осталось. Хочется лишь сказать, что в разработке крупных проектов важна
каждая деталь, а неучтенная мелочь может стать причиной провала. Именно
по-этому в этом деле учиться стоит не на своих ошибках, а на чужих.&lt;/p&gt;
&lt;p&gt;Хоть может быть этот текст и выглядит как некое обобщение всех постов из
серии &lt;a href="https://www.insight-it.ru/highload/"&gt;"Архитектуры высоконагруженных систем"&lt;/a&gt;, но врядли он
станет финальной точкой, надеюсь мне &lt;a href="/feed/"&gt;найдется что сказать&lt;/a&gt; по
этой теме и в будущем, может быть однажды это будет основано и на личном
опыте, а не просто будет результатом переработки массы полученной мной
информации. Кто знает?...&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Mon, 12 May 2008 09:00:00 +0400</pubDate><guid>tag:www.insight-it.ru,2008-05-12:theory/2008/masshtabiruemye-veb-arkhitektury/</guid><category>online</category><category>архитектура</category><category>веб-приложение</category><category>веб-проект</category><category>веб-сервер</category><category>геораспределение</category><category>информационные технологии</category><category>кэширование</category><category>Масштабируемость</category><category>распределенные вычисления</category><category>сегментирование баз данных</category></item><item><title>Comet</title><link>https://www.insight-it.ru//frontend/2008/comet/</link><description>&lt;p&gt;Уже приготовились мыть посуду? Что ж, придется Вас разочаровать, сегодня
речь пойдет вовсе не о моющем средстве, а об одноименной технологии.&lt;/p&gt;
&lt;p&gt;Comet представляет собой архитектуру веб-приложений, основной
особенностью которой является тот факт, что отправка данных от сервера к
клиенту (в роли которого обычно выступает браузер) не требует
какого-либо запроса данных со стороны клиента. Это позволяет
пользователям приложения более оперативно реагировать на возникающие на
сервере события и быть в курсе процесса работы приложения без
необходимости непрерывно опрашивать сервер с помощью веб-клиента.
&lt;!--more--&gt;
Реализация этой технологии, как не сложно догадаться, основывается на
JavaScript. Основной идеей является поддержание долговременных
HTTP-соединений с каждым клиентом приложения и отправка новых данных
клиентам с их помощью как только произошло их обновление или
возникновение на сервере. Этот принцип послужил основой для
альтернативных названий этой технологии: &lt;em&gt;Server-push&lt;/em&gt;, &lt;em&gt;Reverse AJAX&lt;/em&gt;.
В случае классического AJAX (о котором тоже стоило бы сначала написать
статейку, потом может быть соберусь) клиент асинхронно отправляет
серверу запрос на получение какой-либо конкретной информации. В Comet же
клиент с сервером как бы меняются ролями: инициатором передачи
информации является сервер, а не клиент. Что же это меняет? Самым
наглядным примером послужит реализация постоянного обновления какой-либо
информации в реальном времени:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Классическая модель отправки запросов.&lt;/strong&gt; Для решения задачи
    понадобится постоянно обновлять всю страницу целиком, вручную
    пользователем или альтернативными способами автоматически. Совсем не
    вариант, будет генерироваться огромное количество запросов к
    серверу, каждый из которых будет очень существеннен по объему.
    Большое количество одновременно работающих пользователей такое
    приложение явно не выдержит, да и доступность данных в реальном
    времени не обеспечит.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AJAX.&lt;/strong&gt; По сравнению с предыдущим вариантом AJAX предоставляет
    массу преимуществ: размер передаваемых данных существенно
    уменьшается, особенно если использовать в качестве формата данных не
    XML, а JSON. Но тем не менее необходимость регулярно отправлять
    запросы серверу для получения обновленной информации останется. С
    ростом количества пользователей будет расти и количество запросов,
    открытие и закрытие которых будет неуклонно генерировать нагрузку на
    сервер. Для снижения нагрузки можно попытаться увеличивать интервал
    между запросами, но это лишь временная мера, обладающая существенным
    недостатком - увеличение этого промежутка времени повлечет за собой
    рост задержек между обновлением информации на сервере и обновлением
    клиентской части приложения.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Comet.&lt;/strong&gt; С каждым клиентом поддерживается постоянное
    HTTP-соединение, как только данные на сервере обновились - сервер
    сразу же отправляет по уже открытому соединению уведомление о
    необходимости провести изменения в клиентской части, это позволяет
    существенно сократить нагрузку на сервер и практически избавиться от
    задержек между обновлением данных на сервере и клиенте.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Для написания серверной части приложения может использоваться
практически любой язык программирования, наиболее распространенным
решением, пожалуй, является Java Servlet, запущенный в каком-либо
контейнере - Apache TomCat, Jetty или Sun GlassFish. Для реализации
этого подхода к организации общения клиента с сервером написано
достаточно большое количество framework'ов и библиотек, наиболее полный
список, я думаю, можно найти в &lt;a href="https://www.insight-it.ru/goto/b28f61a7/" rel="nofollow" target="_blank" title="http://en.wikipedia.org/wiki/Comet_%28programming%29#Implementations"&gt;английской википедии&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Но и для Comet-приложений рано или поздно возникает вопрос
масштабируемости, так как традиционные HTTP-сервера создают новый поток
(thread) для обслуживания очередных нескольких очередных новых
соединений. Каждый поток в состоянии обрабатывать только небольшое
количество HTTP-соединений, а так как в случае с Comet соединения
находятся в открытом состоянии неопределенно долго, для каждых
нескольких новых пользователей веб-приложения приходится создавать новый
поток. Количество одновременно существующих потоков не безгранично, что
в один прекрасный момент приводит к существенному росту издержек,
связанных с созданием новых и управлением существующими потоками, а
также все чаще и чаще возникающим отказам потокам в предоставлении
серверу необходимых вычислительных. В таких ситуациях некоторые
пользователи встречаются с неприемлимыми задержками в работе приложения
или непредвиденными сообщениями об ошибках. Наиболее простым и в то же
время эффективным решением подобной проблемы является горизонтальное
масштабирование Comet-серверов с балансировкой нагрузки на программном
или аппаратном уровне.&lt;/p&gt;
&lt;p&gt;Если Вас заинтересовала эта тема - могу посоветовать взглянуть на пару
достаточно интересных статей, в котором более с практической точки
зрения описывается этот подход к построению приложений:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/2c5c0107/" rel="nofollow" target="_blank" title="http://www.ibm.com/developerworks/ru/library/j-jettydwr/"&gt;Создание масштабируемых Comet-приложений с использованием Jetty и Direct Web Remoting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/4d14c647/" rel="nofollow" target="_blank" title="http://www.javaworld.com/javaworld/jw-03-2008/jw-03-asynchhttp.html"&gt;Asynchronous HTTP and Comet Architecture&lt;/a&gt;
    (eng.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Я же надеюсь написать статью более практической на направленности по
этой теме лишь в обозримом будущем, не пропустить этот момент Вам
поможет &lt;a href="/feed/"&gt;абонемент&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Wed, 26 Mar 2008 21:13:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-03-26:frontend/2008/comet/</guid><category>AJAX</category><category>Comet</category><category>HTTP</category><category>JavaScript</category><category>persistent</category><category>архитектура</category><category>информационные технологии</category></item><item><title>Hadoop</title><link>https://www.insight-it.ru//storage/2008/hadoop/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/30a7481/" rel="nofollow" target="_blank" title="http://hadoop.apache.org/core/"&gt;Hadoop&lt;/a&gt; представляет собой платформу
для построения приложений, способных обрабатывать огромные объемы
данных. Система основывается на распределенном подходе к вычислениям и
хранению информации, основными ее особенностями являются:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Масштабируемость:&lt;/strong&gt; с помощью &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; возможно
    надежное хранение и обработка огромных объемов данных, которые могут
    измеряться петабайтами;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Экономичность:&lt;/strong&gt; информация и вычисления распределяются по
    &lt;a href="/tag/klaster/"&gt;кластеру&lt;/a&gt;, построенному на самом обыкновенном
    оборудовании. Такой кластер может состоять из тысяч узлов;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Эффективность:&lt;/strong&gt; распределение данных позволяет выполнять их
    обработку параллельно на множестве компьютеров, что существенно
    ускоряет этот процесс;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Надежность:&lt;/strong&gt; при хранении данных возможно предоставление
    избыточности, благодаря хранению нескольких копий. Такой подход
    позволяет гарантировать отсутствие потерь информации в случае сбоев
    в работе системы;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Кроссплатформенность:&lt;/strong&gt; так как основным языком программирования,
    используемым в этой системе является &lt;a href="/tag/java/"&gt;Java&lt;/a&gt;, развернуть
    ее можно на базе любой операционной системы, имеющей &lt;abbr title="Java Virtual Machine"&gt;JVM&lt;/abbr&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;!--more--&gt;
&lt;h3 id="hdfs"&gt;HDFS&lt;/h3&gt;
&lt;p&gt;В основе всей системы лежит распределенная файловая система под
незамысловатым названием &lt;strong&gt;Hadoop Distributed File System&lt;/strong&gt;.
Представляет она собой вполне стандартную распределенную файловую
систему, но все же она обладает рядом особенностей:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Устойчивость к сбоям, разработчики рассматривали сбои в оборудовании
    скорее как норму, чем как исключение;&lt;/li&gt;
&lt;li&gt;Приспособленность к развертке на самом обыкновенном ненадежном
    оборудовании;&lt;/li&gt;
&lt;li&gt;Предоставление высокоскоростного потокового доступа ко всем данным;&lt;/li&gt;
&lt;li&gt;Настроена для работы с большими файлами и наборами файлов;&lt;/li&gt;
&lt;li&gt;Простая модель работы с данными: &lt;em&gt;один раз записали - много раз
    прочли&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;Следование принципу: &lt;em&gt;переместить вычисления проще, чем переместить
    данные&lt;/em&gt;;&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Архитектура HDFS&lt;/h4&gt;
&lt;p&gt;Проще всего ее демонстрирует схема,
&lt;a href="https://www.insight-it.ru/goto/9c57006b/" rel="nofollow" target="_blank" title="http://hadoop.apache.org/core/docs/current/images/hdfsarchitecture.gif"&gt;позаимствованная&lt;/a&gt; с официального сайта проекта и переведенная мной на руский:
&lt;img alt="Архитектура HDFS" class="responsive-img" src="https://www.insight-it.ru/images/hdfsarchitecture.jpg" title="Архитектура HDFS"/&gt;&lt;/p&gt;
&lt;p&gt;Действующие лица:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Namenode&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Этот компонент системы осуществляет всю работу с метаданными. Он
должен быть запущен только на одном компьютере в кластере. Именно он
управляет размещением информации и доступом ко всем данным,
расположенным на ресурсах кластера. Сами данные проходят с остальных
машин кластера к клиенту мимо него.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Datanode&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;На всех остальных компьютерах системы работает именно этот
компонент. Он располагает сами блоки данных в локальной файловой
системе для последующей передачи или обработки их по запросу
клиента. Группы узлов данных принято называть Rack, они
используются, например, в схемах репликации данных.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Клиент&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Просто приложение или пользователь, работающий с файловой системой.
В его роли может выступать практически что угодно.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Пространство имен &lt;a href="/tag/hdfs/"&gt;HDFS&lt;/a&gt; имеет классическую иерархическую
структуру: пользователи и приложения имеют возможность создавать
директории и файлы. Файлы хранятся в виде блоков данных произвольной (но
одинаковой, за исключением последнего; по-умолчанию 64 mb) длины,
размещенных на &lt;strong&gt;Datanode&lt;/strong&gt;'ах. Для обеспечения отказоустойчивости блоки
хранятся в нескольких экземплярах на разных узлах, имеется возможность
настройки количества копий и алгоритма их распределения по системе.
Удаление файлов происходит не сразу, а через какое-то время после
соответствующего запроса, так как после получения запроса файл
перемещается в директорию &lt;strong&gt;/trash&lt;/strong&gt; и хранится там определенный период
времени на случай если пользователь или приложение передумают о своем
решении. В этом случае информацию можно будет восстановить, в противном
случае - физически удалить.&lt;/p&gt;
&lt;p&gt;Для обнаружения возникновения каких-либо неисправностей, &lt;strong&gt;Datanode&lt;/strong&gt;
периодически отправляют &lt;strong&gt;Namenode&lt;/strong&gt;'у сигналы о своей
работоспособности. При прекращении получения таких сигналов от одного из
узлов &lt;strong&gt;Namenode&lt;/strong&gt; помечает его как &lt;em&gt;"мертвый"&lt;/em&gt;, и прекращает какой-либо
с ним взаимодействие до возвращения его работоспособности. Данные,
хранившиеся на &lt;em&gt;"умершем"&lt;/em&gt; узле реплицируются дополнительный раз из
оставшихся &lt;em&gt;"в живых"&lt;/em&gt; копий и система продолжает свое функционирование
как ни в чем не бывало.&lt;/p&gt;
&lt;p&gt;Все коммуникации между компонентами файловой системы проходят по
специальным протоколам, основывающимся на стандартном &lt;strong&gt;TCP/IP&lt;/strong&gt;.
Клиенты работают с &lt;strong&gt;Namenode&lt;/strong&gt; с помощью так называемого
&lt;strong&gt;ClientProtocol&lt;/strong&gt;, а передача данных происходит по
&lt;strong&gt;DatanodeProtocol&lt;/strong&gt;, оба они &lt;em&gt;обернуты&lt;/em&gt; в &lt;strong&gt;Remote Procedure Call
(RPC)&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Система предоставляет несколько интерфейсов, среди которых командная
оболочка &lt;strong&gt;DFSShell&lt;/strong&gt;, набор ПО для администрирования &lt;strong&gt;DFSAdmin&lt;/strong&gt;, а
также простой, но эффективный веб-интерфейс. Помимо этого существуют
несколько API для языков программирования: Java API, C pipeline, WebDAV
и так далее.&lt;/p&gt;
&lt;h3 id="mapreduce"&gt;MapReduce&lt;/h3&gt;
&lt;p&gt;Помимо файловой системы, &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; включает в себя framework
для проведения масштабных вычислений, обрабатывающих огромные объемы
данных. Каждое такое вычисление называется Job (задание) и состоит оно,
как видно из названия, из двух этапов:&lt;/p&gt;
&lt;dl&gt;
&lt;dt&gt;&lt;strong&gt;Map&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Целью этого этапа является представление произвольных данных (на
практике чаще всего просто пары ключ-значение) в виде промежуточных
пар ключ-значение. Результаты сортируются и групируются по ключу и
передаются на следующий этап.&lt;/dd&gt;
&lt;dt&gt;&lt;strong&gt;Reduce&lt;/strong&gt;&lt;/dt&gt;
&lt;dd&gt;Полученные после &lt;strong&gt;map&lt;/strong&gt; значения используются для финального
вычисления требуемых данных. Практические любые данные могут быть
получены таким образом, все зависит от требований и функционала
приложения.&lt;/dd&gt;
&lt;/dl&gt;
&lt;p&gt;Задания выполняются, подобно файловой системе, на всех машинах в
кластере (чаще всего одних и тех же). Одна из них выполняет роль
управления работой остальных - &lt;strong&gt;JobTracker&lt;/strong&gt;, остальные же ее
бесприкословно слушаются - &lt;strong&gt;TaskTracker&lt;/strong&gt;. В задачи &lt;strong&gt;JobTracker&lt;/strong&gt;'а
входит составление расписания выполняемых работ, наблюдение за ходом
выполнения, и перераспределение в случае возникновения сбоев.&lt;/p&gt;
&lt;p&gt;В общем случае каждое приложение, работающее с этим framework'ом,
предоставляет методы для осуществления этапов &lt;strong&gt;map&lt;/strong&gt; и &lt;strong&gt;reduce&lt;/strong&gt;, а
также указывает расположения входных и выходных данных. После получения
этих данных &lt;strong&gt;JobTracker&lt;/strong&gt; распределяет задание между остальными
машинами и предоставляет клиенту полную информацию о ходе работ.&lt;/p&gt;
&lt;p&gt;Помимо основных вычислений могут выполняться вспомогательные процессы,
такие как составление отчетов о ходе работы, кэширование, сортировка и
так далее.&lt;/p&gt;
&lt;h3 id="hbase"&gt;HBase&lt;/h3&gt;
&lt;p&gt;&lt;img alt="HBase Logo" class="right" src="https://www.insight-it.ru/images/hbase-logo.png" title="HBase"/&gt;
В рамках &lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; доступна еще и система хранения данных,
которую правда сложно назвать &lt;a href="/tag/subd/"&gt;СУБД&lt;/a&gt; в традиционном смысле
этого слова. Чаще проводят аналогии с проприетарной системой этого же
плана от &lt;a href="/tag/google/"&gt;Google&lt;/a&gt; - &lt;a href="/tag/bigtable/"&gt;BigTable&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/12419d3d/" rel="nofollow" target="_blank" title="http://hadoop.apache.org/hbase"&gt;HBase&lt;/a&gt; представляет собой
распределенную систему хранения больших объемов данных. Подобно
реляционным СУБД данные хранятся в виде таблиц, состоящих из строк и
столбцов. И даже для доступа к ним предоставляется язык запросов &lt;strong&gt;HQL&lt;/strong&gt;
(как ни странно - &lt;strong&gt;Hadoop Query Language&lt;/strong&gt;), отдаленно напоминающий
более распространенный &lt;a href="/tag/sql/"&gt;SQL&lt;/a&gt;. Помимо этого предоставляется
итерирующмй интерфейс для сканирования наборов строк.&lt;/p&gt;
&lt;p&gt;Одной из основных особенностей хранения данных в &lt;strong&gt;HBase&lt;/strong&gt; является
возможность наличия нескольких значений, соответствующих одной
комбинации таблица-строка-столбец, для их различения используется
информация о времени добавления записи. На концептуальном уровне таблицы
обычно представляют как набор строк, но физически же они хранятся по
столбцам, достаточно важный факт, который стоит учитывать при разработки
схемы хранения данных. Пустые ячейки не отображаются каким-либо образом
физически в хранимых данных, они просто отсутствуют. Существуют конечно
и другие нюансы, но я постарался упомянуть лишь основные.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;HQL&lt;/strong&gt; очень прост по своей сути, если Вы уже знаете &lt;a href="/tag/sql/"&gt;SQL&lt;/a&gt;,
то для изучения его Вам понадобится лишь просмотреть по диагонали
коротенький вывод команды &lt;strong&gt;help;&lt;/strong&gt;, занимающий всего пару экранов в
консоли. Все те же &lt;strong&gt;SELECT&lt;/strong&gt;, &lt;strong&gt;INSERT&lt;/strong&gt;, &lt;strong&gt;UPDATE&lt;/strong&gt;, &lt;strong&gt;DROP&lt;/strong&gt; и так
далее, лишь со слегка измененным синтаксисом.&lt;/p&gt;
&lt;p&gt;Помимо обычно командной оболочки &lt;strong&gt;HBase Shell&lt;/strong&gt;, для работы с &lt;strong&gt;HBase&lt;/strong&gt;
также предоставлено несколько API для различных языков программирования:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/f059ad5e/" rel="nofollow" target="_blank" title="http://hadoop.apache.org/hbase/docs/current/api/index.html"&gt;Java&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/e44fcd5/" rel="nofollow" target="_blank" title="http://wiki.apache.org/hadoop/Hbase/Jython"&gt;Jython&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/8282e2e2/" rel="nofollow" target="_blank" title="http://wiki.apache.org/hadoop/Hbase/HbaseRest"&gt;REST&lt;/a&gt; и&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.insight-it.ru/goto/185bb3f7/" rel="nofollow" target="_blank" title="http://wiki.apache.org/hadoop/Hbase/ThriftApi"&gt;Thrift&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="zakliuchenie"&gt;Заключение&lt;/h3&gt;
&lt;p&gt;&lt;a href="/tag/hadoop/"&gt;Hadoop&lt;/a&gt; является отличным решением для построения
высоконагруженных приложений, которое уже активно используется
&lt;a href="https://www.insight-it.ru/goto/ab057c2a/" rel="nofollow" target="_blank" title="http://wiki.apache.org/hadoop/PoweredBy"&gt;множеством интернет-проектов&lt;/a&gt;.
В последующих постах на эту тему я постараюсь описать процесс
развертывания этой системы и написания приложений, работающих по
принципу &lt;a href="/tag/mapreduce/"&gt;MapReduce&lt;/a&gt;. Не пропустить момент их публикации
Вам может помочь подписка на &lt;a href="/feed/"&gt;RSS-ленту&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 22 Feb 2008 22:41:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-02-22:storage/2008/hadoop/</guid><category>Hadoop</category><category>HBase</category><category>HDFS</category><category>Java</category><category>MapReduce</category><category>архитектура</category><category>информационные технологии</category><category>кластер</category><category>Масштабируемость</category><category>распределенные вычисления</category><category>технология</category></item><item><title>Обзор memcached</title><link>https://www.insight-it.ru//storage/2008/obzor-memcached/</link><description>&lt;p&gt;&lt;a href="https://www.insight-it.ru/goto/62123c99/" rel="nofollow" target="_blank" title="http://www.danga.com/memcached/"&gt;&lt;strong&gt;memcached&lt;/strong&gt;&lt;/a&gt; представляет собой
высокопроизводительную распределенную систему кэширования объектов в
оперативной памяти.&lt;/p&gt;
&lt;p&gt;Оформлена она в виде классического &lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'а, слушающего
подключения на одном из TCP-портов (по-умолчанию: 11211). Работа же с
ним осуществляется с помощью клиентских библиотек, доступных практически
для всех популярных языков программирования.
&lt;!--more--&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; не использует конфигурационные файлы, но
все же может быть в какой-то степени настроен под свои нужды с помощью
параметров, указываемых при запуске &lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'а, и
переменных окружения. Например, часто используется параметр &lt;strong&gt;-m&lt;/strong&gt;,
позволяющий указать объем используемой для хранения объектов оперативной
памяти.
По сути кэширование с помощью &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; представляет
собой некое подобие глобального ассоциативного массива, то есть набора
соответствий &lt;em&gt;ключ &amp;rarr; объект&lt;/em&gt;.&lt;/p&gt;
&lt;h3 id="kak-zhe-ono-rabotaet"&gt;Как же оно работает?&lt;/h3&gt;
&lt;p&gt;Принцип очень прост: после установления соединения между клиентом
(произвольное приложение, воспользовавшееся услугами одной из клиентских
библиотек) и сервером (распределенной системой, состоящей из
&lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'ов), клиенту предоставляется возможность выполнять
четыре примитивных действия для организации кэширования:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;set&lt;/strong&gt; - установить соответствие между ключом и указанным объектом;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;add&lt;/strong&gt; - аналогично &lt;em&gt;set&lt;/em&gt;, но только при условии, что объекта с
    таким ключом в кэше нет;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;replace&lt;/strong&gt; - абсолютная противоположность &lt;em&gt;add&lt;/em&gt;, выполняется только
    если такой объект в кэше есть;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;get&lt;/strong&gt; - получить объект из кэша по указанному ключу.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Вывод напрашивается лишь один: проще не придумаешь.&lt;/p&gt;
&lt;h3 id="v-sravnenii"&gt;В сравнении&lt;/h3&gt;
&lt;p&gt;Многие &lt;a href="/tag/subd/"&gt;СУБД&lt;/a&gt; предоставляют встроенные средства кэширования,
но на практике они умеют кэшировать только результаты запросов, что не
всегда является именно тем, что необходимо веб-приложению. СУБД обычно
полностью очищают кэш таблицы при каждом изменении данных, что приводит
к полной его бесполезности при активном обновлении таблиц.&lt;/p&gt;
&lt;p&gt;Еще один альтернативный вариант кэширования может предоставить
http-сервер, в большинстве случаев кэш дублируется несколько раз для
каждого процесса &lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, &lt;a href="/tag/perl/"&gt;Perl&lt;/a&gt; или любого другого
используемого языка программирования. Помимо излишних затрат оперативной
памяти, такой вариант развития событий еще и снижает эффективность
самого кэша.&lt;/p&gt;
&lt;h3 id="na-praktike"&gt;На практике&lt;/h3&gt;
&lt;p&gt;Использование &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt; на практике в написании
приложений ничуть не сложнее, чем в теории. Например, если говорить о
&lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, то для доступа к &lt;a href="/tag/daemon/"&gt;daemon&lt;/a&gt;'y достаточно
установить соответствующий &lt;a href="https://www.insight-it.ru/goto/a0e58a5c/" rel="nofollow" target="_blank" title="http://pecl.php.net/package/memcache"&gt;PECL extension&lt;/a&gt;, который предоставит класс &lt;strong&gt;Memcached&lt;/strong&gt;. С помощью его методов осуществляется доступ ко всем возможностям &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, о которых я уже упоминал: &lt;strong&gt;connect&lt;/strong&gt;, &lt;strong&gt;set&lt;/strong&gt;, &lt;strong&gt;add&lt;/strong&gt;, &lt;strong&gt;get&lt;/strong&gt; и так далее.&lt;/p&gt;
&lt;p&gt;Для многих других языков программирования также существуют API, список
которых можно &lt;a href="https://www.insight-it.ru/goto/94c7c37e/" rel="nofollow" target="_blank" title="http://www.danga.com/memcached/apis.bml"&gt;найти на официальном сайте&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id="o-chem-ne-stoit-zabyvat"&gt;О чем не стоит забывать&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Кэш не является базой данных!&lt;/em&gt; Не стоит забывать, что кэш является
&lt;em&gt;очень&lt;/em&gt; ненадежным местом хранения данных, не предоставляет избыточности
и каких-либо гарантий, что сохраненная в нем информация будет доступна
через какое-то время. За производительность приходится платить.&lt;/p&gt;
&lt;h3 id="v-zakliuchenii"&gt;В заключении&lt;/h3&gt;
&lt;p&gt;...хотелось бы сказать, что эта &lt;a href="/tag/tekhnologiya/"&gt;технология&lt;/a&gt; является
очень производительным и эффективным решением вопроса кэширования для
масштабных интернет-проектов. Возможности по ее применению не
ограничиваются Сетью, ведь она реализована в виде обычного daemon'а, что
открывает ее для всего спектра программного обеспечения, так или иначе
следующего &lt;a href="/tag/unix-way/"&gt;"Unix&amp;nbsp;way"&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Thu, 21 Feb 2008 18:08:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-02-21:storage/2008/obzor-memcached/</guid><category>cash</category><category>cashing</category><category>daemon</category><category>Memcached</category><category>информационные технологии</category><category>кэш</category><category>кэширование</category><category>производительность</category><category>реализация</category><category>технология</category><category>unix way</category></item><item><title>На пути к идеалу</title><link>https://www.insight-it.ru//php/2008/na-puti-k-idealu/</link><description>&lt;blockquote&gt;
&lt;p&gt;...или 15 привычек, которые помогут ускорить PHP-приложение&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Практически каждый программист стремится в своих приложениях не только
максимально точно реализовать требуемый функционал, но и сделать это как
можно более эффективным методом. Для этого конечно же необходимо
проектирование, подходящий выбор используемых технологий, возможно
некоторый опыт в предметной области, этот список можно продолжать
достаточно долго, но я позволю себе этого не делать, так как речь
сегодня пойдет не об этом. Вместо этого хочу обратить Ваше внимание на
более простые и "приземленные" методы &lt;a href="/tag/optimizaciya/"&gt;оптимизации&lt;/a&gt;
PHP-кода, которые может быть и не так эффективны по сравнению с
указанными выше, но зато не требуют каких-либо усилий со стороны кодера
и/или программиста, достаточно лишь воспринимать их как "не вредные"
привычки.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Прочитав достаточно солидный объем разного рода документации по
&lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, я часто натыкался на статьи и тексты, так или иначе
связанные с &lt;a href="/tag/proizvoditelnost/"&gt;производительностью&lt;/a&gt; PHP-скриптов.
Порой в такого рода источниках информации удавалось найти достаточно
интересные и неочевидные факты об этом языке программирования, которые
не смотря на свою простоту могли дать вполне заметный прирост к
&lt;a href="/tag/proizvoditelnost/"&gt;производительности&lt;/a&gt; итогового приложения. Я
почему-то очень серьезно стал относиться к производительности написанных
мной скриптов, и довольно часто стал испытывать на практике спорные
моменты в реализации, о которых узнавал из Сети или каких-либо
других источников, с помощью самописных или
&lt;a href="/tag/opensource/"&gt;opensource&lt;/a&gt; benchmark'ов, хотя порой и просто внедряя
в реальные приложения. Как ни странно, в большинстве случаев практика
подтверждала теорию, и я стал постоянно пользоваться этими простыми
правилами, о которых я и хочу Вам рассказать.&lt;/p&gt;
&lt;h4&gt;Повышения значения индекса с помощью ++\$i;&lt;/h4&gt;
&lt;p&gt;Этот факт был наверное одним из самых удивительных для меня, когда я
впервые о нем услышал, но действительно операция &lt;strong&gt;++&lt;span style="color: blue"&gt;\$i&lt;/span&gt;&lt;/strong&gt;; выполняется несколько быстрее, чем
&lt;strong&gt;&lt;span style="color: blue"&gt;\$i&lt;/span&gt;++;&lt;/strong&gt;. или другие вариации на ту
же тему вроде &lt;strong&gt;&lt;span style="color: blue"&gt;\$i&lt;/span&gt;+=&lt;span style="color: blue"&gt;1&lt;/span&gt;;&lt;/strong&gt;. Привычка использовать в качестве
индекса цикла переменную под названием i, казалось бы стара как Мир, мне
она досталась в наследство от &lt;strong&gt;C&lt;/strong&gt;, а в месте с ней "в комплекте" шла
привычка писать выражение &lt;strong&gt;i++&lt;/strong&gt; в заголовках циклов. Разница в
скорости обработки этих выражений, насколько мне известно, обусловлена
разным количеством элементарных машинных операций, которые необходимо
выполнить процессору (в точных цифрах не уверен, пишу по памяти, но
&lt;strong&gt;++&lt;span style="color: blue"&gt;\$i&lt;/span&gt;;&lt;/strong&gt; требует трех элементарных
операций, а &lt;strong&gt;&lt;span style="color: blue"&gt;\$i&lt;/span&gt;++;&lt;/strong&gt; &amp;ndash; четырех). В
справедливости этого факта не трудно убедиться, достаточно написать
простенький скрипт, состоящий из цикла с достаточно большим количеством
итераций, и замерить любым способом точное время его выполнения при
использовании разных способов инкрементации индекса цикла.&lt;/p&gt;
&lt;h4&gt;Вывод статического контента без помощи PHP&lt;/h4&gt;
&lt;p&gt;Сейчас тот факт, что использование интерпретатора PHP для вывода
статического контента сильно замедляет этот процесс, кажется мне
очевидным, но поначалу я использовал &lt;strong&gt;&lt;span style="color: #17349c"&gt;echo&lt;/span&gt;&lt;/strong&gt; там, где он был необходим, ничуть
не чаще, чем там, где он лишь замедляет работу скрипта. От использования
еще менее эффективного способа - &lt;strong&gt;&lt;span style="color: #17349c"&gt;print&lt;/span&gt;&lt;/strong&gt;, меня избавила моя лень: писать
каждый раз на одну букву больше дико не хотелось (в отличии от &lt;strong&gt;&lt;span style="color: #17349c"&gt;echo&lt;/span&gt;&lt;/strong&gt;, &lt;strong&gt;&lt;span style="color: #17349c"&gt;print&lt;/span&gt;&lt;/strong&gt; возвращает информацию об
успешности выполнения своей работы, что в большинстве случаев
просто-напросто не нужно). Проверить опять же не трудно - нужен лишь
объемистый текстовый файл, который достаточно вывести в browser разными
способами и засечь уходящее на это время.&lt;/p&gt;
&lt;h4&gt;Вывод статического контента из отдельного файла&lt;/h4&gt;
&lt;p&gt;Частенько при желании выполнить указанное в заголовке действие по
привычке используют &lt;strong&gt;&lt;span style="color: #a3a423"&gt;include&lt;/span&gt;&lt;/strong&gt;,
&lt;strong&gt;&lt;span style="color: #a3a423"&gt;require&lt;/span&gt;&lt;/strong&gt; или их &lt;strong&gt;&lt;span style="color: #a3a423"&gt;_once&lt;/span&gt;&lt;/strong&gt; версии, что является далеко не
самой лучшей идеей с точки зрения производительности. Самым быстрыми
быстрыми и экономичными поотношению к оперативной памяти являются
функции &lt;strong&gt;&lt;span style="color: #17349c"&gt;readfile&lt;/span&gt;&lt;/strong&gt; и &lt;strong&gt;&lt;span style="color: #17349c"&gt;fpassthru&lt;/span&gt;&lt;/strong&gt;. В качестве доказательства
этого факта приведу таблицу, демонстрирующую статистику выполнения этой
операции различными методами и позаимствованную с &lt;a href="https://www.insight-it.ru/goto/f18fa5ab/" rel="nofollow" target="_blank" title="http://www.raditha.com/wiki/Readfile_vs_include"&gt;одного англоязычного
сайта&lt;/a&gt;:&lt;/p&gt;
&lt;table align="center" border="1" cellspacing="0" width="100%"&gt;
&lt;tr&gt;
&lt;th align="center" rowspan="2" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial" valign="center"&gt;
Функция

&lt;/th&gt;
&lt;th align="center" colspan="2" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial"&gt;
Время (сек.)

&lt;/th&gt;
&lt;th align="center" colspan="2" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial"&gt;
Оперативная память (байт)

&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="center" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial"&gt;
32Kb файл

&lt;/td&gt;
&lt;td align="center" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial"&gt;
1Mb файл

&lt;/td&gt;
&lt;td align="center" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial"&gt;
32Kb файл

&lt;/td&gt;
&lt;td align="center" style="background: #fcfcc0 none repeat scroll 0% 50%; -moz-background-clip: -moz-initial; -moz-background-origin: -moz-initial; -moz-background-inline-policy: -moz-initial"&gt;
1Mb файл

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
file\_get\_contents

&lt;/td&gt;
&lt;td align="right"&gt;
0.00152

&lt;/td&gt;
&lt;td align="right"&gt;
0.00564

&lt;/td&gt;
&lt;td align="right"&gt;
52480

&lt;/td&gt;
&lt;td align="right"&gt;
1067856

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
fpassthru

&lt;/td&gt;
&lt;td align="right"&gt;
**0.00117**

&lt;/td&gt;
&lt;td align="right"&gt;
0.00184

&lt;/td&gt;
&lt;td align="right"&gt;
20016

&lt;/td&gt;
&lt;td align="right"&gt;
20032

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
fgets

&lt;/td&gt;
&lt;td align="right"&gt;
0.00195

&lt;/td&gt;
&lt;td align="right"&gt;
0.07190

&lt;/td&gt;
&lt;td align="right"&gt;
30760

&lt;/td&gt;
&lt;td align="right"&gt;
30768

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
file

&lt;/td&gt;
&lt;td align="right"&gt;
0.00157

&lt;/td&gt;
&lt;td align="right"&gt;
0.06464

&lt;/td&gt;
&lt;td align="right"&gt;
87344

&lt;/td&gt;
&lt;td align="right"&gt;
2185624

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
require\_once

&lt;/td&gt;
&lt;td align="right"&gt;
0.00225

&lt;/td&gt;
&lt;td align="right"&gt;
0.08065

&lt;/td&gt;
&lt;td align="right"&gt;
67992

&lt;/td&gt;
&lt;td align="right"&gt;
2067696

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;
readfile

&lt;/td&gt;
&lt;td align="right"&gt;
**0.00117**

&lt;/td&gt;
&lt;td align="right"&gt;
0.00191

&lt;/td&gt;
&lt;td align="right"&gt;
**19192**

&lt;/td&gt;
&lt;td align="right"&gt;
19208

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;h4&gt;Вывод переменных&lt;/h4&gt;
&lt;p&gt;Наверняка вам известно, что переменные можно выводить с помощью
конструкции вроде &lt;strong&gt;&lt;span style="color: #17349c"&gt;echo&lt;/span&gt; &lt;span style="color: red"&gt;"&lt;/span&gt;&lt;span style="color: blue"&gt;\$var&lt;/span&gt; &lt;span style="color: red"&gt;text"&lt;/span&gt;;&lt;/strong&gt;, что является одним из самых удобных
вариантов решения этой задачи благодаря минимальному количеству
символов, которые необходимо набрать, но с точки зрения быстродействия
этот вариант далек от идеала, так как влечет за собой достаточно
серьезные преобразования в памяти сервера, эффект которых порой бывает
заметен невооруженным глазом. Частично ущерб производительности можно
сгладить заменой этой конструкции на &lt;strong&gt;&lt;span style="color: #17349c"&gt;echo&lt;/span&gt; &lt;span style="color: blue"&gt;\$var&lt;/span&gt;.&lt;span style="color: red"&gt;"
text"&lt;/span&gt;;&lt;/strong&gt;, что приводит к несколькому усложнению внешнего вида
кода и несколько поправляет ситуацию со скоростью выполнения. Но как
известно знак . обозначает конкатенацию двух строк, что тоже требует
некоторых вычислений и затрат памяти, но и от нее можно избавиться,
заменив на запятую. Выражение &lt;strong&gt;&lt;span style="color: #17349c"&gt;echo&lt;/span&gt;
&lt;span style="color: blue"&gt;\$var&lt;/span&gt;,&lt;span style="color: red"&gt;"
text"&lt;/span&gt;;&lt;/strong&gt; ничем по своему эффекту не отличается от предложенных
ранее вариантов, за исключением максимального быстрого выполнения,
обусловленного отсутствием дополнительных преобразований в процессе
передачи просто последовательности из константы и переменной.&lt;/p&gt;
&lt;h4&gt;Избегайте выполнения лишних действий&lt;/h4&gt;
&lt;p&gt;Достаточно абстрактное утверждение, но тем не мение постоянное
напоминание себе о нем может избавить Вас от совершения массы ошибок.
Самой широкораспространенной является наверное вызов какой-либо функции
(чаще всего &lt;strong&gt;&lt;span style="color: #17349c"&gt;count&lt;/span&gt;();&lt;/strong&gt; или &lt;strong&gt;&lt;span style="color: #17349c"&gt;strlen&lt;/span&gt;();&lt;/strong&gt;) в проверке условия выхода из
цикла. Когда-нибудь доводилось писать видеть в собственном или чужом
коде выражение вида &lt;strong&gt;&lt;span style="color: #a3a423"&gt;for&lt;/span&gt;(&lt;span style="color: blue"&gt;\$i&lt;/span&gt; = &lt;span style="color: #a3a423"&gt;0&lt;/span&gt;;
&lt;span style="color: blue"&gt;\$i&lt;/span&gt; \&amp;lt; &lt;span style="color: #17349c"&gt;count&lt;/span&gt;(&lt;span style="color: blue"&gt;\$array&lt;/span&gt;); ++&lt;span style="color: blue"&gt;\$i&lt;/span&gt;) { ... }&lt;/strong&gt;? А задумываться о
последовательности выполнения действий при его обработке? Стоит только
немного начать размышлять и ошибка становится очевидной: &lt;strong&gt;&lt;span style="color: #17349c"&gt;count&lt;/span&gt;();&lt;/strong&gt; выполняется при каждой итерации
цикла, что приводит к подсчету количества элементов массива при каждой
проверки условия выхода из цикла - почему бы не посчитать это значение
заранее и сравнивать значения индекса с переменной, а не с результатом
выполнения функции?&lt;/p&gt;
&lt;h4&gt;@&lt;/h4&gt;
&lt;p&gt;Использование этого оператора стоит избегать при каждой возможности.
Казалось бы такое простое действие, как сокрытие вывода возможного
сообщения об ошибке, влечет за собой достаточно трудоемкую
последовательность действий: устанавливает значение параметра
PHP-интерпретатора &lt;strong&gt;error_reporting = 0&lt;/strong&gt;, выполняет указанное за этим
оператором действие, возвращает значение &lt;strong&gt;error_reporting&lt;/strong&gt; в исходное
состояние.&lt;/p&gt;
&lt;h4&gt;Маленькие мелочи&lt;/h4&gt;
&lt;p&gt;Развивая тему предыдущего подраздела, хочется обратить внимания, что
даже на еще более элементарных вещах можно сэкономить драгоценное
процессорное время:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Вместо условия &lt;strong&gt;&lt;span style="color: #a3a423"&gt;if&lt;/span&gt;(&lt;span style="color: blue"&gt;\$variableOne&lt;/span&gt; == &lt;span style="color: blue"&gt;\$variableTwo&lt;/span&gt;) { ... }&lt;/strong&gt; можно написать
    &lt;strong&gt;&lt;span style="color: #a3a423"&gt;if&lt;/span&gt;(&lt;span style="color: blue"&gt;\$variableOne&lt;/span&gt; === &lt;span style="color: blue"&gt;\$variableTwo&lt;/span&gt;) { ... }&lt;/strong&gt;, что избавит от
    проверки на соответствие типов данных и приведения их друг к другу,
    в некоторых случаях эти действия эти случаях эти действия конечно же
    и бывают необходимы, но бывает это далеко не часто.&lt;/li&gt;
&lt;li&gt;Глядя на выражения вроде &lt;strong&gt;&lt;span style="color: #a3a423"&gt;if&lt;/span&gt;(&lt;span style="color: blue"&gt;\$boolean&lt;/span&gt; == true) { ... }&lt;/strong&gt;, я чаще
    всего вспоминаю цитату из одного малоизвестного интернет-ресурса:
    &lt;strong&gt;if (b.ToString().length \&amp;lt; 5) { ... }&lt;/strong&gt;. Хоть и не имет никакого
    отношения к PHP, но суть проблемы отражает очень ярко.&lt;/li&gt;
&lt;li&gt;Самым очевидным способом проверить попадает ли длина строки в
    какой-либо диапазон является использование функции &lt;strong&gt;&lt;span style="color: #17349c"&gt;strlen&lt;/span&gt;();&lt;/strong&gt; и сравнение полученного
    результата с фиксированными значениями, но зачем выполнять лишний
    вызов функции, если можно воспользоваться услугами конструкцией
    языка PHP &lt;strong&gt;&lt;span style="color: #17349c"&gt;isset&lt;/span&gt;();&lt;/strong&gt; для
    определения наличия в строке определенных символов. &lt;strong&gt;&lt;span style="color: #a3a423"&gt;if&lt;/span&gt;(&lt;span style="color: #17349c"&gt;isset&lt;/span&gt;(&lt;span style="color: blue"&gt;\$str&lt;/span&gt;{&lt;span style="color: blue"&gt;5&lt;/span&gt;})) { ... }&lt;/strong&gt; приведет к абсолютно тем
    же результатам, что и &lt;strong&gt;&lt;span style="color: #a3a423"&gt;if&lt;/span&gt;(&lt;span style="color: #17349c"&gt;strlen&lt;/span&gt;(\$str)&amp;gt;4){ ... }&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Битовые операции выполняются намного быстрее относительно обычных
    арифметических действий. Об этом факте редко вспоминают, да и
    работать с ними умеет далеко не каждый, но порой они бывают очень
    актуальны, особенно при частой работе с числами кратными двойке.&lt;/li&gt;
&lt;li&gt;Угадайте, что делает интерпретатор при виде надписи &lt;strong&gt;&lt;span style="color: blue"&gt;1&lt;/span&gt;/&lt;span style="color: blue"&gt;2&lt;/span&gt;&lt;/strong&gt;?
    Правильно: делит &lt;strong&gt;&lt;span style="color: blue"&gt;1&lt;/span&gt;&lt;/strong&gt; на &lt;strong&gt;&lt;span style="color: blue"&gt;2&lt;/span&gt;&lt;/strong&gt;. Зачем лишний раз утруждать его,
    когда можно написать просто половину - &lt;strong&gt;&lt;span style="color: blue"&gt;0.5&lt;/span&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;При возвращении значения переменной из функции при помощи &lt;strong&gt;&lt;span style="color: #17349c"&gt;global&lt;/span&gt;&lt;/strong&gt; выполняется на порядок больше
    действий, чем при классическом &lt;strong&gt;&lt;span style="color: #17349c"&gt;return&lt;/span&gt;&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Конечно же фраза &lt;strong&gt;&lt;span style="color: blue"&gt;\$array&lt;/span&gt;[text];&lt;/strong&gt;
    интерпритируется практически точно так же, как и &lt;strong&gt;&lt;span style="color: blue"&gt;\$array&lt;/span&gt;[&lt;span style="color: red"&gt;'text'&lt;/span&gt;];&lt;/strong&gt;, но зачем выполнять лишнее
    преобразование из необъявленной константы в строку, проверять, что
    такой константы все же не существует, выводить сообщение типа
    &lt;strong&gt;E_NOTICE&lt;/strong&gt;, если можно всего этого не делать?&lt;/li&gt;
&lt;li&gt;По возможности не используйте &lt;strong&gt;&lt;span style="color: #17349c"&gt;require_once&lt;/span&gt;();&lt;/strong&gt; или &lt;strong&gt;&lt;span style="color: #17349c"&gt;include_once&lt;/span&gt;();&lt;/strong&gt; неоднократно по
    отношению к одному и тому же файлу. При отсутствии какого-либо
    эффекта, попусту тратится время на обработку повторного запроса.&lt;/li&gt;
&lt;li&gt;Даже "безобидных" ошибок стоит избегать, лишняя проаерка потратит не
    так много процессорного времени, как генерирование достаточно
    длинного сообщения об ошибке и вывод его в &lt;em&gt;stdout&lt;/em&gt;, &lt;em&gt;stderr&lt;/em&gt; или
    &lt;em&gt;лог-файл&lt;/em&gt;, а также не стоит забывать, что даже "безобидные" ошибки
    могут стать потенциальной угрозой безопасности приложения вцелом.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;В заключении...&lt;/h4&gt;
&lt;p&gt;...хотелось бы упомянуть одну из первых статей по
&lt;a href="/tag/optimizaciya/"&gt;оптимизации&lt;/a&gt; &lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;, которые мне доводилось
читать, до сих пор храню ссылку на нее в bookmark'ах, именно она и
выступала в роли &lt;em&gt;&lt;a href="https://www.insight-it.ru/goto/ce3d47c9/" rel="nofollow" target="_blank" title="http://mgccl.com/php-speed-freaks"&gt;одного из основных источников
информации&lt;/a&gt;&lt;/em&gt; для этого текста. В
качестве возможных вариантов продолжения чтения про &lt;a href="/tag/php/"&gt;PHP&lt;/a&gt;
хотелось бы предложить Вам соответствующие &lt;a href="/category/php/"&gt;раздел сайта&lt;/a&gt;, &lt;a href="https://www.insight-it.ru/dzhentelmenskij-nabor-php-programmista/"&gt;серию
статей&lt;/a&gt;, &lt;a href="/tag/php/"&gt;тэг&lt;/a&gt; и
&lt;a href="/feed/"&gt;RSS-ленту&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Thu, 07 Feb 2008 15:39:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-02-07:php/2008/na-puti-k-idealu/</guid><category>online</category><category>PHP</category><category>интернет</category><category>информационные технологии</category><category>код</category><category>кодинг</category><category>оптимизация</category><category>Программирование</category><category>производительность</category></item><item><title>Обратного пути нет</title><link>https://www.insight-it.ru//security/2008/obratnogo-puti-net/</link><description>&lt;h3 class="right" id="ili-vvedenie-v-kheshirovanie"&gt;&amp;hellip;или введение в хэширование&lt;/h3&gt;
&lt;p&gt;Под таким неоднозначным заголовком я решил разместить всеголишь
повествование о такой неотъемлимой части криптографии как hash-функции и
алгоритмы.&lt;/p&gt;
&lt;p&gt;Не думаю, что многим из читателей будет интересен этот вопрос с
математической точки зрения, а также сомневаюсь что смогу достаточно
качественно осветить его в этой перспективе, так что позволю сделать
более "приземленный" обзор возможных технологии хэширования.&lt;/p&gt;
&lt;!--more--&gt;
&lt;h3 id="vvedenie"&gt;Введение&lt;/h3&gt;
&lt;p&gt;Под словом &lt;em&gt;хэширование&lt;/em&gt; обычно понимают процесс преобразования данных
произвольной длины в двоичную строку фиксированной длины. Происходит он
с помощью хэш-функций, которые, в свою очередь, реализуют
соответствующие им алгоритмы. Таких алгоритмов и, соответственно,
функций существует достаточно много, каждый из них обладает своими
свойствами, преимуществами и недостатками.&lt;/p&gt;
&lt;p&gt;Общим фактом для всех хэш-функций является отсутствие &lt;em&gt;обратной&lt;/em&gt;
функции, то есть функции, однозначно преобразующей полученное значение
(которое как раз принято называть словом &lt;em&gt;хэш&lt;/em&gt; или &lt;em&gt;hash&lt;/em&gt;) обратно в
исходное. Факт этот достаточно очевиден - если бы любой объем информации
можно было бы преобразовать в достаточно небольшого фиксированного
размера, не зависящего от исходного объема данных, двоичную строку и при
этом иметь возможность восстановить по ней исходную информацию, то это,
как минимум, стало бы революцией в сфере хранения и архивирования
данных.&lt;/p&gt;
&lt;h3 id="svoistva"&gt;Свойства&lt;/h3&gt;
&lt;p&gt;Далеко не все хэш-функции применимы в криптографии, именно из-за того,
что, как Вы возможно уже знаете из &lt;a href="https://www.insight-it.ru/security/2008/bezopasnoe-obshhenie/"&gt;предыдущей записи о
криптографии&lt;/a&gt;, основной
целью криптографии изначально являлось сокрытие информации, а для ее
обеспечения необходимо обладание алгоритмом хэширования рядом свойств,
обеспечивающих защиту от потенциальных атак, то есть попыток раскрыть с
тои или иной степенью точности исходные данные по имеющемуся хэшу.&lt;/p&gt;
&lt;h4&gt;Устойчивость к коллизиям&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Коллизия&lt;/strong&gt; &amp;ndash; пара различных прообразов, для которых значение хэша совпадает.&lt;/p&gt;
&lt;p&gt;Устойчивость к возникновению коллизий заключается в том, что &lt;strong&gt;никто&lt;/strong&gt;
не может найти такую пару исходных строк, которая имела бы один и тот же
хэш.&lt;/p&gt;
&lt;p&gt;Если взглянуть на это свойство с точки зрения обычного образованного
человека, то нетрудно заметить, что возможных вариантов исходных данных
практически бесконечное количество, а возможных хэшей - лишь 2 в степени
фиксированной длины хэша. Из чего было бы логичным сделать вывод о том,
что такие пары существуют. Но, как ни странно для всех криптографических
алгоритмов, такие пары все еще кем-либо не найдены.&lt;/p&gt;
&lt;p&gt;Единственный возможный способ найти такие пары - вычислить с помощью
компьютера, сложно дать какое-либо четкое доказательство почему
&lt;em&gt;человек&lt;/em&gt; не в состоянии самостоятельно обнаружить коллизию, но тем не
менее это так. Если не верите на слово - можете попробовать заняться
этим сами в отношении хотябы самых простых и распространенных
алгоритмов, например &lt;strong&gt;md5&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Обнаружение коллизий с помощью специализированных программ в большинстве
случаев не является сложной задачей и ограниченно лишь вычислительной
мощностью используемых компьютеров или кластеров. Так как рост
производительность современных вычислительных систем растет семимильными
шагами, требования к устойчивости хэширующим алгоритмам растут ничуть не
меньшими темпами.&lt;/p&gt;
&lt;p&gt;В научной литературе принята своеобразная классификация алгоритмов
хэширования по устойчивости к обнаружению коллизий типов:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Первый тип&lt;/em&gt;: заключается в том, что при фиксированном первой двоичной строке - невозможно подобрать к ней вторую с таким же хэшем.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Второй тип&lt;/em&gt;: отличается от первого тем, что обнаружение коллизии невозможно и для произвольной пары сообщений.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Однонаправленность&lt;/h4&gt;
&lt;p&gt;Это свойство заключается в отсутствии возможности &lt;em&gt;эффективно&lt;/em&gt; вычислить
прообраз по хэшу и прямо вытекает из предыдущего свойства, для
подтверждения этого факта существует вполне конкретное математическое
доказательство, но приводить его здесь я, с Вашего позволения, не буду.
Одного факта устойчивости к коллизиям недостаточно для утверждения, что
алгоритм обладает свойством однонаправленности, но, как известно,
большинство криптографических алгоритмов хэширования им обладают.
Упомянутое выше доказательство базируется как раз на попытке
воспроизведения действий потенциального злоумышленника, пытающегося
опровергнуть однонаправленность алгоритма с помощью нахождения
"обратного пути" от хэша к прообразу, и доказательства обреченности его
попыток на провал.&lt;/p&gt;
&lt;h4&gt;Кардинальное изменение хэша при незначительном изменении оригинала&lt;/h4&gt;
&lt;p&gt;Еще одно не совсем очевидное свойств, связанное с предыдущими. Если бы
хэши от отличающихся на допустим один бит прообразов практически
полностью совпадали, то этот факт сильно упрощал бы вычисление возможных
коллизий и, как следствие (или причина?), нарушало бы устойчивость к
ним.&lt;/p&gt;
&lt;h3 id="primenenie"&gt;Применение&lt;/h3&gt;
&lt;p&gt;На практике криптографические хэширующие функции имеет несколько
вариантов применения, вот основные из них:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Хранение аутентификационных данных пользователей сайтов или
    программных продуктов.&lt;/strong&gt; В случае чисто теоретически возможной
    ошибки программистов или каких-либо других людей или просто имея
    доступ к базе данных на том или ином основании, потенциальный
    злоумышленник может получить доступ к закрытым компонентам того или
    иного проекта, в том числе и к базе данных пользователей. Если
    такого рода данные хранились бы в открытом виде, он получил бы
    полный доступ ко всем учетным записям пользователей. Для избежания
    возможности возникновения подобной ситуации принято хранить не сами
    логин и пароль пользователей, а их хэши. В этом случае для
    аутентификации введенные пользователем данные пропускаются через тот
    же алгоритм хэширования и полученный хэш сравнивается с хранящимся в
    БД.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Проверка целостности копии данных.&lt;/strong&gt; Чаще всего этот способ
    проверки соответствия копии оригиналу используется в отсутствии
    доступа к оригиналу. В качестве примера можно привести передачу
    больших объемов информации через ненадежное пространство (чаще всего
    Интернет), многие файловые серверы хранят рядом с большими файлами
    вычисленные от них хэши с использованием популярных алгоритмов,
    посетитель, скачав файл, может убедиться в его соответствии
    оригиналу, просто вычислив такой же хэш от копии и сравнив с
    доступным хэшем от оригинала. Но такой же принцип может
    использоваться и при доступном оригинале, например, многие программы
    для прожига образов на компакт-диски используют схожий принцип для
    проверки соответствия полученного диска образу.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Если же слегка отвлечься от криптографии, то можно найти еще достаточно
большое количество вариантов применения хэш-функций, таких как
хэш-таблицы, генерация псевдо-случайных чисел, поиск текста и многие
другие.&lt;/p&gt;
&lt;h4&gt;Заключение&lt;/h4&gt;
&lt;p&gt;Надеюсь сегодня мне успешно удалось осветить еще один компонент науки
под названием криптография, в обозримом будущем я планирую написать
несколько записей на эту же тему, но более практического характера, не
пропустить момент их публикации вам поможет &lt;a href="/feed/"&gt;подписка на RSS-ленту моего
блога&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 01 Feb 2008 15:43:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-02-01:security/2008/obratnogo-puti-net/</guid><category>encrypt</category><category>hash</category><category>защита интернет-ресурсов</category><category>информационные технологии</category><category>коллизия</category><category>Криптография</category><category>хэш</category><category>хэширование</category><category>шифрование</category></item><item><title>Путеводитель для роботов</title><link>https://www.insight-it.ru//theory/2008/putevoditel-dlya-robotov/</link><description>&lt;p&gt;Ни для кого не секрет, что одним их основных факторов, влияющих на
расположение страниц интернет-ресурса на просторах поисковых систем,
является уникальность контента (или другими словами - содержания).
Конечно же простейшим способом избежать дублирующегося контента является
просто собственноручная его генерация (или в крайнем случае с помощью
наемных работников или посетителей Вашего сайта). Но, к сожалению, это
позволяет избежать лишь повторов между разными сайтами. Помимо этого
свою роль играют и повторы в рамках одного сайта. Наверняка Вы замечали,
что многие CMS размещают один и тот же текст на разных страницах сайта:
например на обычной странице, в RSS-ленте и каком-нибудь архиве.&lt;/p&gt;
&lt;p&gt;Именно для решения этой маленькой проблемы и была создана технология под
названием &lt;strong&gt;Robots Exclusion Protocol&lt;/strong&gt;. С ее помощью можно
минимизировать возможность повторов содержимого, проиндексированного
поисковыми системами в рамках одного сайта, а также исключить из индекса
неинформативные страницы.&lt;/p&gt;
&lt;!--more--&gt;
&lt;p&gt;Надеюсь, что Вы представляете себе в чем заключается принцип работы
поисковых систем, но в любом случае не вижу причин для того чтобы не
рассказать вкратце об этом. Помимо собственно сайта, где пользователи
вводят ключевую фразу для поиска, любая поисковая система имеет еще две
части: базу данных (другими словами - индекс сайтов) и специальной
программы (которую чаще всего называют &lt;em&gt;пауком&lt;/em&gt; или по-английски -
&lt;em&gt;crawler&lt;/em&gt; или &lt;em&gt;spider&lt;/em&gt;, но иногда используется более общий термин -
&lt;em&gt;робот&lt;/em&gt;). Эта программа запущена на серверах поисковых систем во
множестве экземпляров и основной целью их работы является пополнение и
обновления индекса поисковой системы. Сам же сайт лишь делает выборку из
индекса в соответствии с запросом и сортирует результат.&lt;/p&gt;
&lt;p&gt;Принцип работы такого класса программ я уже упоминал в &lt;a href="https://www.insight-it.ru/security/2008/otkuda-voznikaet-spam-i-kak-s-nim-borotsya/" title="Откуда возникает спам и как с ним бороться"&gt;записи о борьбе со спамом&lt;/a&gt;,
так что повторюсь лишь вкратце в надежде, что Вы ее уже читали: они
перемещаются по просторам Сети следуя по гиперссылкам, и на каждой
странице, куда они попадают, стараются выполнить заранее определенное
действие, в нашем случае - проиндексировать ее.&lt;/p&gt;
&lt;p&gt;Обсуждаемая нами технология дает возможность веб-мастеру предоставить
crawler'ам, образно говоря, &lt;em&gt;путеводитель&lt;/em&gt; по его сайту. Методов для
этого имеется несколько:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Любой crawler прежде чем перейти на новый домен проверяет
    существование файла по адресу &lt;code&gt;http://www.некий-домен.ru/robots.txt&lt;/code&gt;.
    В таком файле веб-мастер может разместить директивы для
    потенциальных компьютеризированных посетителей в соответствии с
    &lt;a href="https://www.insight-it.ru/goto/32ecd79a/" rel="nofollow" target="_blank" title="http://www.robotstxt.org/norobots-rfc.txt"&gt;соответствующим стандартом&lt;/a&gt;. Если поисковый робот обнаруживает этот файл, то прочитав его он
    корректирует свой маршрут обхода всего интернет-ресурса в
    соответствии с указанными директивами.&lt;/li&gt;
&lt;li&gt;Внутри заголовка любой HTML-страницы или любого другого документа,
    передаваемого по http протоколу (с помощью заголовков самого
    протокола), можно разместить специальный meta-tag для роботов,
    который также должен соответствовать &lt;a href="https://www.insight-it.ru/goto/fef0ecbb/" rel="nofollow" target="_blank" title="http://www.robotstxt.org/meta.html"&gt;стандарту, опубликованному в 1996 году&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Основной частью &lt;em&gt;путеводителя&lt;/em&gt; чаще всего является карта &lt;a href="https://www.insight-it.ru/goto/9821991b/" rel="nofollow" target="_blank" title="http://sitemaps.org/"&gt;сайта в формате XML&lt;/a&gt;. С ее помощью программа может
    быстро определить весь ассортимент страниц, которые ей было бы
    неплохо проиндексировать.&lt;/li&gt;
&lt;li&gt;Самым последним был воплощен в жизнь метод, основанный на
    &lt;a href="https://www.insight-it.ru/goto/a9b68873/" rel="nofollow" target="_blank" title="http://microformats.org/wiki/rel-nofollow"&gt;микроформатах&lt;/a&gt;.
    Реализуется он с помощью параметра &lt;code&gt;rel="nofollow"&lt;/code&gt;, указанного
    внутри тэга &lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;, который обозначает ссылку, не предназначенную для
    перехода по ней пауком.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Карты сайтов и директивы robots.txt предназначены для определения
маршрута путешествия crawler'а, в то время как микроформаты и
meta-тэги - для влияния на сам процесс индексации.&lt;/p&gt;
&lt;p&gt;У каждого из описанных выше методов есть своя узкая специализация:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;robots.txt предоставляет базовый набор директив для роботов, которым
    они следуют даже в случае конфликтов с другими использованными
    методами.&lt;/li&gt;
&lt;li&gt;Карта сайта влияет на последовательность и набор страниц, посещенных
    пауком, с помощью указания приоритетов страниц или времени последней
    модификации.&lt;/li&gt;
&lt;li&gt;Мета-тэги распространяют свое действие на весь документ и влияет на
    индексирование страниц (если они одновременно присутствуют как в
    заголовке (X)HTML документа, так и в заголовках &lt;code&gt;X-Robots-Tags&lt;/code&gt;
    HTTP-протокола, то приоритет считается выше у заголовков протокола).&lt;/li&gt;
&lt;li&gt;Микроформаты позволяют в случае необходимости переопределять
    параметры любого конкретного тэга документа, не смотря на указания в
    мета-тэгах.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;С синтаксисом robots.txt лучше всего ознакомиться прямо в
соответствующей спецификации, ссылку на которую я уже приводил (хотя
возможно в будущем я всетаки соберусь написать запись и по этому
поводу). Не знаю занимается ли кто-нибудь генерацией карт сайта вручную,
но для общего развития будет полезно изучить и ее формат, неплохим
примером может послужить &lt;a href="/sitemap.xml" title="XML Sitemap"&gt;XML-карта этого блога&lt;/a&gt;.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Fri, 18 Jan 2008 01:13:00 +0300</pubDate><guid>tag:www.insight-it.ru,2008-01-18:theory/2008/putevoditel-dlya-robotov/</guid><category>crawler</category><category>robots exclusion protocol</category><category>robots.txt</category><category>SEO</category><category>spider</category><category>интернет</category><category>информационные технологии</category><category>поисковые системы</category><category>принцип работы поисковых систем</category><category>технология</category></item></channel></rss>
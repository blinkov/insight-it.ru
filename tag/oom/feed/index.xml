<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Insight IT</title><link>https://www.insight-it.ru/</link><description></description><atom:link href="https://www.insight-it.ru/tag/oom/feed/index.xml" rel="self"></atom:link><lastBuildDate>Sun, 07 Jun 2015 22:45:00 +0300</lastBuildDate><item><title>Что стоит знать о памяти в Linux?</title><link>https://www.insight-it.ru//linux/2015/chto-stoit-znat-o-pamiati-v-linux/</link><description>&lt;p&gt;Подсистема работы с оперативной памятью в &lt;a href="/tag/linux/"&gt;Linux&lt;/a&gt; - достаточно многогранная конструкция. Чтобы разобраться в её деталях нужно целенаправленно погрузиться в тему, с обязательным чтением исходников ядра, но это нужно не каждому. Для разработки и эксплуатации серверного программного обеспечения важно иметь хотябы базовое предстваление о том, как она работает, но меня не перестает удивлять насколько небольшая доля людей им обладает. В этом посте я постараюсь кратко пробежаться по основным вещам, без понимания которых на мой взгляд очень легко натворить глупостей.
&lt;!--more--&gt;&lt;/p&gt;
&lt;h2 id="kakaia-byvaet-pamiat"&gt;Какая бывает память?&lt;/h2&gt;
&lt;h3 id="fizicheskaia-i-virtualnaia"&gt;Физическая и виртуальная&lt;/h3&gt;
&lt;p&gt;Начнем издалека. В спецификации любого компьютера и в частности сервера непременно числится надпись "N гигабайт оперативной памяти" - именно столько в его распоряжении находится &lt;em&gt;физической&lt;/em&gt; памяти.&lt;/p&gt;
&lt;p&gt;Задача распределения доступных ресурсов между исполняемым программным обеспечением, в том числе и &lt;em&gt;физической&lt;/em&gt; памяти, лежит на плечах операционной системы, в нашем случае Linux. Для обеспечения иллюзии полной независимости, она предоставляет каждой из программ свое &lt;strong&gt;независимое&lt;/strong&gt; &lt;em&gt;виртуальное&lt;/em&gt; адресное пространство и низкоуровневый интерфейс работы с ним. Это избавляет их от необходимости знать друг о друге, размере доступной &lt;em&gt;физической&lt;/em&gt; памяти и текущей её занятости. Адреса в виртуальном пространстве процессов называют &lt;strong&gt;логическими&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Для отслеживания соответствия между физической и виртуальной памятью ядро Linux использует иерархический набор структур данных в своей служебной области &lt;em&gt;физической&lt;/em&gt; памяти (только оно работает с ней напрямую), а также специализированные аппаратные контуры, которые в совокупности называют &lt;abbr title="Memory Management Unit"&gt;MMU&lt;/abbr&gt;.&lt;/p&gt;
&lt;p&gt;Следить за каждым байтом памяти в отдельности было бы накладно, по-этому ядро оперирует достаточно большими блоками памяти - &lt;strong&gt;страницами&lt;/strong&gt;, типовой размер которых составляет 4 килобайта.&lt;/p&gt;
&lt;p&gt;Также стоит упомянуть, что на аппаратном уровне как правило есть поддержка дополнительного уровня абстракции в виде "сегментов" оперативной памяти, с помощью которых можно разделять программы на части. В отличии от других операционных систем, в Linux она практически не используется - логический адрес всегда совпадает с линейным (адресом внутри сегмента, которые сконфигурированы фиксированным образом).&lt;/p&gt;
&lt;h3 id="failovaia-i-anonimnaia"&gt;Файловая и анонимная&lt;/h3&gt;
&lt;p&gt;У приложений существует много способов выделить себе память для тех или иных нужд. Высокоуровневые языки программирования и библиотеки часто прячут от разработчиков какой из них в реальности использовался и другие детали (хотя их всегда можно "раскусить" с помощью &lt;code&gt;strace&lt;/code&gt;). Если углубляться в особенности каждого доступного варианта, эта статья быстро бы превратилась в книгу. Вместо этого предлагаю разделить их на две, на мой взгляд, крайне важные группы по тому, какую память они выделяют:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Файловой&lt;/strong&gt; памяти однозначно соответствует какой-либо файл или его часть в файловой системе. Первым делом в ней как правило находится исполняемый код самой программы. Для прикладных задач можно запросить отображение файла в виртуальное адресное пространство процесса с помощью системного вызова &lt;code&gt;mmap&lt;/code&gt; - после чего с ним можно работать как с любой другой областью памяти без явного чтения/записи, что будет при этом происходить с данными в файловой системе и что будут видеть другие процессы "отобразившие" этот же файл зависит от настроек.&lt;/li&gt;
&lt;li&gt;Любую другую выделенную память называют &lt;strong&gt;анонимной&lt;/strong&gt;, так как ей не соответствует никакой файл, которые как известно именованы. Сюда попадают как переменные на стеке, так и области, выделенные с помощью функций вроде &lt;code&gt;malloc&lt;/code&gt; (к слову, за сценой для выделения больших блоков памяти они обычно тоже используют &lt;code&gt;mmap&lt;/code&gt; с особым набором настроек, а для всего остального - &lt;code&gt;brk/sbrk&lt;/code&gt; или выдают ранее освобожденную память).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;На первый взгляд отличия не выглядят чем-то особенным, но тот факт, что области файловой памяти именованы, позволяет операционной системе экономить физическую память, порой очень значительно, сопоставляя виртуальные адреса нескольких процессов, работающих с одним и тем же файлом, одной физической странице в памяти. Это работает прозрачно, начиная от кода запущенных нескольких копий приложений, заканчивая специально сконструированными под эту оптимизацию систем.&lt;/p&gt;
&lt;h3 id="vytesniaemaia-i-net"&gt;Вытесняемая и нет&lt;/h3&gt;
&lt;p&gt;Суммарный объем используемой виртуальной памяти всех программ запросто может превышать объем доступной физической памяти. При этом в каждый конкретный момент времени приложениями может использоваться лишь небольшое подмножество хранимых по виртуальным адресам данных. Это означает, что операционная система может откладывать не используемые в данный момент данные из оперативной памяти на жесткий диск ("вытесняя"" их из памяти), а затем при попытке к этим данным обратиться - скопировать обратно в физическую оперативную память.
Этот механизм официально называется &lt;strong&gt;major page fault&lt;/strong&gt;, но под просто page fault как правило подразумевают тоже её, так как minor page fault мало кого заботит (отличие в том, что в случае minor ядру удается найти запрашиваемые данные уже загруженными в память с какой-то другой целью и обращения к диску в итоге не происходит).&lt;/p&gt;
&lt;p&gt;На время восстановления запрашиваемых приложением данных его выполнение &lt;em&gt;прерывается&lt;/em&gt; и управление передается ядру для выполнения соответствующей процедуры. Время, которое потребуется, чтобы приложение смогло продолжить свою работу, напрямую зависит от типа используемого жесткого диска:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Прочитать 4Кб данных с обычного серверного жесткого диска 7200rpm занимает порядка &lt;strong&gt;10 мс&lt;/strong&gt;, при хорошем стечении обстоятельств чуть меньше.&lt;ul&gt;
&lt;li&gt;Если вытесненных страниц оказывается много, запросто могут набегать заметные доли секунды (как условным пользователям, так и на внутренних приборах, в зависимости от задачи).&lt;/li&gt;
&lt;li&gt;Особенно опасны циклические pagefaults, когда есть две или более регулярно используемые области памяти, которые вместе не помещаются в физическую память, по-этому бесконечно вытесняют друг друга туда-обратно.&lt;/li&gt;
&lt;li&gt;При этом диск вынужден делать честный seek, что само по себе тоже может быть не кстати. Например, если с этим же диском работает какая-либо база данных.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Если используется &lt;abbr title="Solid State Drive"&gt;SSD&lt;/abbr&gt;, то ситуация несколько более радужная - из-за отсутствия механического движения аналогичная операция занимает примерно на порядок меньше, около &lt;strong&gt;1 мс&lt;/strong&gt; или её доли, в зависимости от типа и конкретной модели диска. Но годы идут, а &lt;abbr title="Solid State Drive"&gt;SSD&lt;/abbr&gt; так и остаются нишевым компромиссным продуктом по цене-объему.&lt;/li&gt;
&lt;li&gt;А теперь для сравнения: если бы страница уже была в памяти, то при обращении к ней счет шел бы на &lt;strong&gt;сотни наносекунд&lt;/strong&gt;. Это почти &lt;em&gt;на 4 порядка быстрее&lt;/em&gt;, чем pagefault, даже на &lt;abbr title="Solid State Drive"&gt;SSD&lt;/abbr&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Стоит отметить, что с точки зрения приложения всё это прозрачно и является внешним воздействием, то есть может происходить в самый не подходящий, с точки зрения решаемой им задачи, момент.&lt;/p&gt;
&lt;p&gt;Думаю понятно, что приложения, которым важна высокая производительность и стабильное время отклика, должны избегать pagefault'ов всеми доступными методами, к ним и перейдем.&lt;/p&gt;
&lt;h2 id="metody-upravleniia-podsistemoi-pamiati_1"&gt;Методы управления подсистемой памяти&lt;/h2&gt;
&lt;h3 id="swap"&gt;&lt;del&gt;swap&lt;/del&gt;&lt;/h3&gt;
&lt;p&gt;С файловой памятью всё просто: если данные в ней не менялись, то для её вытеснения делать особо ничего не нужно - просто перетираешь, а затем всегда можно восстановить из файловой системы.&lt;/p&gt;
&lt;p&gt;С анонимной памятью такой трюк не работает: ей не соответствует никакой файл, по-этому чтобы данные не пропали безвозвратно, их нужно положить куда-то ещё. Для этого можно использовать так называемый "swap" раздел или файл. Можно, но на практике не нужно. Если swap выключен, то анонимная память становится невытесняемой, что делает время обращения к ней предсказуемым.&lt;/p&gt;
&lt;p&gt;Может показаться минусом выключенного swap, что, например, если у приложения утекает память, то оно будет гарантированно зря держать физическую память (утекшая не сможет быть вытеснена). Но на подобные вещи скорее стоит смотреть с той точки зрения, что это наоборот поможет раньше обнаружить и устранить ошибку.&lt;/p&gt;
&lt;h3 id="mlock"&gt;mlock&lt;/h3&gt;
&lt;p&gt;По-умолчанию вся файловая память является вытесняемой, но ядро Linux предоставляет возможность запрещать её вытеснение с точностью не только до файлов, но и до страниц внутри файла.&lt;/p&gt;
&lt;p&gt;Для этого используется системный вызов &lt;code&gt;mlock&lt;/code&gt; на области виртуальной памяти, полученной с помощью &lt;code&gt;mmap&lt;/code&gt;. Если спускаться до уровня системных вызовов не хочется, рекомендую посмотреть в сторону консольной утилиты &lt;code&gt;vmtouch&lt;/code&gt;, которая делает ровно то же самое, но снаружи относительно приложения.&lt;/p&gt;
&lt;p&gt;Несколько примеров, когда это может быть целесообразно:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;У приложения большой исполняемый файл с большим количеством ветвлений, некоторые из которых срабатывают редко, но регулярно. Такого стоит избегать и по другим причинам, но если иначе никак, то чтобы не ждать лишнего на этих редких ветках кода - можно запретить им вытесняться.&lt;/li&gt;
&lt;li&gt;Индексы в базах данных часто физически представляют собой именно файл, с которым работают через &lt;code&gt;mmap&lt;/code&gt;, а &lt;code&gt;mlock&lt;/code&gt; нужен чтобы минимизировать задержки и число операций ввода-вывода на и без того нагруженном диске(-ах).&lt;/li&gt;
&lt;li&gt;Приложение использует какой-то статический словарь, например с соответствием подсетей IP-адресов и стран, к которым они относятся. Вдвойне актуально, если на одном сервере запущено несколько процессов, работающих с этим словарем.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="oom-killer"&gt;&lt;abbr title="Out Of Memory"&gt;OOM&lt;/abbr&gt; killer&lt;/h3&gt;
&lt;p&gt;Перестаравшись с невытесняемой памятью не трудно загнать операционную систему в ситуацию, когда физическая память кончилась, а вытеснять ничего нельзя. Безысходной она выглядит лишь на первый взгляд: вместо вытеснения память можно освободить.&lt;/p&gt;
&lt;p&gt;Происходит это достаточно радикальными методами: послуживший названием данного раздела механизм выбирает по определенному алгоритму процесс, которым наиболее целесообразно в текущий момент пожертвовать - с остановкой процесса освобождается использовавшаяся им память, которую можно перераспределить между выжившими. Основной критерий для выбора: текущее потребление физической памяти и других ресурсов, плюс есть возможность вмешаться и вручную пометить процессы как более или менее ценные, а также вовсе исключить из рассмотрения. Если отключить &lt;abbr title="Out Of Memory"&gt;OOM&lt;/abbr&gt; killer полностью, то системе в случае полного дефицита ничего не останется, как перезагрузиться.&lt;/p&gt;
&lt;h3 id="cgroups"&gt;&lt;abbr title="control groups"&gt;cgroups&lt;/abbr&gt;&lt;/h3&gt;
&lt;p&gt;По-умолчанию все пользовательские процессы наравне претендуют на почти всю физически доступную память в рамках одного сервера. Это поведение редко является приемлемым. Даже если сервер условно-однозадачный, например только отдает статические файлы по HTTP с помощью &lt;a href="/tag/nginx/"&gt;nginx&lt;/a&gt;, всегда есть какие-то служебные процессы вроде &lt;a href="/tag/syslog/"&gt;syslog&lt;/a&gt; или какой-то временной команды, запущенной человеком. Если же на сервере одновременно работает несколько production процессов, например, популярный вариант - подсадить к веб-серверу &lt;a href="/tag/memcached/"&gt;memcached&lt;/a&gt;, крайне желательно, чтобы они не могли начать "воевать" друг с другом за память в случае её дефицита.&lt;/p&gt;
&lt;p&gt;Для изоляции важных процессов в современных ядрах существует механизм &lt;abbr title="control groups"&gt;cgroups&lt;/abbr&gt;, c его помощью можно разделить процессы на логические группы и статически сконфигурировать для каждой из групп сколько физической памяти может быть ей выделено. После чего для каждой группы создается своя почти независимая подсистема памяти, со своим отслеживанием вытеснения, &lt;abbr title="Out Of Memory"&gt;OOM&lt;/abbr&gt; killer и прочими радостями.&lt;/p&gt;
&lt;p&gt;Механизм &lt;abbr title="control groups"&gt;cgroups&lt;/abbr&gt; намного обширнее, чем просто контроль за потреблением памяти, с его помощью можно распределять вычислительные ресурсы, "прибивать" группы к ядрам процессора, ограничивать ввод-вывод и многое другое. Сами группы могут быть организованы в иерархию и вообще на основе &lt;abbr title="control groups"&gt;cgroups&lt;/abbr&gt; работают многие системы "легкой" виртуализации и нынче модные Docker-контейнеры.&lt;/p&gt;
&lt;p&gt;Но на мой взгляд именно контроль за потреблением памяти - самый необходимый минимум, который определенно стоит настроить, остальное уже по желанию/необходимости.&lt;/p&gt;
&lt;h2 id="numa_1"&gt;&lt;abbr title="Non-Uniform Memory Access"&gt;NUMA&lt;/abbr&gt;&lt;/h2&gt;
&lt;p&gt;В многопроцессорных системах не вся память одинакова. Если на материнской плате предусмотрено &lt;code&gt;N&lt;/code&gt; процессоров (например, 2 или 4), то как правило все слоты для оперативной памяти физически разделены на &lt;code&gt;N&lt;/code&gt; групп так, что каждая из них располагается ближе к соответствующему ей процессору - такую схему называют &lt;abbr title="Non-Uniform Memory Access"&gt;NUMA&lt;/abbr&gt;.&lt;/p&gt;
&lt;p&gt;Таким образом, каждый процессор может обращаться к определенной &lt;code&gt;1/N&lt;/code&gt; части физической памяти быстрее (примерно раза в полтора), чем к оставшимся &lt;code&gt;(N-1)/N&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Ядро Linux самостоятельно умеет это всё определять и по-умолчанию достаточно разумным образом учитывать при планировании выполнения процессоров и выделении им памяти. Посмотреть как это все выглядит и подкорректировать можно с помощью утилиты &lt;code&gt;numactl&lt;/code&gt; и ряда доступных системных вызовов, в частности &lt;code&gt;get_mempolicy&lt;/code&gt;/&lt;code&gt;set_mempolicy&lt;/code&gt;.&lt;/p&gt;
&lt;h2 id="operatsii-s-pamiatiu"&gt;Операции с памятью&lt;/h2&gt;
&lt;p&gt;Есть несколько тем, с которыми в реальности сталкиваются лишь &lt;a href="/tag/c/"&gt;C/C++&lt;/a&gt; разработчики низкоуровневых систем, и не мне им про это рассказывать. Но даже если напрямую с этим не сталкиваться на мой взгляд полезно в общих чертах знать, какие бывают нюансы:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Операции, работающие с памятью:&lt;ul&gt;
&lt;li&gt;В большинстве своем не атомарны (то есть другой поток может их "увидеть" на полпути), без явной синхронизации атомарность возможна только для блоков памяти не больше указателя (т.е. как правило 64 бита) и то при определенных условиях.&lt;/li&gt;
&lt;li&gt;В реальности происходят далеко не всегда в том порядке, в котором они написаны в исходном коде программы: процессоры и компиляторы на правах оптимизации могут менять их порядок, как считают нужным. В случае многопоточных программ эти оптимизации часто могут приводить к нарушению логики их работы. Для предотвращения подобных ошибок разработчики могут использовать специальные инструменты, в частности &lt;strong&gt;барьеры памяти&lt;/strong&gt; - инструкции, которые запрещают переносить операции с памятью между частями программы до неё и после.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Новые процессы создаются с помощью системного вызова &lt;code&gt;fork&lt;/code&gt;, который порождает копию текущего процесса (чтобы запустить другую программу в новом процессе существует отдельное семейство системных вызовов - &lt;code&gt;exec&lt;/code&gt;), у которого виртуальное пространство практически полностью идентично родительскому, что не потребляет дополнительной физической памяти до тех пор, пока тот или другой не начнут его изменять. Этот механизм называется &lt;code&gt;copy on write&lt;/code&gt; и на нем можно играть для создания большого числа однотипных независимых процессов (например, обрабатывающих какие-то запросы), с минимумом дополнительных расходов физической памяти - в некоторых случаях так жить удобнее, чем с многопоточным приложением.&lt;/li&gt;
&lt;li&gt;Между процессором и оперативной памятью находится несколько уровней кешей, обращение к которым ещё на порядки быстрее, чем к оперативной памяти. К самому быстрому - доли наносекунд, к самому медленному единицы наносекунд. На особенностях их работы можно делать микро оптимизации, но из высокоуровневых языков программирования до них толком не добраться.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="itogo"&gt;Итого&lt;/h2&gt;
&lt;p&gt;Подсистему памяти в Linux нельзя бросать на произвол судьбы. Как минимум, стоит следить за следующими показателями и вывести на приборы (как суммарно, так и по процессам или их группам):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Скорость возникновения major page faults;&lt;/li&gt;
&lt;li&gt;Срабатывания &lt;abbr title="Out Of Memory"&gt;OOM&lt;/abbr&gt; killer;&lt;/li&gt;
&lt;li&gt;Текущий объем использования физической памяти (это число обычно называют &lt;abbr title="Resident Set Size"&gt;RSS&lt;/abbr&gt;, не путать с одноименным форматом для публикации текстового контента).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;В штатном режиме все три показателя должны быть стабильны (а первые два - близки к нулю). Всплески или плавный рост стоит рассматривать как аномалию, в причинах которой стоит разобраться. Какими методами - надеюсь я показал достаточно направлений, куда можно по-копать.&lt;/p&gt;
&lt;div class="card teal"&gt;
&lt;div class="card-content white-text"&gt;
&lt;ul&gt;
&lt;li class="white-text"&gt;Статья написана с ориентиром на современные Debian-like дистрибутивы Linux и физическое оборудование с двумя процеcсорами Intel Xeon. Общие принципы ортогональны этому и справедливы даже для других операционных систем, но вот детали могут сильно разниться даже в зависимости от сборки ядра или конфигурации.&lt;/li&gt;
&lt;li class="white-text"&gt;У большинства упомянутых выше системных вызовов, функций и команд есть &lt;code&gt;man&lt;/code&gt;, к которому рекомендую обращаться за подробностями об их использовании и работе. Если под рукой нет linux-машины, где можно набрать &lt;code&gt;man foo&lt;/code&gt; - они обычно легко ищутся с таким же запросом.&lt;/li&gt;
&lt;li class="white-text"&gt;Если есть желание углубиться в какую-либо из затронутых вскользь тем - пишите об этом в комментариях, любая из них может стать заголовком отдельной статьи.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="ps"&gt;P.S.&lt;/h2&gt;
&lt;p&gt;На последок ещё раз повторю цифры, которые настоятельно рекомендую запомнить:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;0.0001 мс&lt;/strong&gt; (100 нс) - обращение к оперативной памяти&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;0.1-1 мс&lt;/strong&gt; (0.1-1 млн. нс) - обращение к &lt;abbr title="Solid State Drive"&gt;SSD&lt;/abbr&gt; при major pagefault, &lt;em&gt;на 3-4 порядка дороже&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;5-10 мс&lt;/strong&gt; (5-10 млн. нс) - обращение к традиционному жесткому диску при pagefault, &lt;em&gt;ещё на порядок дороже&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;// мс - миллисекунды, нс - наносекунды.&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Иван Блинков</dc:creator><pubDate>Sun, 07 Jun 2015 22:45:00 +0300</pubDate><guid>tag:www.insight-it.ru,2015-06-07:linux/2015/chto-stoit-znat-o-pamiati-v-linux/</guid><category>оперативная память</category><category>память</category><category>pagefault</category><category>page fault</category><category>cgroups</category><category>NUMA</category><category>oom</category><category>oom killer</category><category>mlock</category></item></channel></rss>